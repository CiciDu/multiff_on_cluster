{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install neo\n",
    "# !pip install matplotlib_scalebar\n",
    "# !pip install ffmpeg\n",
    "# !pip install Ipython --upgrade\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if using google drive\n",
    "\n",
    "# from google.colab import drive # import drive from google colab\n",
    "# drive.mount(\"/content/drive\") \n",
    "# %cd /content/drive/MyDrive/ff_repo/Multifirefly-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "import sys\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, base_processing_class, combine_info_utils, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_points, make_ff_dataframe, ff_dataframe_utils, pattern_by_trials, pattern_by_points, cluster_analysis, organize_patterns_and_features, category_class, cluster_analysis\n",
    "from decision_making_analysis.decision_making import decision_making_class, decision_making_utils, plot_decision_making, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_helper_class, GUAT_collect_info_class, GUAT_combine_info_class, add_features_GUAT_and_TAFT\n",
    "from decision_making_analysis import free_selection, replacement, trajectory_info\n",
    "from null_behaviors import show_null_trajectory, find_best_arc, curvature_utils, curv_of_traj_utils\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class, prep_ml_data_utils\n",
    "from machine_learning.RL.env_related import env_for_lstm, env_utils, base_env, collect_agent_data, process_agent_data\n",
    "from machine_learning.RL.lstm import GRU_functions, LSTM_functions\n",
    "from machine_learning.RL.SB3 import interpret_neural_network, sb3_for_multiff_class, rl_for_multiff_utils, SB3_functions\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics, monkey_heading_utils\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from planning_analysis.test_params_for_planning import params_test_combos_class, params_utils\n",
    "from visualization.plotly_tools import plotly_for_monkey, plotly_for_time_series, plotly_preparation, plotly_for_correlation\n",
    "from visualization.dash_tools import dash_prep_class, dash_utils, dash_utils, dash_comparison_class, dash_params_class\n",
    "from visualization.dash_tools.dash_main_class_methods import dash_main_class\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils\n",
    "from planning_analysis.only_cur_ff import only_cur_ff_utils, only_cur_ff_class, only_cur_ff_utils\n",
    "from planning_analysis.plan_factors import plan_factors_utils, build_factor_comp, plan_factors_class, monkey_plan_factors_x_sess_class, feature_lists\n",
    "from planning_analysis.agent_analysis import compare_monkey_and_agent_utils, agent_plan_factors_class, agent_plan_factors_x_sess_class\n",
    "from planning_analysis.plan_factors import test_vs_control_utils\n",
    "from planning_analysis.factors_vs_indicators import make_variations_utils, process_variations_utils\n",
    "from planning_analysis.show_planning import nxt_ff_utils, show_planning_class, show_planning_utils, examine_null_arcs\n",
    "from planning_analysis.show_planning.cur_vs_nxt_ff import cvn_helper_class, find_cvn_utils, plot_cvn_class, plot_cvn_utils, plot_monkey_heading_helper_class, cvn_from_ref_class\n",
    "from machine_learning.ml_methods import ml_methods_class, prep_ml_data_utils\n",
    "from eye_position_analysis import eye_positions\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_utils, cca_cv_utils, cca_class\n",
    "from planning_analysis.plan_indicators import plan_indicator_utils\n",
    "\n",
    "from importlib import reload\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import cm\n",
    "from os.path import exists\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import itertools\n",
    "import plotly.express as px\n",
    "from scipy.stats import rankdata\n",
    "from scipy import stats\n",
    "from IPython.display import HTML\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, fbeta_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import pi\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import warnings\n",
    "import os, sys, sys\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import plotly.graph_objects as go\n",
    "import gc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.max_rows = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_name = 'monkey_Bruno'\n",
    "opt_arc_type = 'opt_arc_stop_closest'\n",
    "ref_point_mode = 'distance'\n",
    "ref_point_value = -100\n",
    "curv_traj_window_before_stop = [-25, 0]\n",
    "combd_heading_df_x_sessions_exists_ok = True\n",
    "heading_info_df_exists_ok = True\n",
    "sp = show_planning_class.ShowPlanning(monkey_name=monkey_name,\n",
    "                                            opt_arc_type=opt_arc_type)\n",
    "sp.test_heading_info_df, sp.ctrl_heading_info_df = sp.make_or_retrieve_combd_heading_df_x_sessions_from_both_test_and_control(ref_point_mode, ref_point_value,\n",
    "                                                                                                                                        curv_traj_window_before_stop=curv_traj_window_before_stop,\n",
    "                                                                                                                                        combd_heading_df_x_sessions_exists_ok=combd_heading_df_x_sessions_exists_ok,\n",
    "                                                                                                                                        show_printed_output=True, heading_info_df_exists_ok=heading_info_df_exists_ok,\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _make_combd_heading_df_x_sessions(self, test_or_control='test',\n",
    "                                          ref_point_mode='distance', ref_point_value=-100,\n",
    "                                          curv_traj_window_before_stop=[\n",
    "                                              -25, 0],\n",
    "                                          stops_near_ff_df_exists_ok=True, heading_info_df_exists_ok=True,\n",
    "                                          sessions_df_for_one_monkey=None,\n",
    "                                          use_curv_to_ff_center=False):\n",
    "        ref_point_mode = ref_point_mode\n",
    "        ref_point_value = ref_point_value\n",
    "        curv_traj_window_before_stop = curv_traj_window_before_stop\n",
    "\n",
    "        if sessions_df_for_one_monkey is not None:\n",
    "            sessions_df_for_one_monkey = sessions_df_for_one_monkey\n",
    "        else:\n",
    "            sessions_df_for_one_monkey = combine_info_utils.make_sessions_df_for_one_monkey(\n",
    "                raw_data_dir_name, monkey_name)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            for index, row in sessions_df_for_one_monkey.iterrows():\n",
    "                if row['finished'] is True:\n",
    "                    continue\n",
    "                print(\n",
    "                    f'Making heading_info_df for: {row[\"monkey_name\"]} {row[\"data_name\"]}')\n",
    "                heading_info_df = _make_heading_info_df_for_a_data_session(row['monkey_name'], row['data_name'], ref_point_mode=ref_point_mode,\n",
    "                                                                                     ref_point_value=ref_point_value, test_or_control=test_or_control,\n",
    "                                                                                     curv_traj_window_before_stop=curv_traj_window_before_stop,\n",
    "                                                                                     stops_near_ff_df_exists_ok=stops_near_ff_df_exists_ok, heading_info_df_exists_ok=heading_info_df_exists_ok,\n",
    "                                                                                     use_curv_to_ff_center=use_curv_to_ff_center,\n",
    "                                                                                     merge_diff_in_curv_df_to_heading_info=False,\n",
    "                                                                                     )\n",
    "                heading_info_df['data_name'] = row['data_name']\n",
    "                combd_heading_df_x_sessions = pd.concat(\n",
    "                    [combd_heading_df_x_sessions, heading_info_df], axis=0)\n",
    "                combd_diff_in_curv_df = pd.concat(\n",
    "                    [combd_diff_in_curv_df, snf.diff_in_curv_df], axis=0)\n",
    "                sessions_df_for_one_monkey.loc[sessions_df_for_one_monkey['data_name']\n",
    "                                                    == row['data_name'], 'finished'] = True\n",
    "        return combd_heading_df_x_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# exp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_point_params = monkey_plan_factors_x_sess_class.PlanAcrossSessions.default_ref_point_params_based_on_mode\n",
    "monkeys=['monkey_Schro', 'monkey_Bruno']\n",
    "verbose=True\n",
    "kwargs = {}\n",
    "\n",
    "for monkey_name in monkeys:\n",
    "    variations_list = specific_utils.init_variations_list_func(\n",
    "        ref_point_params,\n",
    "        monkey_name=monkey_name\n",
    "    )\n",
    "    \n",
    "    for _, row in variations_list.iterrows():\n",
    "        ref_point_mode = row['ref_point_mode']\n",
    "        ref_point_value = row['ref_point_value']\n",
    "        if verbose:\n",
    "            print(row)\n",
    "        \n",
    "        # Initialize sessions\n",
    "        planner = monkey_plan_factors_x_sess_class.PlanAcrossSessions(monkey_name=monkey_name)\n",
    "        planner.initialize_monkey_sessions_df_for_one_monkey()\n",
    "        planner.get_test_and_ctrl_heading_info_df_across_sessions(\n",
    "            ref_point_mode=ref_point_mode,\n",
    "            ref_point_value=ref_point_value,\n",
    "            save_data=False,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner.test_heading_info_df['diff_in_abs_angle_to_nxt_ff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner.test_heading_info_df['data_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_sess_median_info = pd.DataFrame()\n",
    "# for data_name in planner.test_heading_info_df['data_name'].unique():\n",
    "#     print(f'Processing data_name: {data_name}')\n",
    "#     session_test_heading_info_df = planner.test_heading_info_df[planner.test_heading_info_df['data_name'] == data_name]\n",
    "#     session_ctrl_heading_info_df = planner.ctrl_heading_info_df[planner.ctrl_heading_info_df['data_name'] == data_name]\n",
    "    \n",
    "#     session_median_info = make_variations_utils.make_pooled_median_info_from_test_and_ctrl_heading_info_df(session_test_heading_info_df,\n",
    "#                                                                                                     session_ctrl_heading_info_df, verbose=False)\n",
    "\n",
    "#     session_median_info['data_name'] = data_name\n",
    "#     per_sess_median_info = pd.concat([per_sess_median_info, session_median_info], axis=0)\n",
    "\n",
    "# per_sess_median_info['ref_point_mode'] = ref_point_mode\n",
    "# per_sess_median_info['ref_point_value'] = ref_point_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map data_name to sequential session_id\n",
    "unique_data_names = np.sort(per_sess_median_info['data_name'].unique())\n",
    "data_name_to_id = {name: i for i, name in enumerate(unique_data_names)}\n",
    "per_sess_median_info['session_id'] = per_sess_median_info['data_name'].map(data_name_to_id)\n",
    "per_sess_median_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pooled_median_info_from_session(session_test_heading_info_df, session_ctrl_heading_info_df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_median_info = make_variations_utils.make_pooled_median_info_from_test_and_ctrl_heading_info_df(test_heading_info_df,\n",
    "                                                                                                      ctrl_heading_info_df, verbose=verbose)\n",
    "pooled_median_info['ref_point_mode'] = ref_point_mode\n",
    "pooled_median_info['ref_point_value'] = ref_point_value\n",
    "time_calibration = {'ref_point_mode': ref_point_mode,\n",
    "                        'ref_point_value': ref_point_value, 'monkey_name': monkey_name}\n",
    "pooled_median_info.attrs.update(time_calibration)\n",
    "\n",
    "\n",
    "os.makedirs(pooled_median_info_folder_path, exist_ok=True)\n",
    "pooled_median_info.to_csv(df_path)\n",
    "print('Stored new pooled_median_info in ',\n",
    "      pooled_median_info_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "            pooled_perc_info = make_variations_utils.make_pooled_perc_info_from_test_and_ctrl_heading_info_df(test_heading_info_df,\n",
    "                                                                                                             ctrl_heading_info_df, verbose=verbose)\n",
    "\n",
    "            if save_data:\n",
    "                pooled_perc_info.to_csv(pooled_perc_info_path)\n",
    "            print('Stored new pooled_perc_info in ', pooled_perc_info_path)\n",
    "\n",
    "        pooled_perc_info['monkey_name'] = monkey_name\n",
    "        pooled_perc_info['opt_arc_type'] = opt_arc_type\n",
    "\n",
    "        if process_info_for_plotting:\n",
    "            process_pooled_perc_info_to_plot_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ref_point_params = monkey_plan_factors_x_sess_class.PlanAcrossSessions.default_ref_point_params_based_on_mode\n",
    "# monkeys=['monkey_Schro', 'monkey_Bruno']\n",
    "# verbose=True\n",
    "\n",
    "# for monkey_name in monkeys:\n",
    "#     variations_list = specific_utils.init_variations_list_func(\n",
    "#         ref_point_params,\n",
    "#         monkey_name=monkey_name\n",
    "#     )\n",
    "    \n",
    "#     for _, row in variations_list.iterrows():\n",
    "#         ref_point_mode = row['ref_point_mode']\n",
    "#         ref_point_value = row['ref_point_value']\n",
    "#         if verbose:\n",
    "#             print(row)\n",
    "        \n",
    "#         # Initialize sessions\n",
    "#         planner = monkey_plan_factors_x_sess_class.PlanAcrossSessions(monkey_name=monkey_name)\n",
    "#         planner.initialize_monkey_sessions_df_for_one_monkey()\n",
    "#         planner.get_test_and_ctrl_heading_info_df_across_sessions(\n",
    "#             ref_point_mode=ref_point_mode,\n",
    "#             ref_point_value=ref_point_value,\n",
    "#             save_data=False,\n",
    "#             **kwargs\n",
    "#         )\n",
    "        \n",
    "        # Process test and control data\n",
    "        test_df = build_factor_comp.process_heading_info_df(\n",
    "            planner.test_heading_info_df.copy()\n",
    "        )\n",
    "        ctrl_df = build_factor_comp.process_heading_info_df(\n",
    "            planner.ctrl_heading_info_df.copy()\n",
    "        )\n",
    "        \n",
    "        # Filter NaNs for d_curv column\n",
    "        test_df_clean, ctrl_df_clean = filter_and_report_nan(\n",
    "            test_df, ctrl_df, col_name='diff_in_abs_angle_to_nxt_ff'\n",
    "        )\n",
    "        \n",
    "        # Run angle test directly on raw data (assumed no filtering needed)\n",
    "        angle_p = test_angle_func(\n",
    "            test_df_clean['diff_in_abs_angle_to_nxt_ff'].values,\n",
    "            ctrl_df_clean['diff_in_abs_angle_to_nxt_ff'].values\n",
    "        )\n",
    "        \n",
    "        # Filter NaNs for d_curv column\n",
    "        test_df_clean, ctrl_df_clean = filter_and_report_nan(\n",
    "            test_df, ctrl_df, col_name='diff_in_abs_d_curv'\n",
    "        )\n",
    "\n",
    "        # Run d_curv test on cleaned data\n",
    "        d_curv_p = test_d_curv_func(\n",
    "            test_df_clean['diff_in_abs_d_curv'].values,\n",
    "            ctrl_df_clean['diff_in_abs_d_curv'].values\n",
    "        )\n",
    "\n",
    "        # get dir_from_cur_ff_same_side\n",
    "        build_factor_comp.add_dir_from_cur_ff_same_side(test_df)\n",
    "        build_factor_comp.add_dir_from_cur_ff_same_side(ctrl_df)\n",
    "\n",
    "        \n",
    "        # Filter NaNs for d_dir column\n",
    "        test_df_clean, ctrl_df_clean = filter_and_report_nan(\n",
    "            test_df, ctrl_df, col_name='dir_from_cur_ff_same_side'\n",
    "        )\n",
    "        \n",
    "        # Run d_dir test on cleaned data\n",
    "        d_dir_p = test_d_dir_func(\n",
    "            test_df['dir_from_cur_ff_same_side'].values,\n",
    "            ctrl_df['dir_from_cur_ff_same_side'].values\n",
    "        )\n",
    "        \n",
    "        # Collect results\n",
    "        results.append({\n",
    "            'monkey_name': monkey_name,\n",
    "            'ref_point_mode': ref_point_mode,\n",
    "            'ref_point_value': ref_point_value,\n",
    "            'angle_p_value': angle_p,\n",
    "            'd_curv_p_value': d_curv_p,\n",
    "            'd_dir_p_value': d_dir_p,\n",
    "            'd_dir_test_sample_size': len(test_df_clean),\n",
    "            'd_dir_ctrl_sample_size': len(ctrl_df_clean),\n",
    "        })\n",
    "\n",
    "return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## all sessions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = monkey_plan_factors_x_sess_class.PlanAcrossSessions(monkey_name='monkey_Schro')\n",
    "ps.initialize_monkey_sessions_df_for_one_monkey()\n",
    "ps.get_test_and_ctrl_heading_info_df_across_sessions(\n",
    "                        ref_point_mode='distance', ref_point_value=-100,\n",
    "                        save_data=False)\n",
    "\n",
    "test_heading_info_df = ps.test_heading_info_df.copy()\n",
    "ctrl_heading_info_df = ps.ctrl_heading_info_df.copy()\n",
    "test_heading_info_df = build_factor_comp.process_heading_info_df(test_heading_info_df)\n",
    "ctrl_heading_info_df = build_factor_comp.process_heading_info_df(ctrl_heading_info_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## one session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "snf.heading_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\"\n",
    "\n",
    "kwargs = {\n",
    "    'ref_point_mode': 'time after cur ff visible', # 'distance',\n",
    "    'ref_point_value': 0.1, #-150,\n",
    "    'deal_with_rows_with_big_ff_angles': True,\n",
    "    'remove_i_o_modify_rows_with_big_ff_angles': False,\n",
    "}\n",
    "\n",
    "add_kwargs = {\n",
    "    'curv_of_traj_mode': 'distance',\n",
    "    'window_for_curv_of_traj': [-25, 0],\n",
    "    'truncate_curv_of_traj_by_time_of_capture': True,\n",
    "}\n",
    "\n",
    "#data_item_info = find_cvn_utils.extract_key_info_from_data_item_for_stops_near_ff_class(data_item)\n",
    "\n",
    "snf = cvn_from_ref_class.CurVsNxtFfFromRefClass(raw_data_folder_path=raw_data_folder_path)\n",
    "snf.get_more_monkey_data()\n",
    "snf.traj_curv_descr = 'Traj Curv: From Current Point to Right Before Stop'\n",
    "\n",
    "snf.streamline_organizing_info(**kwargs, **add_kwargs, test_or_control='test')\n",
    "test_heading_info_df = snf.heading_info_df.copy()\n",
    "\n",
    "# also need to make heading info df for control\n",
    "snf.make_heading_info_df_without_long_process(**kwargs, test_or_control='control')\n",
    "ctrl_heading_info_df = snf.heading_info_df.copy()\n",
    "\n",
    "test_heading_info_df = build_factor_comp.process_heading_info_df(test_heading_info_df)\n",
    "ctrl_heading_info_df = build_factor_comp.process_heading_info_df(ctrl_heading_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## all ref points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon_df = plan_indicator_utils.run_tests_over_monkeys(\n",
    "    test='wilcoxon',\n",
    "    ref_point_params=monkey_plan_factors_x_sess_class.PlanAcrossSessions.default_ref_point_params_based_on_mode,\n",
    "    curv_traj_window_before_stop=[-25, 0],\n",
    "    filter_heading_info_df_across_refs=False,\n",
    ")\n",
    "wilcoxon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## one ref point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_heading_info_df['diff_in_abs_angle_to_nxt_ff'].values\n",
    "y = ctrl_heading_info_df['diff_in_abs_angle_to_nxt_ff'].values\n",
    "_, p = mannwhitneyu(x, y, alternative='greater')\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Perm test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## all ref points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_df = plan_indicator_utils.run_tests_over_monkeys(\n",
    "    test='permutation',\n",
    "    ref_point_params=monkey_plan_factors_x_sess_class.PlanAcrossSessions.default_ref_point_params_based_on_mode,\n",
    "    curv_traj_window_before_stop=[-25, 0],\n",
    "    num_permutations=10000\n",
    ")\n",
    "perm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## one ref point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_heading_info_df['diff_in_abs_angle_to_nxt_ff'].values\n",
    "y = ctrl_heading_info_df['diff_in_abs_angle_to_nxt_ff'].values\n",
    "plan_indicator_utils.permutation_test(x, y, num_permutations=10000, alternative='greater', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_heading_info_df['diff_in_abs_d_curv'].values\n",
    "y = ctrl_heading_info_df['diff_in_abs_d_curv'].values\n",
    "plan_indicator_utils.permutation_test(x, y, num_permutations=10000, alternative='greater', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_factor_comp.add_dir_from_cur_ff_same_side(test_heading_info_df)\n",
    "build_factor_comp.add_dir_from_cur_ff_same_side(ctrl_heading_info_df)\n",
    "\n",
    "x = test_heading_info_df['dir_from_cur_ff_same_side'].values\n",
    "y = ctrl_heading_info_df['dir_from_cur_ff_same_side'].values\n",
    "plan_indicator_utils.permutation_test(x, y, num_permutations=10000, alternative='greater', random_state=None, statistic='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Plot var of interest\n",
    "\n",
    "Looking back at this after some time, I believe the purpose of this section is to show that, in test cases, the parameter of interest (such as diff_in_abs_angle_to_nxt_ff) tends to be more skewed to the right compared to control cases. This is important because higher values of this parameter provide stronger evidence of planning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# planning indicators: diff_in_abs_angle_to_nxt_ff, diff_in_abs_d_curv, dir_from_cur_ff_same_side, dir_from_cur_ff_to_nxt_ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## scatter + hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### curv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_col = 'd_curv_null_arc'\n",
    "monk_col = 'd_curv_monkey'\n",
    "diff_col = 'diff_in_d_curv'\n",
    "diff_in_abs_col = 'diff_in_abs_d_curv'\n",
    "#plan_indicator_utils.plot_scatter_test_vs_ctrl(test_heading_info_df, ctrl_heading_info_df, arc_col, monk_col, diff_col, diff_in_abs_col)\n",
    "plan_indicator_utils.plot_hist_test_vs_ctrl(test_heading_info_df, ctrl_heading_info_df, arc_col, monk_col, diff_col, diff_in_abs_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_col = 'angle_opt_cur_end_to_nxt_ff'\n",
    "monk_col = 'angle_from_stop_to_nxt_ff'\n",
    "diff_col = 'diff_in_angle_to_nxt_ff'\n",
    "diff_in_abs_col = 'diff_in_abs_angle_to_nxt_ff'\n",
    "# plan_indicator_utils.plot_scatter_test_vs_ctrl(test_heading_info_df, ctrl_heading_info_df, arc_col, monk_col, diff_col, diff_in_abs_col)\n",
    "plan_indicator_utils.plot_hist_test_vs_ctrl(test_heading_info_df, ctrl_heading_info_df, arc_col, monk_col, diff_col, diff_in_abs_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a cumulative density distribution of test_heading_info_df['diff_in_abs_angle_to_nxt_ff']\n",
    "def plot_cdf(test_heading_info_df, ctrl_heading_info_df, column='diff_in_abs_angle_to_nxt_ff', xlim=None):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    sns.ecdfplot(data=test_heading_info_df[column], ax=ax, label='test')\n",
    "    sns.ecdfplot(data=ctrl_heading_info_df[column], ax=ax, label='ctrl')\n",
    "    ax.axhline(y=0.5, color='black', linestyle='--')\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cdf(test_heading_info_df, ctrl_heading_info_df, column='diff_in_abs_angle_to_nxt_ff', xlim=[-20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cdf(test_heading_info_df, ctrl_heading_info_df, column='diff_in_abs_d_curv', xlim=[-40, 40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## directly retrieve files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_process(df):\n",
    "    df['diff_in_angle_to_nxt_ff'] = df['angle_opt_arc_from_cur_end_to_nxt'] - \\\n",
    "        df['angle_from_m_before_stop_to_nxt_ff']\n",
    "    df['diff_in_abs_angle_to_nxt_ff'] = np.abs(\n",
    "        df['angle_opt_arc_from_cur_end_to_nxt']) - np.abs(df['angle_from_m_before_stop_to_nxt_ff'])\n",
    "    return df\n",
    "\n",
    "test_path = 'all_monkey_data/planning/monkey_Bruno/combined_data/cur_and_nxt/data/combd_heading_info/norm_opt_arc/test/Bruno_dist_100'\n",
    "ctrl_path = 'all_monkey_data/planning/monkey_Bruno/combined_data/cur_and_nxt/data/combd_heading_info/norm_opt_arc/control/Bruno_dist_100'\n",
    "\n",
    "test_df = pd.read_csv(test_path)\n",
    "ctrl_df = pd.read_csv(ctrl_path)\n",
    "\n",
    "test_df = temp_process(\n",
    "    test_df\n",
    ")\n",
    "ctrl_df = temp_process(\n",
    "    ctrl_df\n",
    ")\n",
    "\n",
    "test_df.head()\n",
    "ctrl_df.head()\n",
    "\n",
    "test_df['diff_in_abs_angle_to_nxt_ff'].values\n",
    "ctrl_df['diff_in_abs_angle_to_nxt_ff'].values\n",
    "# Perform permutation tests\n",
    "angle_p = plan_indicator_utils.permutation_test(\n",
    "    test_df['diff_in_abs_angle_to_nxt_ff'].values,\n",
    "    ctrl_df['diff_in_abs_angle_to_nxt_ff'].values,\n",
    "    num_permutations=10000,\n",
    "    alternative='greater'\n",
    ")\n",
    "angle_p\n",
    "stat, p = mannwhitneyu(test_df['diff_in_abs_angle_to_nxt_ff'].values, ctrl_df['diff_in_abs_angle_to_nxt_ff'].values, alternative='greater')\n",
    "print(stat, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "# Exp (PAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_factor_comp.add_dir_from_cur_ff_same_side(test_heading_info_df)\n",
    "build_factor_comp.add_dir_from_cur_ff_same_side(ctrl_heading_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc = (test_heading_info_df['dir_from_cur_ff_to_stop'] ==\n",
    "                test_heading_info_df['dir_from_cur_ff_to_nxt_ff']).sum()/len(test_heading_info_df)\n",
    "ctrl_perc = (ctrl_heading_info_df['dir_from_cur_ff_to_stop'] ==\n",
    "                ctrl_heading_info_df['dir_from_cur_ff_to_nxt_ff']).sum()/len(ctrl_heading_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc = (test_heading_info_df['dir_from_cur_ff_to_stop'] ==\n",
    "                test_heading_info_df['dir_from_cur_ff_to_nxt_ff']).sum()/len(test_heading_info_df)\n",
    "ctrl_perc = (ctrl_heading_info_df['dir_from_cur_ff_to_stop'] ==\n",
    "                ctrl_heading_info_df['dir_from_cur_ff_to_nxt_ff']).sum()/len(ctrl_heading_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for monkey_name in monkeys:\n",
    "    variations_list = specific_utils.init_variations_list_func(\n",
    "        ref_point_params,\n",
    "        monkey_name=monkey_name\n",
    "    )\n",
    "    \n",
    "    for _, row in variations_list.iterrows():\n",
    "        ref_point_mode = row['ref_point_mode']\n",
    "        ref_point_value = row['ref_point_value']\n",
    "        if verbose:\n",
    "            print(row)\n",
    "        \n",
    "        # Initialize sessions\n",
    "        planner = monkey_plan_factors_x_sess_class.PlanAcrossSessions(monkey_name=monkey_name)\n",
    "        planner.initialize_monkey_sessions_df_for_one_monkey()\n",
    "        planner.get_test_and_ctrl_heading_info_df_across_sessions(\n",
    "            ref_point_mode=ref_point_mode,\n",
    "            ref_point_value=ref_point_value,\n",
    "            save_data=False\n",
    "        )\n",
    "        \n",
    "        # Process test and control data\n",
    "        test_df = build_factor_comp.process_heading_info_df(\n",
    "            planner.test_heading_info_df.copy()\n",
    "        )\n",
    "        ctrl_df = build_factor_comp.process_heading_info_df(\n",
    "            planner.ctrl_heading_info_df.copy()\n",
    "        )\n",
    "        \n",
    "        # Filter NaNs for d_curv column\n",
    "        test_df_clean, ctrl_df_clean = filter_and_report_nan(\n",
    "            test_df, ctrl_df, col_name='diff_in_abs_angle_to_nxt_ff'\n",
    "        )\n",
    "        \n",
    "        # Run angle test directly on raw data (assumed no filtering needed)\n",
    "        angle_p = test_func_angle(\n",
    "            test_df_clean['diff_in_abs_angle_to_nxt_ff'].values,\n",
    "            ctrl_df_clean['diff_in_abs_angle_to_nxt_ff'].values\n",
    "        )\n",
    "        \n",
    "        # Filter NaNs for d_curv column\n",
    "        test_df_clean, ctrl_df_clean = filter_and_report_nan(\n",
    "            test_df, ctrl_df, col_name='diff_in_abs_d_curv'\n",
    "        )\n",
    "        \n",
    "        # Run d_curv test on cleaned data\n",
    "        d_curv_p = test_func_d_curv(\n",
    "            test_df_clean['diff_in_abs_d_curv'].values,\n",
    "            ctrl_df_clean['diff_in_abs_d_curv'].values\n",
    "        )\n",
    "        \n",
    "        # Collect results\n",
    "        results.append({\n",
    "            'monkey_name': monkey_name,\n",
    "            'ref_point_mode': ref_point_mode,\n",
    "            'ref_point_value': ref_point_value,\n",
    "            'angle_p_value': angle_p,\n",
    "            'd_curv_p_value': d_curv_p,\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
