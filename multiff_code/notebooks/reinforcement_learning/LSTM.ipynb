{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "KMRCk6qpFsyH",
   "metadata": {
    "id": "KMRCk6qpFsyH"
   },
   "source": [
    "Source of LSTM codes:\n",
    "https://github.com/quantumiracle/Popular-RL-Algorithms/blob/master/sac_v2_lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93C64_FAEoSJ",
   "metadata": {
    "id": "93C64_FAEoSJ"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f9c7f3",
   "metadata": {
    "id": "06f9c7f3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from data_wrangling import specific_utils, process_monkey_information, base_processing_class\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_points, make_ff_dataframe, ff_dataframe_utils, pattern_by_trials, pattern_by_points, cluster_analysis, organize_patterns_and_features, category_class\n",
    "from decision_making_analysis.cluster_replacement import cluster_replacement_utils, plot_cluster_replacement\n",
    "from decision_making_analysis.decision_making import decision_making_utils, plot_decision_making, intended_targets_classes\n",
    "from decision_making_analysis.GUAT import GUAT_helper_class, GUAT_collect_info_class, GUAT_combine_info_class, add_features_GUAT_and_TAFT\n",
    "from decision_making_analysis import free_selection, replacement, trajectory_info\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from null_behaviors import sample_null_distributions, show_null_trajectory\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils, hyperparam_tuning_class\n",
    "from reinforcement_learning.base_classes import env_utils, base_env, more_envs, rl_base_class, rl_base_utils\n",
    "from reinforcement_learning.agents.rnn import gru_utils, lstm_utils, lstm_utils, lstm_class\n",
    "from reinforcement_learning.agents.feedforward import interpret_neural_network, sb3_class, sb3_utils\n",
    "from eye_position_analysis import eye_positions\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import neural_data_modeling\n",
    "from decision_making_analysis.compare_GUAT_and_TAFT import find_GUAT_or_TAFT_trials\n",
    "from reinforcement_learning.agents.feedforward import interpret_neural_network, sb3_class, sb3_utils\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from gymnasium import spaces, Env\n",
    "import torch\n",
    "import optuna\n",
    "from numpy import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torch.linalg import vector_norm\n",
    "from IPython.display import HTML\n",
    "from functools import partial\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import gc\n",
    "from importlib import reload\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "device_idx = 0\n",
    "# device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "## if using Jupyter Notebook\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model_folder_name = \"multiff_analysis/RL_models/LSTM_stored_models/all_agents/gen_0/LSTM_Aug_1_24\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "PLAYER = \"agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c586e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user_data/cicid/Multifirefly-Project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b46a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/miniconda3/envs/multiff_clean/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7770be",
   "metadata": {},
   "source": [
    "# streamline everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b14d7",
   "metadata": {},
   "source": [
    "### oct_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8f636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_folder_name: RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2\n"
     ]
    }
   ],
   "source": [
    "overall_folder = 'multiff_analysis/RL_models/LSTM_stored_models/all_agents/oct_18_2/'\n",
    "env_kwargs = {'num_obs_ff': 7,\n",
    "              'add_action_to_obs': True,\n",
    "              'angular_terminal_vel': 0.05,\n",
    "              \"dt\": 0.1,\n",
    "              \"max_in_memory_time\": 2,\n",
    "            }   \n",
    "rl = lstm_class.LSTMforMultifirefly(overall_folder=overall_folder,\n",
    "                                                **env_kwargs)\n",
    "\n",
    "# rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "#                          best_model_postcurriculum_exists_ok=True)\n",
    "                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7beeae2",
   "metadata": {},
   "source": [
    "what seemed to work at last: clamping to avoid NA\n",
    "other changes made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa0eee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No family_of_agents_log existed. Made new family_of_agents_log\n",
      "Failed to load existing agent. Need to train a new agent. Error:  There was an error retrieving agent or replay_buffer in RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2. Error message Failed to load agent from RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2/best_model_in_curriculum because of failure to load checkpoint manifest\n",
      "Need to train a new best_model_postcurriculum\n",
      "Starting curriculum training\n",
      "Need to train a new best_model_in_curriculum\n",
      "Made env with the following kwargs: {'v_noise_std': 0.1, 'w_noise_std': 0.1, 'num_alive_ff': 200, 'flash_on_interval': 0.3, 'num_obs_ff': 7, 'max_in_memory_time': 2, 'invisible_distance': 500, 'make_ff_always_flash_on': False, 'reward_per_ff': 100, 'dv_cost_factor': 10, 'dw_cost_factor': 10, 'w_cost_factor': 3, 'distance2center_cost': 0, 'stop_vel_cost': 50, 'reward_boundary': 25, 'add_vel_cost_when_catching_ff_only': False, 'linear_terminal_vel': 0.01, 'angular_terminal_vel': 0.01, 'dt': 0.1, 'episode_len': 512, 'print_ff_capture_incidents': True, 'print_episode_reward_rates': True, 'add_action_to_obs': True, 'noise_mode': 'linear', 'slot_fields': None, 'obs_visible_only': False, 'zero_invisible_ff_features': False, 'use_prev_obs_for_invisible_pose': True, 'obs_noise': None, 'identity_slot_strategy': 'drop_fill'}\n",
      "Made initial env for curriculum training\n",
      "Soft Q Network (1,2):  QNetworkLSTM2(\n",
      "  (linear1): Linear(in_features=55, out_features=256, bias=True)\n",
      "  (lstm1): LSTM(256, 256, dropout=0.2)\n",
      "  (linear2): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Policy Network:  SAC_PolicyNetworkLSTM(\n",
      "  (linear1): Linear(in_features=51, out_features=256, bias=True)\n",
      "  (linear2): Linear(in_features=53, out_features=256, bias=True)\n",
      "  (lstm1): LSTM(256, 256, dropout=0.2)\n",
      "  (linear3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (mean_linear): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (log_std_linear): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cicid/miniconda3/envs/multiff_clean/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current reward_threshold to progress in curriculum training: 716.8000000000002\n",
      "TIME before resetting: 0\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "7.40 action: [-0.547 -0.987] n_targets: 2 reward: 88.61 cost_for_distance2center: 69.41 cost_for_stop_vel: 41.98\n",
      "18.60 action: [-0.63 -0.981] n_targets: 2 reward: 62.05 cost_for_distance2center: 89.50 cost_for_stop_vel: 48.46\n",
      "30.70 action: [-0.319 -0.99] n_targets: 3 reward: 140.94 cost_for_distance2center: 134.95 cost_for_stop_vel: 24.11\n",
      "Firely capture rate for the episode:  7 ff for 51.20000000000046 s: -------------------> 0.14\n",
      "Total reward for the episode:  291.599628534168\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [44.30709 44.30709 31.02386 31.02386 46.97924 46.97924 46.97924]\n",
      "Episode: 0, Episode Reward: 291.599628534168\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  1\n",
      "38.40 action: [0.602 -0.985] n_targets: 1 reward: 4.38 cost_for_distance2center: 49.34 cost_for_stop_vel: 46.28\n",
      "Firely capture rate for the episode:  1 ff for 51.20000000000046 s: -------------------> 0.02\n",
      "Total reward for the episode:  4.380812098582581\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [4.38081]\n",
      "Episode: 1, Episode Reward: 4.380812098582581\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  2\n",
      "19.40 action: [-0.108 -0.992] n_targets: 1 reward: 65.61 cost_for_distance2center: 26.72 cost_for_stop_vel: 7.67\n",
      "34.50 action: [-0.457 -0.992] n_targets: 1 reward: 27.79 cost_for_distance2center: 37.30 cost_for_stop_vel: 34.91\n",
      "Firely capture rate for the episode:  2 ff for 51.20000000000046 s: -------------------> 0.04\n",
      "Total reward for the episode:  93.39956696517766\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [65.60642 27.79315]\n",
      "Episode: 2, Episode Reward: 93.39956696517766\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  3\n",
      "18.20 action: [-0.042 -0.987] n_targets: 2 reward: 132.03 cost_for_distance2center: 65.50 cost_for_stop_vel: 2.47\n",
      "20.80 action: [-0.108 -0.983] n_targets: 1 reward: 78.90 cost_for_distance2center: 13.45 cost_for_stop_vel: 7.65\n",
      "42.20 action: [0.027 -0.993] n_targets: 1 reward: 87.50 cost_for_distance2center: 11.16 cost_for_stop_vel: 1.34\n",
      "Firely capture rate for the episode:  4 ff for 51.20000000000046 s: -------------------> 0.08\n",
      "Total reward for the episode:  298.4361452949233\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [66.01599 66.01599 78.90386 87.50031]\n",
      "Episode: 3, Episode Reward: 298.4361452949233\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  4\n",
      "1.30 action: [-0.181 -0.981] n_targets: 1 reward: 52.04 cost_for_distance2center: 34.63 cost_for_stop_vel: 13.33\n",
      "36.50 action: [0.326 -0.983] n_targets: 2 reward: 128.35 cost_for_distance2center: 46.97 cost_for_stop_vel: 24.68\n",
      "43.10 action: [-0.599 -0.99] n_targets: 1 reward: 45.94 cost_for_distance2center: 8.04 cost_for_stop_vel: 46.02\n",
      "Firely capture rate for the episode:  4 ff for 51.20000000000046 s: -------------------> 0.08\n",
      "Total reward for the episode:  226.3313656648\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [52.03926 64.17457 64.17457 45.94296]\n",
      "Episode: 4, Episode Reward: 226.33136566480002\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  5\n",
      "22.90 action: [0.48 -0.987] n_targets: 2 reward: 87.12 cost_for_distance2center: 76.19 cost_for_stop_vel: 36.70\n",
      "38.90 action: [0.594 -0.99] n_targets: 3 reward: 140.13 cost_for_distance2center: 114.28 cost_for_stop_vel: 45.60\n",
      "42.40 action: [0.426 -0.981] n_targets: 2 reward: 120.69 cost_for_distance2center: 46.81 cost_for_stop_vel: 32.49\n",
      "47.10 action: [0.101 -0.989] n_targets: 4 reward: 292.38 cost_for_distance2center: 100.50 cost_for_stop_vel: 7.12\n",
      "Firely capture rate for the episode:  11 ff for 51.20000000000046 s: -------------------> 0.21\n",
      "Total reward for the episode:  640.3194459447016\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [43.55797 43.55797 46.70878 46.70878 46.70878 60.3461  60.3461  73.09624\n",
      " 73.09624 73.09624 73.09624]\n",
      "Episode: 5, Episode Reward: 640.3194459447016\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  6\n",
      "6.30 action: [0.014 -0.988] n_targets: 1 reward: 51.08 cost_for_distance2center: 48.63 cost_for_stop_vel: 0.29\n",
      "Firely capture rate for the episode:  1 ff for 51.20000000000046 s: -------------------> 0.02\n",
      "Total reward for the episode:  51.08297913758239\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [51.08298]\n",
      "Episode: 6, Episode Reward: 51.08297913758239\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  7\n",
      "22.40 action: [0.525 -0.987] n_targets: 2 reward: 92.82 cost_for_distance2center: 66.93 cost_for_stop_vel: 40.25\n",
      "Firely capture rate for the episode:  2 ff for 51.20000000000046 s: -------------------> 0.04\n",
      "Total reward for the episode:  92.81888658056656\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [46.40944 46.40944]\n",
      "Episode: 7, Episode Reward: 92.81888658056656\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  8\n",
      "30.60 action: [-0.254 -0.99] n_targets: 1 reward: 35.79 cost_for_distance2center: 45.15 cost_for_stop_vel: 19.06\n",
      "Firely capture rate for the episode:  1 ff for 51.20000000000046 s: -------------------> 0.02\n",
      "Total reward for the episode:  35.785290191570915\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [35.78529]\n",
      "Episode: 8, Episode Reward: 35.785290191570915\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  9\n",
      "Firely capture rate for the episode:  0 ff for 51.20000000000046 s: -------------------> 0.0\n",
      "Total reward for the episode:  0.0\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  []\n",
      "Episode: 9, Episode Reward: 0.0\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  10\n",
      "7.90 action: [0.571 -0.992] n_targets: 1 reward: 12.72 cost_for_distance2center: 43.49 cost_for_stop_vel: 43.80\n",
      "11.20 action: [0.577 -0.998] n_targets: 1 reward: 15.45 cost_for_distance2center: 40.24 cost_for_stop_vel: 44.31\n",
      "15.90 action: [-0.379 -0.989] n_targets: 1 reward: 30.62 cost_for_distance2center: 40.57 cost_for_stop_vel: 28.80\n",
      "28.40 action: [0.357 -0.993] n_targets: 1 reward: 33.81 cost_for_distance2center: 39.10 cost_for_stop_vel: 27.09\n",
      "Firely capture rate for the episode:  4 ff for 51.20000000000046 s: -------------------> 0.08\n",
      "Total reward for the episode:  92.59353258212406\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [12.7159  15.44868 30.6235  33.80546]\n",
      "Episode: 10, Episode Reward: 92.59353258212406\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  11\n",
      "19.40 action: [-0.489 -0.986] n_targets: 1 reward: 38.84 cost_for_distance2center: 23.73 cost_for_stop_vel: 37.43\n",
      "Firely capture rate for the episode:  1 ff for 51.20000000000046 s: -------------------> 0.02\n",
      "Total reward for the episode:  38.84059267366925\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [38.84059]\n",
      "ALPHA (entropy-related):  tensor([0.8140], grad_fn=<ExpBackward0>)\n",
      "Last 10 ALPHA: [0.81398]\n",
      "Episode: 11, Episode Reward: 38.84059267366925\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  12\n",
      "27.80 action: [-0.377 -0.984] n_targets: 2 reward: 100.76 cost_for_distance2center: 70.61 cost_for_stop_vel: 28.63\n",
      "Firely capture rate for the episode:  2 ff for 51.20000000000046 s: -------------------> 0.04\n",
      "Total reward for the episode:  100.75844829777876\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [50.37922 50.37922]\n",
      "ALPHA (entropy-related):  tensor([0.6628], grad_fn=<ExpBackward0>)\n",
      "Last 10 ALPHA: [0.81398 0.66278]\n",
      "Episode: 12, Episode Reward: 100.75844829777876\n",
      "============================================================\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.64\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  2\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  3\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  75\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  13\n",
      "5.40 action: [0.018 -0.991] n_targets: 2 reward: 130.71 cost_for_distance2center: 68.69 cost_for_stop_vel: 0.59\n",
      "9.40 action: [0.042 -0.986] n_targets: 1 reward: 66.11 cost_for_distance2center: 31.42 cost_for_stop_vel: 2.47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/base_classes/rl_base_utils.py:157\u001b[39m, in \u001b[36mread_checkpoint_manifest\u001b[39m\u001b[34m(checkpoint_dir)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanifest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    158\u001b[39m         data = json.load(f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'multiff_analysis/RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2/best_model_postcurriculum/checkpoint_manifest.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:4\u001b[39m, in \u001b[36mload_agent\u001b[39m\u001b[34m(self, load_replay_buffer, dir_name)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/base_classes/rl_base_utils.py:164\u001b[39m, in \u001b[36mread_checkpoint_manifest\u001b[39m\u001b[34m(checkpoint_dir)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to read manifest at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanifest_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Failed to read manifest at RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2/best_model_postcurriculum/checkpoint_manifest.json: [Errno 2] No such file or directory: 'multiff_analysis/RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2/best_model_postcurriculum/checkpoint_manifest.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/base_classes/rl_base_class.py:158\u001b[39m, in \u001b[36m_RLforMultifirefly.curriculum_training\u001b[39m\u001b[34m(self, best_model_in_curriculum_exists_ok, best_model_postcurriculum_exists_ok, load_replay_buffer_of_best_model_postcurriculum)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_best_model_postcurriculum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_replay_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_replay_buffer_of_best_model_postcurriculum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mLoaded best_model_postcurriculum\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/agents/rnn/lstm_class.py:211\u001b[39m, in \u001b[36mload_best_model_postcurriculum\u001b[39m\u001b[34m(self, load_replay_buffer)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_best_model_postcurriculum\u001b[39m(\u001b[38;5;28mself\u001b[39m, load_replay_buffer=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# load_agent will recreate env and agent using saved manifest\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m.load_agent(load_replay_buffer=load_replay_buffer,\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m                     dir_name=\u001b[38;5;28mself\u001b[39m.best_model_postcurriculum_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:6\u001b[39m, in \u001b[36mload_agent\u001b[39m\u001b[34m(self, load_replay_buffer, dir_name)\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Failed to load agent from RL_models/LSTM_stored_models/all_agents/oct_18_2/dv10_dw10_w3_memT2/best_model_postcurriculum because of failure to load checkpoint manifest",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstreamline_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrentTrial_for_animation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trials_for_animation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mto_load_latest_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mbest_model_postcurriculum_exists_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mto_train_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:15\u001b[39m, in \u001b[36mstreamline_everything\u001b[39m\u001b[34m(self, currentTrial_for_animation, num_trials_for_animation, duration, n_steps, use_curriculum_training, load_replay_buffer_of_best_model_postcurriculum, best_model_in_curriculum_exists_ok, best_model_postcurriculum_exists_ok, to_load_latest_agent, load_replay_buffer, to_train_agent)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/base_classes/rl_base_class.py:569\u001b[39m, in \u001b[36mtrain_agent\u001b[39m\u001b[34m(self, use_curriculum_training, best_model_in_curriculum_exists_ok, best_model_postcurriculum_exists_ok, load_replay_buffer_of_best_model_postcurriculum, timesteps)\u001b[39m\n\u001b[32m    567\u001b[39m     print('Starting regular training')\n\u001b[32m    568\u001b[39m     self.regular_training(timesteps=timesteps)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m else:\n\u001b[32m    570\u001b[39m     self.curriculum_training(best_model_in_curriculum_exists_ok=best_model_in_curriculum_exists_ok,\n\u001b[32m    571\u001b[39m                              best_model_postcurriculum_exists_ok=best_model_postcurriculum_exists_ok,\n\u001b[32m    572\u001b[39m                              load_replay_buffer_of_best_model_postcurriculum=load_replay_buffer_of_best_model_postcurriculum)\n\u001b[32m    573\u001b[39m self.training_time = time_package.time()-self.training_start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/base_classes/rl_base_class.py:163\u001b[39m, in \u001b[36m_RLforMultifirefly.curriculum_training\u001b[39m\u001b[34m(self, best_model_in_curriculum_exists_ok, best_model_postcurriculum_exists_ok, load_replay_buffer_of_best_model_postcurriculum)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    162\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNeed to train a new best_model_postcurriculum\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_progress_in_curriculum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_in_curriculum_exists_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m._progress_in_curriculum(best_model_in_curriculum_exists_ok)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/base_classes/rl_base_class.py:196\u001b[39m, in \u001b[36m_RLforMultifirefly._progress_in_curriculum\u001b[39m\u001b[34m(self, best_model_in_curriculum_exists_ok)\u001b[39m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_agent_for_curriculum_training()\n\u001b[32m    195\u001b[39m \u001b[38;5;28mself\u001b[39m.successful_training = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_use_while_loop_for_curriculum_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.streamline_making_animation(currentTrial_for_animation=\u001b[38;5;28;01mNone\u001b[39;00m, num_trials_for_animation=\u001b[38;5;28;01mNone\u001b[39;00m, duration=[\u001b[32m10\u001b[39m, \u001b[32m40\u001b[39m], n_steps=\u001b[32m8000\u001b[39m,\n\u001b[32m    198\u001b[39m                                  video_dir=\u001b[38;5;28mself\u001b[39m.best_model_postcurriculum_dir)\n\u001b[32m    199\u001b[39m \u001b[38;5;28mself\u001b[39m.agent_id = \u001b[38;5;28mself\u001b[39m.original_agent_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/agents/rnn/lstm_class.py:124\u001b[39m, in \u001b[36mLSTMforMultifirefly._use_while_loop_for_curriculum_training\u001b[39m\u001b[34m(self, eval_eps_freq, num_eval_episodes)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    122\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mCurrent reward_threshold to progress in curriculum training:\u001b[39m\u001b[33m'\u001b[39m, reward_threshold)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# reward_threshold = 1000\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregular_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_eps_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_eps_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_eval_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mreward_threshold_to_stop_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreward_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mdir_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_model_in_curriculum_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.best_avg_reward_record < reward_threshold:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBest average reward record \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.best_avg_reward_record\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is less than reward threshold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33mt progress in curriculum training.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/agents/rnn/lstm_class.py:227\u001b[39m, in \u001b[36mregular_training\u001b[39m\u001b[34m(self, num_train_episodes, eval_eps_freq, num_eval_episodes, print_episode_reward, reward_threshold_to_stop_on, dir_name)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregular_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_train_episodes=\u001b[32m10000\u001b[39m, eval_eps_freq=\u001b[32m15\u001b[39m, num_eval_episodes=\u001b[32m2\u001b[39m,\n\u001b[32m    223\u001b[39m                      print_episode_reward=\u001b[38;5;28;01mTrue\u001b[39;00m, reward_threshold_to_stop_on=\u001b[38;5;28;01mNone\u001b[39;00m, dir_name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    224\u001b[39m     max_steps_per_eps = \u001b[38;5;28mself\u001b[39m.env.episode_len\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m.train_rnn_agent(\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m         \u001b[38;5;28mself\u001b[39m.env,\n\u001b[32m    228\u001b[39m         num_train_episodes=num_train_episodes,\n\u001b[32m    229\u001b[39m         eval_eps_freq=eval_eps_freq,\n\u001b[32m    230\u001b[39m         max_steps_per_eps=max_steps_per_eps,\n\u001b[32m    231\u001b[39m         num_eval_episodes=num_eval_episodes,\n\u001b[32m    232\u001b[39m         print_episode_reward=print_episode_reward,\n\u001b[32m    233\u001b[39m         reward_threshold_to_stop_on=reward_threshold_to_stop_on,\n\u001b[32m    234\u001b[39m         dir_name=dir_name,\n\u001b[32m    235\u001b[39m     )\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dir_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    237\u001b[39m         \u001b[38;5;28mself\u001b[39m.write_checkpoint_manifest(dir_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/agents/rnn/lstm_class.py:321\u001b[39m, in \u001b[36mtrain_rnn_agent\u001b[39m\u001b[34m(self, env, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_rnn_agent\u001b[39m(\u001b[38;5;28mself\u001b[39m, env, **kwargs):\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m._common_train_loop(\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m         env,\n\u001b[32m    322\u001b[39m         train_episode_fn=lstm_utils._train_episode,\n\u001b[32m    323\u001b[39m         eval_agent_fn=lstm_utils.evaluate_agent,\n\u001b[32m    324\u001b[39m         utils_module=lstm_utils,\n\u001b[32m    325\u001b[39m         save_fn=\u001b[38;5;28;01mlambda\u001b[39;00m model, dir_name: lstm_utils.save_best_model(model, dir_name=dir_name),\n\u001b[32m    326\u001b[39m         track_alpha=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    327\u001b[39m         **kwargs\n\u001b[32m    328\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/agents/rnn/lstm_class.py:266\u001b[39m, in \u001b[36m_common_train_loop\u001b[39m\u001b[34m(self, env, train_episode_fn, eval_agent_fn, num_train_episodes, eval_eps_freq, max_steps_per_eps, num_eval_episodes, print_episode_reward, reward_threshold_to_stop_on, dir_name, track_alpha, utils_module, save_fn)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_train_episodes):\n\u001b[32m    265\u001b[39m     episode_reward = train_episode_fn(env, \u001b[38;5;28mself\u001b[39m.sac_model, max_steps_per_eps)\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28mself\u001b[39m.list_of_epi_rewards.append(episode_reward)\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m track_alpha:\n\u001b[32m    269\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/reinforcement_learning/agents/rnn/lstm_utils.py:731\u001b[39m, in \u001b[36m_train_episode\u001b[39m\u001b[34m(env, sac_model, max_steps_per_eps)\u001b[39m\n\u001b[32m    728\u001b[39m         hidden_in = _initialize_hidden_state(\n\u001b[32m    729\u001b[39m             sac_model.hidden_dim, sac_model.device)\n\u001b[32m    730\u001b[39m \u001b[38;5;66;03m# Select action without tracking gradients and detach hidden state to avoid graph growth\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    732\u001b[39m     action, hidden_out = sac_model.policy_net.get_action(\n\u001b[32m    733\u001b[39m         state, last_action, hidden_in, deterministic=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# Reuse a detached hidden state at the next step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:52\u001b[39m, in \u001b[36mupdate\u001b[39m\u001b[34m(self, device)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multiff_clean/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multiff_clean/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/multiff_clean/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rl.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                         to_load_latest_agent=True,\n",
    "                         best_model_postcurriculum_exists_ok=True,\n",
    "                         to_train_agent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "214d789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.agent_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203ba7c",
   "metadata": {},
   "source": [
    "## see animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl.make_env(**rl.env_kwargs)\n",
    "# rl.make_agent()\n",
    "# # rl.make_initial_env_for_curriculum_training()\n",
    "# rl.load_best_model_postcurriculum()\n",
    "rl.streamline_making_animation(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40], n_steps=1000, video_dir=None)\n",
    "from IPython.display import Video\n",
    "Video(rl.video_path_name, embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f05e38",
   "metadata": {},
   "source": [
    "## manually eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c265c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(lstm_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47db700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.04\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  0.0\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  1.8000000000000005\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  25\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  163\n",
      "mean:  [[[-0.71876 -2.57102]]] z: [[[-0.642 -1.575]]] std:  [[[0.03852 0.15123]]]\n",
      "mean:  [[[-0.64712 -0.37392]]] z: [[[-1.23  -0.064]]] std:  [[[0.33664 0.62855]]]\n",
      "mean:  [[[-0.5936  -0.15418]]] z: [[[-0.53   0.283]]] std:  [[[0.1591  0.61161]]]\n",
      "mean:  [[[-0.08703  1.45505]]] z: [[[0.388 0.404]]] std:  [[[0.62828 0.55566]]]\n",
      "mean:  [[[-0.16764 -1.7622 ]]] z: [[[ 0.072 -0.182]]] std:  [[[0.13547 0.89373]]]\n",
      "mean:  [[[-0.05783  1.49112]]] z: [[[-1.637  0.617]]] std:  [[[0.65318 0.5465 ]]]\n",
      "mean:  [[[-0.13665 -2.1692 ]]] z: [[[-1.837  0.49 ]]] std:  [[[0.12362 0.95593]]]\n",
      "mean:  [[[-0.04758  1.50349]]] z: [[[-0.234  1.98 ]]] std:  [[[0.66375 0.54943]]]\n",
      "mean:  [[[-0.08193 -2.22325]]] z: [[[ 0.835 -0.89 ]]] std:  [[[0.13327 1.056  ]]]\n",
      "mean:  [[[-0.04986  1.4965 ]]] z: [[[-1.025 -1.174]]] std:  [[[0.67103 0.55761]]]\n",
      "mean:  [[[-0.06356 -2.26344]]] z: [[[-0.615 -0.278]]] std:  [[[0.13393 1.08415]]]\n",
      "mean:  [[[-0.04466  1.47889]]] z: [[[-0.359  1.922]]] std:  [[[0.66726 0.56759]]]\n",
      "mean:  [[[-0.05627 -2.28033]]] z: [[[-1.814  0.833]]] std:  [[[0.13477 1.09501]]]\n",
      "mean:  [[[-0.0431   1.48262]]] z: [[[ 0.419 -0.013]]] std:  [[[0.66678 0.56484]]]\n",
      "mean:  [[[-0.05813 -2.29219]]] z: [[[-0.536 -1.265]]] std:  [[[0.13647 1.11678]]]\n",
      "mean:  [[[-0.04117  1.47992]]] z: [[[2.891 0.332]]] std:  [[[0.66971 0.56456]]]\n",
      "mean:  [[[-0.0395 -2.2708]]] z: [[[ 0.893 -1.083]]] std:  [[[0.14009 1.13533]]]\n",
      "mean:  [[[-0.04054  1.45497]]] z: [[[0.028 1.756]]] std:  [[[0.66261 0.57714]]]\n",
      "mean:  [[[-0.02996 -2.241  ]]] z: [[[0.996 0.345]]] std:  [[[0.1425  1.10941]]]\n",
      "mean:  [[[-0.04804  1.44315]]] z: [[[-0.388 -1.627]]] std:  [[[0.66618 0.59352]]]\n",
      "mean:  [[[-0.07914 -2.3947 ]]] z: [[[-0.943 -2.399]]] std:  [[[0.13423 1.10839]]]\n",
      "mean:  [[[-0.03033  1.44588]]] z: [[[-0.309 -0.465]]] std:  [[[0.66833 0.59238]]]\n",
      "mean:  [[[-0.09197 -2.42297]]] z: [[[ 1.29  -1.511]]] std:  [[[0.13295 1.1393 ]]]\n",
      "mean:  [[[-0.02614  1.44667]]] z: [[[ 0.065 -0.155]]] std:  [[[0.66648 0.59501]]]\n",
      "mean:  [[[-0.06751 -2.34289]]] z: [[[-1.853  0.039]]] std:  [[[0.13748 1.12007]]]\n",
      "mean:  [[[-0.03213  1.42581]]] z: [[[-0.79   0.839]]] std:  [[[0.66635 0.60941]]]\n",
      "mean:  [[[-0.14227 -2.55061]]] z: [[[ 0.725 -0.246]]] std:  [[[0.12699 1.17526]]]\n",
      "mean:  [[[-0.00959  1.4343 ]]] z: [[[-1.82   0.287]]] std:  [[[0.66599 0.59217]]]\n",
      "mean:  [[[-0.10183 -2.43601]]] z: [[[-1.275 -1.575]]] std:  [[[0.13546 1.20319]]]\n",
      "mean:  [[[-0.02398  1.46535]]] z: [[[-1.011 -0.647]]] std:  [[[0.66776 0.5754 ]]]\n",
      "mean:  [[[-0.08829 -2.37892]]] z: [[[-1.976 -2.577]]] std:  [[[0.12544 1.14802]]]\n",
      "mean:  [[[-0.03182  1.471  ]]] z: [[[-0.774  1.146]]] std:  [[[0.66599 0.57301]]]\n",
      "mean:  [[[-0.07809 -2.34178]]] z: [[[1.107 0.188]]] std:  [[[0.12683 1.1299 ]]]\n",
      "mean:  [[[-0.03167  1.4708 ]]] z: [[[1.506 1.76 ]]] std:  [[[0.66546 0.57238]]]\n",
      "mean:  [[[-0.04105 -2.27966]]] z: [[[0.385 0.502]]] std:  [[[0.13717 1.15628]]]\n",
      "mean:  [[[-0.03147  1.43403]]] z: [[[ 0.68 -0.55]]] std:  [[[0.66751 0.5834 ]]]\n",
      "mean:  [[[-0.05299 -2.3213 ]]] z: [[[ 0.261 -0.75 ]]] std:  [[[0.12602 1.11323]]]\n",
      "mean:  [[[-0.03278  1.42532]]] z: [[[-0.831  0.053]]] std:  [[[0.66504 0.60223]]]\n",
      "mean:  [[[-0.00593 -2.17396]]] z: [[[ 1.649 -0.749]]] std:  [[[0.13477 1.08442]]]\n",
      "mean:  [[[-0.05406  1.471  ]]] z: [[[0.848 1.019]]] std:  [[[0.65673 0.56915]]]\n",
      "mean:  [[[-0.01049 -2.19328]]] z: [[[-0.693 -0.115]]] std:  [[[0.13196 1.08672]]]\n",
      "mean:  [[[-0.04899  1.45912]]] z: [[[0.55  0.388]]] std:  [[[0.65917 0.57554]]]\n",
      "mean:  [[[ 0.0025  -2.16611]]] z: [[[ 1.223 -1.099]]] std:  [[[0.13392 1.08593]]]\n",
      "mean:  [[[-0.05151  1.45544]]] z: [[[-0.722 -0.003]]] std:  [[[0.65804 0.57769]]]\n",
      "mean:  [[[ 0.02067 -2.10338]]] z: [[[-1.213 -2.023]]] std:  [[[0.13713 1.09643]]]\n",
      "mean:  [[[-0.04566  1.4727 ]]] z: [[[-0.412 -0.006]]] std:  [[[0.66143 0.56096]]]\n",
      "mean:  [[[ 0.02621 -2.11614]]] z: [[[0.366 0.591]]] std:  [[[0.13968 1.10822]]]\n",
      "mean:  [[[-0.06363  1.44629]]] z: [[[ 0.096 -0.245]]] std:  [[[0.65725 0.59395]]]\n",
      "mean:  [[[-0.06712 -2.36877]]] z: [[[0.132 1.059]]] std:  [[[0.12712 1.07432]]]\n",
      "mean:  [[[-0.0353   1.44621]]] z: [[[-1.158  1.829]]] std:  [[[0.66773 0.59358]]]\n",
      "mean:  [[[-0.05402 -2.31963]]] z: [[[-0.538 -0.465]]] std:  [[[0.1317  1.10754]]]\n",
      "mean:  [[[-0.04263  1.44372]]] z: [[[-0.718  0.039]]] std:  [[[0.66526 0.59507]]]\n",
      "mean:  [[[-0.05355 -2.30703]]] z: [[[ 0.031 -1.154]]] std:  [[[0.13214 1.09405]]]\n",
      "mean:  [[[-0.04164  1.45516]]] z: [[[-0.801  0.098]]] std:  [[[0.67217 0.58575]]]\n",
      "mean:  [[[-0.07411 -2.3558 ]]] z: [[[-0.084 -0.647]]] std:  [[[0.1229  1.10418]]]\n",
      "mean:  [[[-0.03781  1.47364]]] z: [[[ 0.512 -0.389]]] std:  [[[0.67051 0.57642]]]\n",
      "mean:  [[[-0.10241 -2.4334 ]]] z: [[[0.477 0.814]]] std:  [[[0.11958 1.12818]]]\n",
      "mean:  [[[-0.02981  1.47269]]] z: [[[ 0.099 -0.145]]] std:  [[[0.66891 0.57912]]]\n",
      "mean:  [[[-0.08803 -2.37918]]] z: [[[-0.528  0.96 ]]] std:  [[[0.12281 1.12074]]]\n",
      "mean:  [[[-0.0365   1.47148]]] z: [[[-0.44   0.827]]] std:  [[[0.66823 0.57843]]]\n",
      "mean:  [[[-0.10023 -2.41   ]]] z: [[[-0.122 -0.114]]] std:  [[[0.1197  1.12154]]]\n",
      "mean:  [[[-0.03196  1.477  ]]] z: [[[ 0.441 -0.318]]] std:  [[[0.66354 0.5702 ]]]\n",
      "mean:  [[[-0.05926 -2.3101 ]]] z: [[[1.346 0.292]]] std:  [[[0.12516 1.12719]]]\n",
      "mean:  [[[-0.03209  1.41286]]] z: [[[ 2.736 -0.576]]] std:  [[[0.66886 0.62366]]]\n",
      "mean:  [[[-0.07405 -2.36467]]] z: [[[-0.242  0.252]]] std:  [[[0.124   1.09982]]]\n",
      "mean:  [[[-0.03     1.41908]]] z: [[[-2.349 -0.035]]] std:  [[[0.67514 0.61746]]]\n",
      "mean:  [[[ 0.02524 -2.11545]]] z: [[[-0.334 -0.15 ]]] std:  [[[0.1337  1.09319]]]\n",
      "mean:  [[[-0.03832  1.48337]]] z: [[[ 0.648 -1.827]]] std:  [[[0.66047 0.56438]]]\n",
      "mean:  [[[ 0.02504 -2.12488]]] z: [[[-0.121 -0.208]]] std:  [[[0.13106 1.1242 ]]]\n",
      "mean:  [[[-0.03362  1.46973]]] z: [[[ 0.083 -2.974]]] std:  [[[0.66132 0.57072]]]\n",
      "mean:  [[[-0.01113 -2.26177]]] z: [[[ 0.154 -0.945]]] std:  [[[0.12212 1.11578]]]\n",
      "mean:  [[[-0.02796  1.39528]]] z: [[[0.393 1.23 ]]] std:  [[[0.66064 0.62318]]]\n",
      "mean:  [[[ 0.00126 -2.25758]]] z: [[[-0.213  1.57 ]]] std:  [[[0.1347  1.10119]]]\n",
      "mean:  [[[-0.03721  1.43259]]] z: [[[-2.004  0.478]]] std:  [[[0.66616 0.58472]]]\n",
      "mean:  [[[-0.00185 -2.25362]]] z: [[[ 1.87  -0.369]]] std:  [[[0.13674 1.14609]]]\n",
      "mean:  [[[-0.03514  1.41471]]] z: [[[-1.074  0.45 ]]] std:  [[[0.66592 0.59449]]]\n",
      "mean:  [[[-0.01036 -2.27347]]] z: [[[-0.414  0.046]]] std:  [[[0.13565 1.1408 ]]]\n",
      "mean:  [[[-0.04627  1.42488]]] z: [[[-1.163 -0.422]]] std:  [[[0.65895 0.59136]]]\n",
      "mean:  [[[-0.00557 -2.25324]]] z: [[[-0.59  -1.486]]] std:  [[[0.13733 1.12325]]]\n",
      "mean:  [[[-0.04771  1.42389]]] z: [[[ 0.71  -0.062]]] std:  [[[0.65844 0.59293]]]\n",
      "mean:  [[[-0.03848 -2.31421]]] z: [[[ 1.249 -0.641]]] std:  [[[0.13342 1.06076]]]\n",
      "8.10 action: [-0.038 -0.981] n_targets: 1 reward: 64.42 cost_for_stop_vel: 35.58\n",
      "mean:  [[[-0.02102  1.3943 ]]] z: [[[-0.14   1.063]]] std:  [[[0.66266 0.63924]]]\n",
      "mean:  [[[ 0.00124 -2.25849]]] z: [[[0.454 1.888]]] std:  [[[0.14591 1.11354]]]\n",
      "mean:  [[[-0.0288   1.39461]]] z: [[[1.248 0.467]]] std:  [[[0.65303 0.61566]]]\n",
      "mean:  [[[-0.00343 -2.26955]]] z: [[[-0.879 -0.229]]] std:  [[[0.14532 1.10226]]]\n",
      "mean:  [[[-0.01833  1.39143]]] z: [[[-0.919 -1.076]]] std:  [[[0.64961 0.60805]]]\n",
      "mean:  [[[ 0.03556 -2.18358]]] z: [[[-2.011  0.101]]] std:  [[[0.15325 1.12872]]]\n",
      "mean:  [[[-0.01783  1.3832 ]]] z: [[[-0.602 -0.867]]] std:  [[[0.64478 0.60743]]]\n",
      "mean:  [[[ 0.02037 -2.21737]]] z: [[[-0.001 -0.811]]] std:  [[[0.15107 1.12218]]]\n",
      "mean:  [[[0.03317 1.30895]]] z: [[[0.445 0.293]]] std:  [[[0.64672 0.62746]]]\n",
      "mean:  [[[ 0.21627 -1.79722]]] z: [[[ 0.673 -0.088]]] std:  [[[0.17745 1.41967]]]\n",
      "mean:  [[[0.36163 1.24766]]] z: [[[0.703 0.289]]] std:  [[[0.74105 0.63598]]]\n",
      "mean:  [[[ 0.35124 -1.66744]]] z: [[[0.001 1.3  ]]] std:  [[[0.26626 2.07337]]]\n",
      "mean:  [[[0.5061  0.92962]]] z: [[[0.566 0.363]]] std:  [[[0.76558 0.68989]]]\n",
      "mean:  [[[ 0.35323 -1.62754]]] z: [[[0.575 1.519]]] std:  [[[0.26844 1.94883]]]\n",
      "mean:  [[[0.40147 1.03885]]] z: [[[-0.581  0.776]]] std:  [[[0.90798 0.69716]]]\n",
      "mean:  [[[ 0.39835 -1.59488]]] z: [[[-0.79   0.937]]] std:  [[[0.32205 2.10029]]]\n",
      "mean:  [[[0.40358 0.73536]]] z: [[[-0.644 -0.018]]] std:  [[[0.91683 0.78916]]]\n",
      "mean:  [[[ 0.34355 -1.54198]]] z: [[[0.123 0.566]]] std:  [[[0.24902 1.73304]]]\n",
      "mean:  [[[0.39636 1.13735]]] z: [[[-1.24  -1.312]]] std:  [[[0.88348 0.67486]]]\n",
      "mean:  [[[ 0.38156 -1.70041]]] z: [[[-1.232  0.288]]] std:  [[[0.32287 2.08943]]]\n",
      "mean:  [[[0.4436 0.7101]]] z: [[[ 0.942 -0.019]]] std:  [[[0.96066 0.81589]]]\n",
      "mean:  [[[ 0.47493 -1.62278]]] z: [[[ 1.468 -1.38 ]]] std:  [[[0.29675 2.05024]]]\n",
      "mean:  [[[0.46295 0.99575]]] z: [[[0.504 0.09 ]]] std:  [[[1.02983 0.75491]]]\n",
      "mean:  [[[ 0.57324 -1.94177]]] z: [[[-1.825  1.662]]] std:  [[[0.26441 2.66429]]]\n",
      "mean:  [[[0.66472 1.53488]]] z: [[[-0.125  1.21 ]]] std:  [[[1.48583 0.51939]]]\n",
      "mean:  [[[ 0.40187 -1.87073]]] z: [[[ 0.814 -2.014]]] std:  [[[0.20582 3.81549]]]\n",
      "mean:  [[[0.70101 1.62709]]] z: [[[-0.157  1.481]]] std:  [[[1.35824 0.51665]]]\n",
      "mean:  [[[ 0.44842 -1.95358]]] z: [[[0.966 0.54 ]]] std:  [[[0.20998 2.35591]]]\n",
      "mean:  [[[0.43824 1.23842]]] z: [[[2.511 0.621]]] std:  [[[1.38234 0.59353]]]\n",
      "mean:  [[[ 0.10911 -1.83397]]] z: [[[-0.037  0.358]]] std:  [[[0.17726 1.63207]]]\n",
      "mean:  [[[0.05331 1.35046]]] z: [[[-0.599  0.725]]] std:  [[[0.64166 0.59894]]]\n",
      "mean:  [[[-0.04553 -2.38463]]] z: [[[-0.132  0.645]]] std:  [[[0.13076 1.11647]]]\n",
      "mean:  [[[-0.01873  1.43668]]] z: [[[-2.055  0.204]]] std:  [[[0.68301 0.59   ]]]\n",
      "mean:  [[[-0.05168 -2.39973]]] z: [[[0.148 1.589]]] std:  [[[0.12882 1.15489]]]\n",
      "mean:  [[[-0.01664  1.41969]]] z: [[[-1.319 -0.352]]] std:  [[[0.68703 0.60033]]]\n",
      "mean:  [[[-0.05884 -2.4178 ]]] z: [[[ 0.87  -0.569]]] std:  [[[0.12699 1.15423]]]\n",
      "mean:  [[[-0.01632  1.42366]]] z: [[[-0.022  0.481]]] std:  [[[0.68501 0.59957]]]\n",
      "mean:  [[[-0.03536 -2.34271]]] z: [[[-0.992 -0.621]]] std:  [[[0.13013 1.13429]]]\n",
      "11.90 action: [-0.035 -0.982] n_targets: 1 reward: 68.32 cost_for_stop_vel: 31.68\n",
      "mean:  [[[-0.02658  1.44518]]] z: [[[1.1   0.915]]] std:  [[[0.68165 0.58424]]]\n",
      "mean:  [[[-0.08066 -2.44746]]] z: [[[ 1.076 -1.043]]] std:  [[[0.12539 1.17776]]]\n",
      "mean:  [[[-0.00919  1.44148]]] z: [[[-0.759  2.169]]] std:  [[[0.67795 0.58322]]]\n",
      "mean:  [[[-0.01919 -2.29376]]] z: [[[-0.169  0.901]]] std:  [[[0.13684 1.19122]]]\n",
      "mean:  [[[-0.02201  1.4105 ]]] z: [[[1.921 3.086]]] std:  [[[0.67508 0.59909]]]\n",
      "mean:  [[[-0.03455 -2.32716]]] z: [[[-0.908 -1.297]]] std:  [[[0.13299 1.15219]]]\n",
      "mean:  [[[-0.02142  1.42013]]] z: [[[ 0.159 -0.036]]] std:  [[[0.67325 0.595  ]]]\n",
      "mean:  [[[-0.01257 -2.253  ]]] z: [[[-0.645 -0.241]]] std:  [[[0.13612 1.13221]]]\n",
      "mean:  [[[-0.03373  1.42713]]] z: [[[ 0.594 -1.812]]] std:  [[[0.66918 0.59083]]]\n",
      "mean:  [[[-0.01018 -2.24903]]] z: [[[-0.751 -0.622]]] std:  [[[0.14097 1.14475]]]\n",
      "mean:  [[[-0.0272   1.39807]]] z: [[[-0.39  -0.596]]] std:  [[[0.6579  0.60511]]]\n",
      "mean:  [[[ 0.04499 -2.13875]]] z: [[[ 0.316 -0.717]]] std:  [[[0.14281 1.11602]]]\n",
      "mean:  [[[-0.01985  1.43258]]] z: [[[-0.065 -1.435]]] std:  [[[0.66095 0.58183]]]\n",
      "mean:  [[[ 0.03654 -2.14912]]] z: [[[0.889 0.394]]] std:  [[[0.14578 1.17492]]]\n",
      "mean:  [[[-0.01659  1.40954]]] z: [[[-0.214 -0.813]]] std:  [[[0.65867 0.59094]]]\n",
      "mean:  [[[ 0.01351 -2.22909]]] z: [[[ 0.184 -0.662]]] std:  [[[0.14257 1.15795]]]\n",
      "mean:  [[[-0.024    1.38405]]] z: [[[-0.599  1.533]]] std:  [[[0.66308 0.61044]]]\n",
      "mean:  [[[ 0.00277 -2.24638]]] z: [[[1.31  0.857]]] std:  [[[0.14166 1.13218]]]\n",
      "mean:  [[[-0.02419  1.38651]]] z: [[[1.347 1.38 ]]] std:  [[[0.66409 0.61068]]]\n",
      "mean:  [[[-0.0071  -2.26401]]] z: [[[-0.587 -0.92 ]]] std:  [[[0.1405  1.13089]]]\n",
      "mean:  [[[-0.02131  1.38695]]] z: [[[-1.212 -0.498]]] std:  [[[0.6633  0.61269]]]\n",
      "mean:  [[[-0.0607  -2.35801]]] z: [[[-0.967 -1.964]]] std:  [[[0.1243  1.08013]]]\n",
      "mean:  [[[-0.02803  1.42671]]] z: [[[1.056 1.179]]] std:  [[[0.67478 0.6059 ]]]\n",
      "mean:  [[[-0.08423 -2.38437]]] z: [[[-1.685 -1.241]]] std:  [[[0.12343 1.10193]]]\n",
      "mean:  [[[-0.02453  1.42284]]] z: [[[-1.607  0.041]]] std:  [[[0.67601 0.60811]]]\n",
      "mean:  [[[-0.08165 -2.38073]]] z: [[[-0.752 -0.157]]] std:  [[[0.12633 1.11361]]]\n",
      "mean:  [[[-0.02485  1.41962]]] z: [[[0.79  0.481]]] std:  [[[0.67526 0.61269]]]\n",
      "mean:  [[[-0.05967 -2.32737]]] z: [[[ 2.139 -0.04 ]]] std:  [[[0.12822 1.09448]]]\n",
      "mean:  [[[-0.03368  1.41802]]] z: [[[ 0.772 -0.272]]] std:  [[[0.68413 0.61799]]]\n",
      "mean:  [[[-0.08795 -2.38039]]] z: [[[-1.701  0.597]]] std:  [[[0.12007 1.0759 ]]]\n",
      "mean:  [[[-0.02869  1.43249]]] z: [[[ 1.423 -0.666]]] std:  [[[0.68001 0.60632]]]\n",
      "mean:  [[[-0.07377 -2.30394]]] z: [[[-1.235  1.409]]] std:  [[[0.12829 1.15003]]]\n",
      "mean:  [[[0.009   1.42025]]] z: [[[1.639 0.004]]] std:  [[[0.67089 0.59568]]]\n",
      "mean:  [[[-0.06829 -2.37231]]] z: [[[0.328 0.041]]] std:  [[[0.12188 1.03905]]]\n",
      "mean:  [[[-0.04976  1.50939]]] z: [[[-0.904  1.812]]] std:  [[[0.66228 0.55906]]]\n",
      "mean:  [[[ 0.01144 -2.12781]]] z: [[[1.377 0.134]]] std:  [[[0.13602 1.05587]]]\n",
      "mean:  [[[-0.06294  1.49643]]] z: [[[-0.518  1.362]]] std:  [[[0.66083 0.56071]]]\n",
      "mean:  [[[-0.0012  -2.16574]]] z: [[[0.959 0.189]]] std:  [[[0.13307 1.04263]]]\n",
      "mean:  [[[-0.05808  1.49447]]] z: [[[1.192 1.247]]] std:  [[[0.66145 0.56169]]]\n",
      "mean:  [[[ 0.01293 -2.1253 ]]] z: [[[ 0.755 -1.308]]] std:  [[[0.13644 1.04938]]]\n",
      "mean:  [[[-0.06245  1.47571]]] z: [[[ 0.33  -1.058]]] std:  [[[0.65891 0.5795 ]]]\n",
      "mean:  [[[-0.00717 -2.17914]]] z: [[[0.073 1.882]]] std:  [[[0.13491 1.02644]]]\n",
      "mean:  [[[-0.05489  1.44669]]] z: [[[ 0.114 -0.909]]] std:  [[[0.65375 0.60027]]]\n",
      "mean:  [[[ 0.00545 -2.15622]]] z: [[[-0.632  0.41 ]]] std:  [[[0.14249 1.03238]]]\n",
      "mean:  [[[-0.06137  1.45774]]] z: [[[-0.546 -1.297]]] std:  [[[0.65941 0.59068]]]\n",
      "mean:  [[[-0.00229 -2.18589]]] z: [[[0.027 2.805]]] std:  [[[0.13634 1.02607]]]\n",
      "mean:  [[[-0.05054  1.46677]]] z: [[[-1.566 -0.905]]] std:  [[[0.65679 0.57785]]]\n",
      "mean:  [[[-0.03751 -2.268  ]]] z: [[[ 0.171 -0.623]]] std:  [[[0.13602 1.08418]]]\n",
      "mean:  [[[-0.03789  1.45709]]] z: [[[-0.225 -0.291]]] std:  [[[0.65999 0.58276]]]\n",
      "mean:  [[[-0.02287 -2.23195]]] z: [[[-1.362  0.184]]] std:  [[[0.13892 1.08717]]]\n",
      "mean:  [[[-0.04356  1.45818]]] z: [[[ 0.597 -0.651]]] std:  [[[0.65808 0.58092]]]\n",
      "mean:  [[[-0.01919 -2.22384]]] z: [[[-0.824 -0.604]]] std:  [[[0.13938 1.08162]]]\n",
      "mean:  [[[-0.04968  1.45643]]] z: [[[ 1.932 -0.428]]] std:  [[[0.66554 0.58091]]]\n",
      "mean:  [[[-0.05842 -2.34113]]] z: [[[-0.124  1.15 ]]] std:  [[[0.13623 1.11604]]]\n",
      "mean:  [[[-0.03476  1.44775]]] z: [[[ 0.874 -1.697]]] std:  [[[0.66907 0.59476]]]\n",
      "mean:  [[[-0.05056 -2.31073]]] z: [[[ 0.508 -0.069]]] std:  [[[0.13989 1.11466]]]\n",
      "mean:  [[[-0.04046  1.45108]]] z: [[[0.532 0.828]]] std:  [[[0.66288 0.58563]]]\n",
      "mean:  [[[-0.05774 -2.32266]]] z: [[[-0.608  0.717]]] std:  [[[0.1389  1.10905]]]\n",
      "mean:  [[[-0.03878  1.45171]]] z: [[[-0.923  1.434]]] std:  [[[0.66212 0.5869 ]]]\n",
      "mean:  [[[-0.04336 -2.2998 ]]] z: [[[ 0.537 -0.624]]] std:  [[[0.13524 1.11762]]]\n",
      "mean:  [[[-0.0384  1.4475]]] z: [[[-1.747 -0.279]]] std:  [[[0.66884 0.58314]]]\n",
      "mean:  [[[-0.07189 -2.38309]]] z: [[[-0.723  0.944]]] std:  [[[0.12362 1.1187 ]]]\n",
      "mean:  [[[-0.02357  1.43034]]] z: [[[-0.958 -1.075]]] std:  [[[0.67527 0.59867]]]\n",
      "mean:  [[[-0.06415 -2.37079]]] z: [[[-0.255  0.777]]] std:  [[[0.12573 1.13274]]]\n",
      "mean:  [[[-0.02579  1.42138]]] z: [[[-0.009 -1.076]]] std:  [[[0.67455 0.60675]]]\n",
      "mean:  [[[-0.07084 -2.37949]]] z: [[[-1.142 -0.368]]] std:  [[[0.12419 1.12258]]]\n",
      "mean:  [[[-0.02493  1.42068]]] z: [[[0.807 0.719]]] std:  [[[0.67422 0.60936]]]\n",
      "mean:  [[[-0.07134 -2.37678]]] z: [[[1.315 1.68 ]]] std:  [[[0.12345 1.11717]]]\n",
      "mean:  [[[-0.02626  1.42132]]] z: [[[-1.089  1.876]]] std:  [[[0.67306 0.60785]]]\n",
      "mean:  [[[-0.0647  -2.34669]]] z: [[[ 0.219 -1.109]]] std:  [[[0.12459 1.10824]]]\n",
      "mean:  [[[-0.02947  1.41912]]] z: [[[ 0.374 -0.845]]] std:  [[[0.67251 0.61099]]]\n",
      "mean:  [[[-0.04743 -2.29688]]] z: [[[-1.033  1.671]]] std:  [[[0.12177 1.09554]]]\n",
      "mean:  [[[-0.02707  1.43405]]] z: [[[ 0.364 -0.403]]] std:  [[[0.6756  0.59385]]]\n",
      "mean:  [[[-0.06959 -2.39284]]] z: [[[-1.761 -1.477]]] std:  [[[0.11094 1.13286]]]\n",
      "mean:  [[[-0.01992  1.42678]]] z: [[[ 1.757 -0.48 ]]] std:  [[[0.68005 0.60643]]]\n",
      "mean:  [[[-0.08481 -2.441  ]]] z: [[[-0.03  -1.632]]] std:  [[[0.10758 1.12626]]]\n",
      "mean:  [[[-0.01731  1.42285]]] z: [[[0.118 0.9  ]]] std:  [[[0.67951 0.61074]]]\n",
      "mean:  [[[-0.08064 -2.44361]]] z: [[[0.335 2.721]]] std:  [[[0.1069  1.18097]]]\n",
      "mean:  [[[-0.00362  1.39249]]] z: [[[-0.94  0.72]]] std:  [[[0.66915 0.62373]]]\n",
      "mean:  [[[-0.11413 -2.58314]]] z: [[[-1.121 -0.345]]] std:  [[[0.09957 1.21051]]]\n",
      "mean:  [[[0.00568 1.3222 ]]] z: [[[-0.524  1.393]]] std:  [[[0.67977 0.69759]]]\n",
      "mean:  [[[-0.07784 -2.42663]]] z: [[[-0.632 -0.472]]] std:  [[[0.12226 1.20579]]]\n",
      "mean:  [[[0.00651 1.34041]]] z: [[[-0.859 -1.474]]] std:  [[[0.671   0.65405]]]\n",
      "mean:  [[[-0.11708 -2.5729 ]]] z: [[[-1.051 -0.777]]] std:  [[[0.11575 1.25141]]]\n",
      "mean:  [[[0.01697 1.35033]]] z: [[[0.561 1.037]]] std:  [[[0.66489 0.6503 ]]]\n",
      "mean:  [[[-0.10013 -2.48879]]] z: [[[0.181 0.089]]] std:  [[[0.11998 1.25428]]]\n",
      "mean:  [[[0.00894 1.39802]]] z: [[[ 0.958 -2.213]]] std:  [[[0.66211 0.61022]]]\n",
      "mean:  [[[-0.03675 -2.34253]]] z: [[[-1.596  1.171]]] std:  [[[0.13122 1.29052]]]\n",
      "mean:  [[[0.01685 1.32967]]] z: [[[-1.705  0.936]]] std:  [[[0.65912 0.63584]]]\n",
      "mean:  [[[-0.06608 -2.42682]]] z: [[[0.176 1.436]]] std:  [[[0.1184  1.21214]]]\n",
      "mean:  [[[0.0054  1.39688]]] z: [[[0.82  0.399]]] std:  [[[0.66425 0.60919]]]\n",
      "mean:  [[[-0.04811 -2.36554]]] z: [[[ 1.548 -1.831]]] std:  [[[0.12087 1.24057]]]\n",
      "mean:  [[[0.00395 1.38185]]] z: [[[-0.154 -2.407]]] std:  [[[0.66327 0.61595]]]\n",
      "mean:  [[[-0.05604 -2.38659]]] z: [[[ 0.079 -0.638]]] std:  [[[0.11813 1.22069]]]\n",
      "mean:  [[[0.00284 1.38646]]] z: [[[-0.06  -0.439]]] std:  [[[0.66203 0.61394]]]\n",
      "mean:  [[[-0.04321 -2.34034]]] z: [[[ 1.904 -1.283]]] std:  [[[0.11989 1.20552]]]\n",
      "mean:  [[[-0.00188  1.38594]]] z: [[[-1.276  0.53 ]]] std:  [[[0.65932 0.61393]]]\n",
      "mean:  [[[-0.03328 -2.29856]]] z: [[[-0.442  0.825]]] std:  [[[0.12127 1.18025]]]\n",
      "mean:  [[[-0.03492  1.477  ]]] z: [[[ 1.393 -1.103]]] std:  [[[0.65378 0.56943]]]\n",
      "mean:  [[[ 0.00091 -2.15188]]] z: [[[-2.507  0.272]]] std:  [[[0.13294 1.14064]]]\n",
      "mean:  [[[-0.04129  1.44496]]] z: [[[ 0.215 -0.69 ]]] std:  [[[0.64759 0.57676]]]\n",
      "mean:  [[[ 0.02052 -2.11602]]] z: [[[1.371 0.39 ]]] std:  [[[0.13277 1.13247]]]\n",
      "mean:  [[[-0.03548  1.45808]]] z: [[[ 1.229 -0.389]]] std:  [[[0.64717 0.5692 ]]]\n",
      "mean:  [[[ 0.02888 -2.09221]]] z: [[[-3.381  0.072]]] std:  [[[0.1341  1.15444]]]\n",
      "mean:  [[[-0.03848  1.45461]]] z: [[[0.68  0.401]]] std:  [[[0.64181 0.5738 ]]]\n",
      "mean:  [[[ 0.03679 -2.08993]]] z: [[[-0.242 -0.884]]] std:  [[[0.13803 1.1098 ]]]\n",
      "mean:  [[[-0.04957  1.51419]]] z: [[[0.181 1.646]]] std:  [[[0.65056 0.56302]]]\n",
      "mean:  [[[-0.00867 -2.23157]]] z: [[[-0.56 -1.32]]] std:  [[[0.12891 1.08566]]]\n",
      "mean:  [[[-0.05226  1.49561]]] z: [[[-1.423 -0.364]]] std:  [[[0.65772 0.56972]]]\n",
      "mean:  [[[-0.0564  -2.39462]]] z: [[[-1.988 -0.613]]] std:  [[[0.1192  1.09805]]]\n",
      "mean:  [[[-0.04012  1.46199]]] z: [[[-0.124  0.743]]] std:  [[[0.66963 0.58027]]]\n",
      "mean:  [[[-0.05036 -2.38837]]] z: [[[-0.375  0.12 ]]] std:  [[[0.12687 1.13165]]]\n",
      "mean:  [[[-0.04082  1.45406]]] z: [[[0.626 0.844]]] std:  [[[0.67014 0.58375]]]\n",
      "mean:  [[[-0.04171 -2.35807]]] z: [[[ 1.399 -0.179]]] std:  [[[0.12917 1.12704]]]\n",
      "mean:  [[[-0.04402  1.45449]]] z: [[[-0.811  0.249]]] std:  [[[0.66858 0.58333]]]\n",
      "mean:  [[[-0.02067 -2.31009]]] z: [[[-2.235  0.833]]] std:  [[[0.1336  1.14198]]]\n",
      "23.50 action: [-0.021 -0.98] n_targets: 1 reward: 86.67 cost_for_stop_vel: 13.33\n",
      "mean:  [[[-0.04537  1.44896]]] z: [[[-0.774  0.517]]] std:  [[[0.65969 0.58561]]]\n",
      "mean:  [[[-0.05063 -2.4031 ]]] z: [[[0.88  0.088]]] std:  [[[0.12992 1.12831]]]\n",
      "mean:  [[[-0.03345  1.43712]]] z: [[[1.242 0.602]]] std:  [[[0.65827 0.60719]]]\n",
      "mean:  [[[-0.09151 -2.49816]]] z: [[[-0.349 -0.883]]] std:  [[[0.1182  1.13627]]]\n",
      "mean:  [[[-0.0329   1.48842]]] z: [[[ 1.527 -0.717]]] std:  [[[0.64884 0.57793]]]\n",
      "mean:  [[[-0.06936 -2.41246]]] z: [[[-0.068 -1.403]]] std:  [[[0.12159 1.14838]]]\n",
      "mean:  [[[-0.041    1.48122]]] z: [[[ 1.823 -0.998]]] std:  [[[0.64928 0.58309]]]\n",
      "mean:  [[[-0.06285 -2.39942]]] z: [[[0.081 0.269]]] std:  [[[0.11903 1.13533]]]\n",
      "mean:  [[[-0.02839  1.44472]]] z: [[[-0.718 -0.993]]] std:  [[[0.66327 0.59046]]]\n",
      "mean:  [[[-0.04617 -2.35891]]] z: [[[-1.948 -0.433]]] std:  [[[0.12372 1.14751]]]\n",
      "mean:  [[[-0.03073  1.43437]]] z: [[[0.502 0.915]]] std:  [[[0.66414 0.59658]]]\n",
      "mean:  [[[-0.05946 -2.38712]]] z: [[[0.454 0.441]]] std:  [[[0.12105 1.14922]]]\n",
      "mean:  [[[-0.03167  1.47635]]] z: [[[ 0.665 -0.192]]] std:  [[[0.6571  0.57302]]]\n",
      "mean:  [[[-0.024   -2.23118]]] z: [[[-0.232  0.254]]] std:  [[[0.11895 1.08493]]]\n",
      "mean:  [[[-0.04685  1.48721]]] z: [[[0.446 0.785]]] std:  [[[0.66231 0.56479]]]\n",
      "mean:  [[[-0.01205 -2.2137 ]]] z: [[[-0.582  0.884]]] std:  [[[0.12254 1.10592]]]\n",
      "mean:  [[[-0.04227  1.46447]]] z: [[[0.478 0.577]]] std:  [[[0.66456 0.57733]]]\n",
      "mean:  [[[-0.01043 -2.20552]]] z: [[[ 0.154 -0.832]]] std:  [[[0.12361 1.10153]]]\n",
      "mean:  [[[-0.03912  1.4631 ]]] z: [[[ 0.939 -0.825]]] std:  [[[0.6637  0.57858]]]\n",
      "mean:  [[[-0.0426  -2.28012]]] z: [[[ 0.358 -0.786]]] std:  [[[0.11857 1.12006]]]\n",
      "mean:  [[[-0.02319  1.44638]]] z: [[[ 0.7   -2.216]]] std:  [[[0.66156 0.58534]]]\n",
      "mean:  [[[-0.08257 -2.45697]]] z: [[[ 1.028 -0.01 ]]] std:  [[[0.11041 1.15318]]]\n",
      "mean:  [[[-0.00424  1.34871]]] z: [[[ 0.433 -0.371]]] std:  [[[0.67284 0.65439]]]\n",
      "mean:  [[[-0.05604 -2.40076]]] z: [[[-0.238 -1.238]]] std:  [[[0.1277  1.25587]]]\n",
      "mean:  [[[0.01649 1.32918]]] z: [[[ 1.9   -1.024]]] std:  [[[0.65335 0.64298]]]\n",
      "mean:  [[[-0.08261 -2.50203]]] z: [[[ 0.954 -0.076]]] std:  [[[0.12213 1.24575]]]\n",
      "mean:  [[[0.05924 1.24223]]] z: [[[-0.176 -0.204]]] std:  [[[0.68479 0.68053]]]\n",
      "mean:  [[[-0.00529 -2.3252 ]]] z: [[[0.564 1.494]]] std:  [[[0.14709 1.42129]]]\n",
      "mean:  [[[0.08232 1.1446 ]]] z: [[[0.498 0.733]]] std:  [[[0.69447 0.72228]]]\n",
      "mean:  [[[-0.01092 -2.36323]]] z: [[[ 1.302 -0.546]]] std:  [[[0.14486 1.38622]]]\n",
      "mean:  [[[0.07489 1.16464]]] z: [[[1.334 0.567]]] std:  [[[0.68969 0.71461]]]\n",
      "mean:  [[[-0.04688 -2.27282]]] z: [[[ 0.93  -0.266]]] std:  [[[0.14195 1.264  ]]]\n",
      "mean:  [[[-0.00442  1.38139]]] z: [[[ 1.104 -0.125]]] std:  [[[0.64022 0.62762]]]\n",
      "mean:  [[[-0.06605 -2.33297]]] z: [[[ 1.035 -0.622]]] std:  [[[0.12404 1.17239]]]\n",
      "mean:  [[[-0.0027  1.3642]]] z: [[[-1.149  0.143]]] std:  [[[0.62903 0.63834]]]\n",
      "mean:  [[[-0.05262 -2.22909]]] z: [[[0.74  0.782]]] std:  [[[0.13565 1.33404]]]\n",
      "mean:  [[[0.00668 1.32693]]] z: [[[-0.329  0.26 ]]] std:  [[[0.63902 0.64706]]]\n",
      "mean:  [[[-0.03253 -2.21764]]] z: [[[ 0.567 -0.03 ]]] std:  [[[0.13938 1.3316 ]]]\n",
      "mean:  [[[0.00368 1.34229]]] z: [[[-1.17   0.456]]] std:  [[[0.63997 0.63739]]]\n",
      "mean:  [[[-0.04748 -2.27139]]] z: [[[-1.308  2.788]]] std:  [[[0.13558 1.34013]]]\n",
      "mean:  [[[0.25681 1.25068]]] z: [[[-0.58   1.536]]] std:  [[[0.82932 0.80502]]]\n",
      "mean:  [[[ 0.48439 -1.27285]]] z: [[[ 0.772 -2.014]]] std:  [[[0.27785 3.09835]]]\n",
      "mean:  [[[0.95167 1.57971]]] z: [[[ 2.222 -0.865]]] std:  [[[1.2767  0.64467]]]\n",
      "mean:  [[[ 0.69242 -1.46546]]] z: [[[-0.437 -0.156]]] std:  [[[0.37271 3.31836]]]\n",
      "mean:  [[[0.62908 1.0787 ]]] z: [[[2.02 0.74]]] std:  [[[0.97486 0.92279]]]\n",
      "mean:  [[[ 0.65996 -1.21859]]] z: [[[ 0.226 -0.554]]] std:  [[[0.35008 3.4813 ]]]\n",
      "mean:  [[[0.99842 1.82276]]] z: [[[ 1.022 -2.128]]] std:  [[[1.34091 0.69928]]]\n",
      "mean:  [[[ 0.69412 -1.40359]]] z: [[[-1.508 -0.243]]] std:  [[[0.4114  3.23633]]]\n",
      "mean:  [[[0.44294 0.61866]]] z: [[[-2.654 -0.084]]] std:  [[[1.03182 1.03714]]]\n",
      "mean:  [[[ 0.1171  -1.31715]]] z: [[[-0.63  0.51]]] std:  [[[0.20072 1.78612]]]\n",
      "mean:  [[[1.05968 1.47493]]] z: [[[ 1.253 -0.409]]] std:  [[[1.10129 0.55506]]]\n",
      "mean:  [[[ 0.3898  -1.65532]]] z: [[[-1.172  2.478]]] std:  [[[0.25557 1.34732]]]\n",
      "mean:  [[[0.18026 0.25467]]] z: [[[-1.188  1.149]]] std:  [[[0.80968 0.98175]]]\n",
      "mean:  [[[ 0.03186 -1.87119]]] z: [[[ 0.817 -1.434]]] std:  [[[0.15536 1.07247]]]\n",
      "mean:  [[[0.20641 1.3447 ]]] z: [[[0.227 1.28 ]]] std:  [[[0.70129 0.59252]]]\n",
      "mean:  [[[ 0.20775 -1.75878]]] z: [[[0.819 0.668]]] std:  [[[0.19993 1.80078]]]\n",
      "mean:  [[[0.29595 0.99262]]] z: [[[ 0.655 -0.833]]] std:  [[[0.79458 0.73478]]]\n",
      "mean:  [[[ 0.10565 -1.68676]]] z: [[[-0.239 -0.524]]] std:  [[[0.18904 1.45746]]]\n",
      "mean:  [[[0.41242 1.08191]]] z: [[[ 0.985 -0.646]]] std:  [[[0.7626  0.64007]]]\n",
      "mean:  [[[ 0.17593 -1.5664 ]]] z: [[[-2.368  1.113]]] std:  [[[0.21723 1.79781]]]\n",
      "mean:  [[[0.5286  0.94632]]] z: [[[-0.384 -0.53 ]]] std:  [[[0.7826  0.65709]]]\n",
      "mean:  [[[ 0.19191 -1.56544]]] z: [[[-0.058 -0.716]]] std:  [[[0.22353 1.83479]]]\n",
      "mean:  [[[0.22824 1.22705]]] z: [[[0.05  1.481]]] std:  [[[0.64392 0.58192]]]\n",
      "mean:  [[[ 0.06875 -1.98232]]] z: [[[-0.913  1.811]]] std:  [[[0.15621 1.29533]]]\n",
      "mean:  [[[0.02565 1.46016]]] z: [[[-0.465  0.101]]] std:  [[[0.62591 0.55324]]]\n",
      "mean:  [[[ 0.02265 -2.12473]]] z: [[[ 0.337 -1.36 ]]] std:  [[[0.14702 1.16906]]]\n",
      "mean:  [[[-0.02276  1.44993]]] z: [[[ 0.123 -0.513]]] std:  [[[0.63896 0.56672]]]\n",
      "mean:  [[[ 0.01147 -2.13713]]] z: [[[0.832 0.696]]] std:  [[[0.14508 1.13342]]]\n",
      "mean:  [[[0.12749 1.32408]]] z: [[[-1.706  1.11 ]]] std:  [[[0.67328 0.61295]]]\n",
      "mean:  [[[ 0.07983 -2.10389]]] z: [[[-0.393  0.536]]] std:  [[[0.16509 1.58107]]]\n",
      "mean:  [[[0.05605 1.30571]]] z: [[[-0.594 -0.496]]] std:  [[[0.65908 0.63987]]]\n",
      "mean:  [[[ 0.11042 -1.90497]]] z: [[[-0.865  0.475]]] std:  [[[0.1645  1.46742]]]\n",
      "mean:  [[[0.13234 1.33411]]] z: [[[-0.674  1.809]]] std:  [[[0.671   0.63347]]]\n",
      "mean:  [[[ 0.13742 -1.82716]]] z: [[[1.416 0.439]]] std:  [[[0.17733 1.69862]]]\n",
      "mean:  [[[0.2072 1.2945]]] z: [[[ 1.524 -0.599]]] std:  [[[0.68578 0.64018]]]\n",
      "mean:  [[[ 0.14913 -1.83213]]] z: [[[ 0.77  -0.489]]] std:  [[[0.18352 1.76408]]]\n",
      "mean:  [[[0.21942 1.28408]]] z: [[[0.085 0.17 ]]] std:  [[[0.68314 0.63897]]]\n",
      "mean:  [[[ 0.14017 -1.86458]]] z: [[[1.051 0.623]]] std:  [[[0.18106 1.75369]]]\n",
      "mean:  [[[0.19195 1.29437]]] z: [[[-0.42   1.432]]] std:  [[[0.67826 0.6402 ]]]\n",
      "mean:  [[[ 0.14056 -1.81804]]] z: [[[0.535 1.232]]] std:  [[[0.17939 1.683  ]]]\n",
      "mean:  [[[0.20849 1.28913]]] z: [[[ 0.825 -1.315]]] std:  [[[0.675   0.63569]]]\n",
      "mean:  [[[ 0.14265 -1.81395]]] z: [[[ 1.147 -1.417]]] std:  [[[0.18118 1.70812]]]\n",
      "mean:  [[[0.37244 1.32573]]] z: [[[ 0.64  -0.542]]] std:  [[[0.73898 0.60146]]]\n",
      "mean:  [[[ 0.35531 -1.63804]]] z: [[[-1.118 -1.441]]] std:  [[[0.28893 2.43449]]]\n",
      "mean:  [[[0.35251 1.02711]]] z: [[[0.35  0.579]]] std:  [[[0.84425 0.76601]]]\n",
      "mean:  [[[ 0.13591 -1.51365]]] z: [[[ 0.344 -1.478]]] std:  [[[0.19308 1.44587]]]\n",
      "mean:  [[[0.40712 1.18643]]] z: [[[ 0.862 -1.867]]] std:  [[[0.77018 0.62502]]]\n",
      "mean:  [[[ 0.0591  -1.89417]]] z: [[[2.011 0.554]]] std:  [[[0.15253 1.40771]]]\n",
      "mean:  [[[0.2887  1.30361]]] z: [[[-0.004 -0.404]]] std:  [[[0.64346 0.56177]]]\n",
      "mean:  [[[ 0.035   -2.09298]]] z: [[[-0.086 -1.584]]] std:  [[[0.14527 1.32198]]]\n",
      "mean:  [[[-0.0413   1.52289]]] z: [[[0.373 1.095]]] std:  [[[0.6408 0.5471]]]\n",
      "mean:  [[[-0.05118 -2.3433 ]]] z: [[[-2.618 -0.516]]] std:  [[[0.12459 1.06127]]]\n",
      "mean:  [[[-0.04061  1.46482]]] z: [[[-0.195 -0.261]]] std:  [[[0.6737  0.58386]]]\n",
      "mean:  [[[-0.03675 -2.28522]]] z: [[[-0.361  0.131]]] std:  [[[0.12807 1.07017]]]\n",
      "mean:  [[[-0.04471  1.46138]]] z: [[[ 0.98  -2.151]]] std:  [[[0.67298 0.58817]]]\n",
      "mean:  [[[-0.03778 -2.29965]]] z: [[[ 0.587 -0.562]]] std:  [[[0.13427 1.08827]]]\n",
      "mean:  [[[-0.039    1.41074]]] z: [[[0.142 0.706]]] std:  [[[0.67435 0.63028]]]\n",
      "mean:  [[[-0.05726 -2.33008]]] z: [[[-0.31   0.684]]] std:  [[[0.13273 1.06971]]]\n",
      "mean:  [[[-0.03637  1.4336 ]]] z: [[[-1.177 -0.791]]] std:  [[[0.66387 0.606  ]]]\n",
      "mean:  [[[-0.02934 -2.23833]]] z: [[[-0.435 -1.339]]] std:  [[[0.13939 1.09294]]]\n",
      "mean:  [[[-0.05066  1.44616]]] z: [[[-0.269  0.566]]] std:  [[[0.65697 0.5868 ]]]\n",
      "mean:  [[[-0.03865 -2.26406]]] z: [[[ 1.    -1.359]]] std:  [[[0.1368  1.08018]]]\n",
      "mean:  [[[-0.04702  1.44774]]] z: [[[-0.359  0.27 ]]] std:  [[[0.65789 0.5868 ]]]\n",
      "mean:  [[[-0.04502 -2.27192]]] z: [[[1.61 0.51]]] std:  [[[0.1361  1.08436]]]\n",
      "mean:  [[[-0.04647  1.44909]]] z: [[[-2.544  0.416]]] std:  [[[0.65775 0.58579]]]\n",
      "mean:  [[[-0.03685 -2.2465 ]]] z: [[[0.003 0.272]]] std:  [[[0.13769 1.07849]]]\n",
      "mean:  [[[-0.02574  1.40703]]] z: [[[-1.464  1.648]]] std:  [[[0.65683 0.60755]]]\n",
      "mean:  [[[ 0.06961 -2.16987]]] z: [[[-1.423 -2.055]]] std:  [[[0.15296 1.23732]]]\n",
      "mean:  [[[-0.00504  1.32954]]] z: [[[ 0.469 -0.531]]] std:  [[[0.66928 0.63337]]]\n",
      "mean:  [[[ 0.07136 -2.19367]]] z: [[[-0.858  0.926]]] std:  [[[0.15552 1.23108]]]\n",
      "mean:  [[[0.06065 1.23943]]] z: [[[ 0.973 -0.542]]] std:  [[[0.67526 0.65933]]]\n",
      "mean:  [[[ 0.16923 -2.11145]]] z: [[[-1.826  1.033]]] std:  [[[0.16586 1.33362]]]\n",
      "mean:  [[[0.09969 1.18115]]] z: [[[ 0.329 -0.701]]] std:  [[[0.67206 0.68137]]]\n",
      "mean:  [[[ 0.17929 -2.12298]]] z: [[[0.051 1.691]]] std:  [[[0.16817 1.32613]]]\n",
      "mean:  [[[0.20147 1.27899]]] z: [[[-1.102 -1.717]]] std:  [[[0.88626 0.72559]]]\n",
      "mean:  [[[ 0.363   -1.69468]]] z: [[[-0.014  0.665]]] std:  [[[0.27314 2.10254]]]\n",
      "mean:  [[[0.34724 0.90941]]] z: [[[-1.62  -0.471]]] std:  [[[0.90488 0.80078]]]\n",
      "mean:  [[[ 0.32288 -1.80501]]] z: [[[0.211 1.28 ]]] std:  [[[0.22243 1.71373]]]\n",
      "mean:  [[[0.62786 1.23511]]] z: [[[-1.74  -1.215]]] std:  [[[0.93909 0.61768]]]\n",
      "mean:  [[[ 0.35595 -1.52144]]] z: [[[-0.506 -1.418]]] std:  [[[0.29883 2.17597]]]\n",
      "mean:  [[[0.62871 0.9115 ]]] z: [[[ 1.103 -0.252]]] std:  [[[0.78104 0.67513]]]\n",
      "mean:  [[[ 0.24244 -1.41177]]] z: [[[-0.523  0.576]]] std:  [[[0.24456 1.76376]]]\n",
      "mean:  [[[0.78461 1.01692]]] z: [[[-0.518 -1.39 ]]] std:  [[[0.77891 0.59806]]]\n",
      "mean:  [[[ 0.29976 -1.64957]]] z: [[[-0.212 -2.316]]] std:  [[[0.27104 1.96979]]]\n",
      "mean:  [[[0.36066 0.70027]]] z: [[[ 0.59  -1.731]]] std:  [[[0.77818 0.78043]]]\n",
      "mean:  [[[-0.0723  -2.27994]]] z: [[[0.13 0.27]]] std:  [[[0.13064 1.04583]]]\n",
      "mean:  [[[-0.05644  1.53805]]] z: [[[1.681 0.821]]] std:  [[[0.66244 0.53295]]]\n",
      "mean:  [[[-0.08824 -2.39626]]] z: [[[0.077 1.027]]] std:  [[[0.12629 1.08167]]]\n",
      "mean:  [[[-0.03348  1.46386]]] z: [[[ 1.287 -0.391]]] std:  [[[0.67975 0.57086]]]\n",
      "mean:  [[[-0.06655 -2.35015]]] z: [[[ 1.546 -0.165]]] std:  [[[0.13034 1.11251]]]\n",
      "mean:  [[[-0.03804  1.47298]]] z: [[[ 0.159 -1.565]]] std:  [[[0.67663 0.56688]]]\n",
      "mean:  [[[-0.07387 -2.36235]]] z: [[[-0.513 -0.833]]] std:  [[[0.12926 1.13529]]]\n",
      "mean:  [[[-0.03424  1.47512]]] z: [[[-0.641  1.145]]] std:  [[[0.67582 0.56491]]]\n",
      "mean:  [[[-0.07375 -2.36625]]] z: [[[1.351 0.476]]] std:  [[[0.12889 1.15136]]]\n",
      "mean:  [[[-0.03323  1.47339]]] z: [[[ 0.448 -0.42 ]]] std:  [[[0.67621 0.56521]]]\n",
      "mean:  [[[-0.03827 -2.2746 ]]] z: [[[-0.164  2.419]]] std:  [[[0.1353  1.17752]]]\n",
      "mean:  [[[-0.03328  1.45571]]] z: [[[1.59  0.096]]] std:  [[[0.67687 0.57219]]]\n",
      "mean:  [[[-0.02849 -2.26542]]] z: [[[0.48 0.21]]] std:  [[[0.1367 1.1748]]]\n",
      "mean:  [[[-0.01845  1.44042]]] z: [[[-0.352 -0.065]]] std:  [[[0.67023 0.57938]]]\n",
      "mean:  [[[ 0.01718 -2.17013]]] z: [[[-0.226 -1.818]]] std:  [[[0.14523 1.19228]]]\n",
      "mean:  [[[-0.01004  1.42967]]] z: [[[-0.893  0.593]]] std:  [[[0.66444 0.58205]]]\n",
      "mean:  [[[ 0.03142 -2.13667]]] z: [[[0.101 0.447]]] std:  [[[0.1484  1.18584]]]\n",
      "mean:  [[[-0.0097   1.43206]]] z: [[[ 0.492 -0.514]]] std:  [[[0.66215 0.57954]]]\n",
      "mean:  [[[ 0.03037 -2.1339 ]]] z: [[[1.048 0.896]]] std:  [[[0.14855 1.18695]]]\n",
      "mean:  [[[-0.03493  1.41584]]] z: [[[ 0.847 -0.306]]] std:  [[[0.65956 0.59349]]]\n",
      "mean:  [[[-0.04337 -2.34666]]] z: [[[-0.803  0.019]]] std:  [[[0.13615 1.14522]]]\n",
      "mean:  [[[-0.02042  1.42158]]] z: [[[-0.288  1.026]]] std:  [[[0.6767  0.60492]]]\n",
      "mean:  [[[-0.03228 -2.33894]]] z: [[[0.883 0.024]]] std:  [[[0.13191 1.12712]]]\n",
      "mean:  [[[-0.02795  1.41962]]] z: [[[ 1.525 -0.899]]] std:  [[[0.67465 0.60589]]]\n",
      "mean:  [[[-0.02967 -2.34023]]] z: [[[-0.621 -0.979]]] std:  [[[0.13701 1.14434]]]\n",
      "mean:  [[[-0.02077  1.38839]]] z: [[[-2.052  1.072]]] std:  [[[0.66787 0.62422]]]\n",
      "mean:  [[[-0.02471 -2.31661]]] z: [[[-0.058 -1.738]]] std:  [[[0.13884 1.11847]]]\n",
      "mean:  [[[-0.02545  1.39668]]] z: [[[ 0.461 -0.443]]] std:  [[[0.66568 0.62092]]]\n",
      "mean:  [[[-0.04408 -2.36417]]] z: [[[-0.791  0.349]]] std:  [[[0.13554 1.12328]]]\n",
      "mean:  [[[-0.01736  1.37746]]] z: [[[-0.739 -0.091]]] std:  [[[0.67455 0.6467 ]]]\n",
      "mean:  [[[-0.03983 -2.34642]]] z: [[[-0.317  0.806]]] std:  [[[0.1376  1.13583]]]\n",
      "mean:  [[[-0.01612  1.3837 ]]] z: [[[-0.319  0.376]]] std:  [[[0.66464 0.62659]]]\n",
      "mean:  [[[-0.04369 -2.41318]]] z: [[[-0.292  0.085]]] std:  [[[0.13605 1.23969]]]\n",
      "mean:  [[[-0.02547  1.41734]]] z: [[[0.207 0.577]]] std:  [[[0.65376 0.61031]]]\n",
      "mean:  [[[-0.02835 -2.30076]]] z: [[[ 0.524 -1.019]]] std:  [[[0.13953 1.1286 ]]]\n",
      "mean:  [[[-0.0445   1.44313]]] z: [[[-0.319 -1.716]]] std:  [[[0.64899 0.58825]]]\n",
      "mean:  [[[-0.0223 -2.2762]]] z: [[[-1.043 -1.394]]] std:  [[[0.13738 1.11117]]]\n",
      "mean:  [[[-0.04339  1.4392 ]]] z: [[[1.343 0.859]]] std:  [[[0.64942 0.59095]]]\n",
      "mean:  [[[ 0.01485 -2.21861]]] z: [[[-0.935 -0.438]]] std:  [[[0.14153 1.20508]]]\n",
      "mean:  [[[0.01951 1.31771]]] z: [[[-1.133  0.019]]] std:  [[[0.66353 0.63247]]]\n",
      "mean:  [[[ 0.01456 -2.27478]]] z: [[[-0.848 -0.241]]] std:  [[[0.14719 1.23707]]]\n",
      "mean:  [[[0.0192  1.30583]]] z: [[[2.192 1.709]]] std:  [[[0.66211 0.64008]]]\n",
      "mean:  [[[ 0.00636 -2.22751]]] z: [[[-0.474  1.362]]] std:  [[[0.14867 1.11915]]]\n",
      "mean:  [[[-0.03437  1.43219]]] z: [[[-0.327 -1.783]]] std:  [[[0.63063 0.59247]]]\n",
      "mean:  [[[ 0.03748 -2.08509]]] z: [[[0.534 1.11 ]]] std:  [[[0.14896 1.16453]]]\n",
      "mean:  [[[-0.01712  1.41831]]] z: [[[1.316 1.925]]] std:  [[[0.62507 0.59204]]]\n",
      "mean:  [[[ 0.03562 -2.07527]]] z: [[[0.125 1.686]]] std:  [[[0.14908 1.18313]]]\n",
      "mean:  [[[-0.00617  1.4135 ]]] z: [[[1.594 0.052]]] std:  [[[0.62333 0.58961]]]\n",
      "mean:  [[[-0.01953 -2.24235]]] z: [[[-0.369 -0.583]]] std:  [[[0.13769 1.15954]]]\n",
      "mean:  [[[0.18312 1.28638]]] z: [[[-0.381  1.005]]] std:  [[[0.75894 0.6789 ]]]\n",
      "mean:  [[[ 0.0376  -1.83415]]] z: [[[ 0.982 -0.745]]] std:  [[[0.17962 1.5787 ]]]\n",
      "mean:  [[[0.23826 1.20722]]] z: [[[-1.471 -0.933]]] std:  [[[0.749   0.62284]]]\n",
      "mean:  [[[ 0.08721 -1.79092]]] z: [[[-0.852  0.751]]] std:  [[[0.19548 1.75947]]]\n",
      "mean:  [[[0.29372 1.19283]]] z: [[[-0.464 -1.49 ]]] std:  [[[0.74471 0.61072]]]\n",
      "mean:  [[[ 0.09942 -1.79999]]] z: [[[-1.399 -1.945]]] std:  [[[0.20019 1.8538 ]]]\n",
      "mean:  [[[0.29367 1.17578]]] z: [[[0.915 0.67 ]]] std:  [[[0.74336 0.61534]]]\n",
      "mean:  [[[ 0.09313 -1.78626]]] z: [[[1.022 0.794]]] std:  [[[0.19679 1.79411]]]\n",
      "mean:  [[[0.2872  1.19274]]] z: [[[0.477 0.41 ]]] std:  [[[0.7359  0.60436]]]\n",
      "mean:  [[[ 0.09467 -1.78023]]] z: [[[-2.007 -0.427]]] std:  [[[0.19655 1.80372]]]\n",
      "mean:  [[[0.28022 1.25632]]] z: [[[-0.555  1.02 ]]] std:  [[[0.77607 0.6142 ]]]\n",
      "mean:  [[[ 0.28508 -1.6997 ]]] z: [[[-1.713 -0.986]]] std:  [[[0.25193 2.42848]]]\n",
      "mean:  [[[0.42028 0.96797]]] z: [[[-0.973  0.609]]] std:  [[[0.85409 0.73463]]]\n",
      "mean:  [[[ 0.24332 -1.60241]]] z: [[[-2.     1.768]]] std:  [[[0.22092 1.91999]]]\n",
      "mean:  [[[0.48009 1.15295]]] z: [[[0.001 0.095]]] std:  [[[0.81993 0.63542]]]\n",
      "mean:  [[[ 0.20987 -1.56563]]] z: [[[ 1.022 -0.155]]] std:  [[[0.23345 2.19624]]]\n",
      "mean:  [[[0.44639 1.14833]]] z: [[[-0.208  0.204]]] std:  [[[0.7273  0.61069]]]\n",
      "mean:  [[[ 0.17301 -1.66078]]] z: [[[-0.035 -1.285]]] std:  [[[0.19301 1.67095]]]\n",
      "mean:  [[[0.34879 1.22449]]] z: [[[-0.87   0.531]]] std:  [[[0.67221 0.57829]]]\n",
      "mean:  [[[ 0.11945 -1.86661]]] z: [[[ 0.538 -1.371]]] std:  [[[0.16849 1.49318]]]\n",
      "mean:  [[[0.30098 1.29687]]] z: [[[-0.806  0.049]]] std:  [[[0.67238 0.57927]]]\n",
      "mean:  [[[ 0.22739 -1.77862]]] z: [[[-0.86   0.475]]] std:  [[[0.20041 1.70366]]]\n",
      "mean:  [[[0.32958 1.22742]]] z: [[[-0.941  1.476]]] std:  [[[0.67182 0.60946]]]\n",
      "mean:  [[[ 0.22308 -1.81152]]] z: [[[-0.39  -1.874]]] std:  [[[0.19623 1.65886]]]\n",
      "mean:  [[[0.29906 1.27203]]] z: [[[ 0.176 -0.099]]] std:  [[[0.66617 0.60484]]]\n",
      "mean:  [[[ 0.21476 -1.82791]]] z: [[[0.1 1. ]]] std:  [[[0.19266 1.62955]]]\n",
      "mean:  [[[0.26483 1.28668]]] z: [[[-0.103  1.028]]] std:  [[[0.65515 0.60416]]]\n",
      "mean:  [[[ 0.206  -1.8479]]] z: [[[ 1.538 -1.041]]] std:  [[[0.18822 1.56781]]]\n",
      "mean:  [[[0.25118 1.31037]]] z: [[[-0.319  0.513]]] std:  [[[0.66066 0.60458]]]\n",
      "mean:  [[[ 0.20126 -1.85779]]] z: [[[0.225 0.824]]] std:  [[[0.18618 1.56446]]]\n",
      "mean:  [[[0.16483 1.30976]]] z: [[[1.008 0.026]]] std:  [[[0.65351 0.61932]]]\n",
      "mean:  [[[ 0.11178 -2.11088]]] z: [[[0.492 0.798]]] std:  [[[0.16203 1.36769]]]\n",
      "mean:  [[[0.05091 1.33073]]] z: [[[-0.685  0.63 ]]] std:  [[[0.66786 0.6254 ]]]\n",
      "mean:  [[[ 0.01657 -2.23569]]] z: [[[-0.131  0.537]]] std:  [[[0.14464 1.15129]]]\n",
      "mean:  [[[-0.05285  1.45252]]] z: [[[0.291 0.572]]] std:  [[[0.6445  0.58722]]]\n",
      "mean:  [[[-0.01824 -2.26981]]] z: [[[1.416 0.923]]] std:  [[[0.13462 1.10658]]]\n",
      "mean:  [[[-0.04833  1.4564 ]]] z: [[[-0.399 -0.205]]] std:  [[[0.64469 0.58544]]]\n",
      "mean:  [[[-0.0101  -2.24597]]] z: [[[0.501 0.541]]] std:  [[[0.13553 1.10365]]]\n",
      "mean:  [[[-0.0443   1.46751]]] z: [[[0.684 0.508]]] std:  [[[0.64892 0.58504]]]\n",
      "mean:  [[[ 0.00724 -2.13975]]] z: [[[ 0.742 -0.109]]] std:  [[[0.13824 1.15419]]]\n",
      "mean:  [[[-0.03366  1.46579]]] z: [[[-0.628  0.041]]] std:  [[[0.64767 0.5862 ]]]\n",
      "mean:  [[[ 0.02425 -2.11995]]] z: [[[ 0.732 -0.469]]] std:  [[[0.1382  1.14236]]]\n",
      "mean:  [[[-0.03319  1.44552]]] z: [[[0.545 0.344]]] std:  [[[0.6588  0.58137]]]\n",
      "mean:  [[[ 0.02638 -2.14163]]] z: [[[-0.372  2.093]]] std:  [[[0.13869 1.14145]]]\n",
      "mean:  [[[-0.03791  1.44308]]] z: [[[0.067 1.15 ]]] std:  [[[0.66041 0.58188]]]\n",
      "mean:  [[[-0.04547 -2.31392]]] z: [[[1.764 0.805]]] std:  [[[0.12484 1.09817]]]\n",
      "mean:  [[[-0.03133  1.44399]]] z: [[[ 0.383 -0.575]]] std:  [[[0.67254 0.5795 ]]]\n",
      "mean:  [[[-0.04569 -2.34035]]] z: [[[-0.129 -1.464]]] std:  [[[0.12542 1.13352]]]\n",
      "mean:  [[[-0.01957  1.404  ]]] z: [[[-0.386  1.394]]] std:  [[[0.66349 0.60554]]]\n",
      "mean:  [[[ 0.02419 -2.16127]]] z: [[[ 1.173 -1.675]]] std:  [[[0.1353  1.11419]]]\n",
      "mean:  [[[-0.03647  1.45492]]] z: [[[1.738 0.762]]] std:  [[[0.65163 0.58113]]]\n",
      "mean:  [[[-0.00122 -2.24431]]] z: [[[0.046 1.209]]] std:  [[[0.13558 1.14245]]]\n",
      "mean:  [[[-0.02193  1.38392]]] z: [[[-1.134 -0.84 ]]] std:  [[[0.64483 0.61614]]]\n",
      "mean:  [[[-0.02043 -2.29009]]] z: [[[-1.701 -0.289]]] std:  [[[0.13329 1.1074 ]]]\n",
      "mean:  [[[-0.02006  1.4016 ]]] z: [[[-0.582  1.456]]] std:  [[[0.64112 0.60742]]]\n",
      "mean:  [[[-0.02538 -2.29084]]] z: [[[-0.505  1.215]]] std:  [[[0.13297 1.12444]]]\n",
      "mean:  [[[-0.01362  1.38993]]] z: [[[0.099 0.513]]] std:  [[[0.6337  0.61116]]]\n",
      "mean:  [[[-0.01586 -2.22142]]] z: [[[-2.414 -0.63 ]]] std:  [[[0.1366  1.13533]]]\n",
      "mean:  [[[-0.02722  1.41864]]] z: [[[-0.013 -0.529]]] std:  [[[0.64713 0.6024 ]]]\n",
      "mean:  [[[-0.06089 -2.37389]]] z: [[[-0.093 -0.339]]] std:  [[[0.12127 1.09436]]]\n",
      "mean:  [[[0.01082 1.39009]]] z: [[[-0.977 -0.572]]] std:  [[[0.6854  0.60468]]]\n",
      "mean:  [[[-0.03035 -2.386  ]]] z: [[[0.086 0.335]]] std:  [[[0.13176 1.29963]]]\n",
      "mean:  [[[0.02532 1.34167]]] z: [[[-0.159  0.501]]] std:  [[[0.68924 0.63222]]]\n",
      "mean:  [[[-0.03572 -2.40676]]] z: [[[ 0.829 -0.022]]] std:  [[[0.13047 1.29262]]]\n",
      "mean:  [[[0.02355 1.35465]]] z: [[[0.695 0.434]]] std:  [[[0.68545 0.62571]]]\n",
      "mean:  [[[-0.08051 -2.41864]]] z: [[[-0.876 -0.127]]] std:  [[[0.12483 1.19864]]]\n",
      "mean:  [[[-0.02755  1.46941]]] z: [[[-0.656 -0.374]]] std:  [[[0.6437  0.59258]]]\n",
      "mean:  [[[-0.10427 -2.37054]]] z: [[[-1.77   0.266]]] std:  [[[0.13032 1.21367]]]\n",
      "mean:  [[[-0.02744  1.45159]]] z: [[[-1.312  0.348]]] std:  [[[0.6757  0.58384]]]\n",
      "mean:  [[[-0.1247  -2.50833]]] z: [[[-0.147  0.598]]] std:  [[[0.11523 1.20064]]]\n",
      "mean:  [[[-0.01511  1.48163]]] z: [[[0.836 0.454]]] std:  [[[0.6531  0.57994]]]\n",
      "mean:  [[[-0.07965 -2.36968]]] z: [[[-1.637  2.162]]] std:  [[[0.12312 1.169  ]]]\n",
      "mean:  [[[-0.02305  1.48184]]] z: [[[-0.242 -0.475]]] std:  [[[0.67047 0.56205]]]\n",
      "mean:  [[[-0.05302 -2.28281]]] z: [[[-0.835 -1.812]]] std:  [[[0.12604 1.17668]]]\n",
      "mean:  [[[-0.0268   1.47251]]] z: [[[1.097 1.023]]] std:  [[[0.67379 0.566  ]]]\n",
      "mean:  [[[-0.08808 -2.45668]]] z: [[[ 0.693 -0.267]]] std:  [[[0.10464 1.15726]]]\n",
      "mean:  [[[0.00399 1.45246]]] z: [[[-0.169  0.678]]] std:  [[[0.66139 0.58206]]]\n",
      "mean:  [[[-0.06788 -2.34882]]] z: [[[-2.098 -1.278]]] std:  [[[0.11448 1.08747]]]\n",
      "mean:  [[[0.0034  1.39382]]] z: [[[ 0.868 -0.69 ]]] std:  [[[0.66181 0.61142]]]\n",
      "mean:  [[[-0.06607 -2.39056]]] z: [[[-0.204  0.596]]] std:  [[[0.1184  1.09337]]]\n",
      "mean:  [[[0.00103 1.39812]]] z: [[[-0.794 -0.457]]] std:  [[[0.6644  0.60821]]]\n",
      "mean:  [[[-0.056   -2.36777]]] z: [[[-0.49   0.878]]] std:  [[[0.12358 1.12106]]]\n",
      "mean:  [[[-0.00003  1.38739]]] z: [[[-0.921  0.134]]] std:  [[[0.66697 0.60942]]]\n",
      "mean:  [[[-0.08313 -2.45671]]] z: [[[-0.367 -0.172]]] std:  [[[0.1112  1.05245]]]\n",
      "mean:  [[[-0.02657  1.40668]]] z: [[[ 0.507 -0.672]]] std:  [[[0.67664 0.63285]]]\n",
      "mean:  [[[-0.04113 -2.30658]]] z: [[[-0.107  1.161]]] std:  [[[0.12249 1.0997 ]]]\n",
      "mean:  [[[-0.03362  1.40634]]] z: [[[-0.055 -0.59 ]]] std:  [[[0.6686  0.61859]]]\n",
      "mean:  [[[-0.00104 -2.21293]]] z: [[[0.243 0.608]]] std:  [[[0.12662 1.0938 ]]]\n",
      "mean:  [[[-0.04629  1.43167]]] z: [[[0.509 0.7  ]]] std:  [[[0.66831 0.5855 ]]]\n",
      "mean:  [[[-0.02169 -2.29397]]] z: [[[-0.274 -0.114]]] std:  [[[0.12129 1.14247]]]\n",
      "mean:  [[[-0.0117   1.36565]]] z: [[[-1.728 -1.468]]] std:  [[[0.66074 0.62491]]]\n",
      "mean:  [[[-0.07871 -2.46497]]] z: [[[-0.982  0.73 ]]] std:  [[[0.11961 1.21789]]]\n",
      "mean:  [[[0.00762 1.36352]]] z: [[[0.744 0.051]]] std:  [[[0.6639  0.62795]]]\n",
      "mean:  [[[-0.04396 -2.36996]]] z: [[[-0.439  1.394]]] std:  [[[0.12515 1.21714]]]\n",
      "mean:  [[[0.00117 1.34591]]] z: [[[-1.43   0.324]]] std:  [[[0.66126 0.63723]]]\n",
      "mean:  [[[-0.06856 -2.42928]]] z: [[[1.082 2.262]]] std:  [[[0.12077 1.20593]]]\n",
      "mean:  [[[0.00538 1.35476]]] z: [[[ 0.063 -0.216]]] std:  [[[0.66139 0.63538]]]\n",
      "mean:  [[[-0.01997 -2.24664]]] z: [[[-1.15  -0.357]]] std:  [[[0.12238 1.12632]]]\n",
      "mean:  [[[-0.0231   1.39279]]] z: [[[-0.678 -0.276]]] std:  [[[0.64829 0.6064 ]]]\n",
      "mean:  [[[-0.00876 -2.22937]]] z: [[[-1.496 -0.361]]] std:  [[[0.12778 1.13974]]]\n",
      "mean:  [[[-0.02069  1.3772 ]]] z: [[[-0.216 -0.442]]] std:  [[[0.65891 0.61773]]]\n",
      "mean:  [[[-0.00939 -2.24829]]] z: [[[ 0.935 -0.702]]] std:  [[[0.12216 1.12737]]]\n",
      "mean:  [[[-0.01939  1.37879]]] z: [[[-0.598  1.028]]] std:  [[[0.65767 0.61778]]]\n",
      "Firely capture rate for the episode:  3 ff for 51.20000000000046 s: -------------------> 0.06\n",
      "Total reward for the episode:  219.4146165624261\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [64.42297 68.32297 86.66868]\n",
      "TIME before resetting: 51.20000000000046\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.04\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  0\n",
      "current dw_cost_factor:  0\n",
      "current w_cost_factor:  0\n",
      "current distance2center_cost:  0.0\n",
      "current stop_vel_cost:  50\n",
      "current flash_on_interval:  1.8000000000000005\n",
      "current num_obs_ff:  7\n",
      "current reward_boundary:  25\n",
      "current max_in_memory_time:  2\n",
      "\n",
      " episode:  164\n",
      "mean:  [[[-0.67127 -2.38399]]] z: [[[ 1.308 -0.292]]] std:  [[[0.05413 0.2092 ]]]\n",
      "mean:  [[[-0.89405  0.7627 ]]] z: [[[0.644 0.598]]] std:  [[[0.25185 0.23394]]]\n",
      "mean:  [[[-1.18503  0.05704]]] z: [[[0.427 0.455]]] std:  [[[0.05094 0.37163]]]\n",
      "mean:  [[[-0.1135   0.94906]]] z: [[[1.133 0.159]]] std:  [[[0.46662 0.7575 ]]]\n",
      "mean:  [[[-0.16207 -1.34646]]] z: [[[-0.517 -1.167]]] std:  [[[0.14703 0.82674]]]\n",
      "mean:  [[[-0.07241  1.51305]]] z: [[[-1.571 -1.654]]] std:  [[[0.61229 0.53468]]]\n",
      "mean:  [[[-0.11878 -1.99962]]] z: [[[0.306 0.382]]] std:  [[[0.12992 0.91064]]]\n",
      "mean:  [[[-0.05363  1.49243]]] z: [[[-0.405  0.907]]] std:  [[[0.65695 0.55805]]]\n",
      "mean:  [[[-0.05356 -2.12959]]] z: [[[0.527 0.38 ]]] std:  [[[0.1349  1.00573]]]\n",
      "mean:  [[[-0.05098  1.48545]]] z: [[[ 0.899 -0.204]]] std:  [[[0.66524 0.56632]]]\n",
      "mean:  [[[-0.00883 -2.13994]]] z: [[[-0.705  0.666]]] std:  [[[0.13965 1.04548]]]\n",
      "mean:  [[[-0.04776  1.48526]]] z: [[[-0.563 -0.003]]] std:  [[[0.66575 0.56653]]]\n",
      "mean:  [[[-0.033   -2.28568]]] z: [[[0.679 1.041]]] std:  [[[0.13405 1.06962]]]\n",
      "mean:  [[[-0.03949  1.45022]]] z: [[[0.997 0.141]]] std:  [[[0.67786 0.59073]]]\n",
      "mean:  [[[-0.00995 -2.23964]]] z: [[[-1.152  0.622]]] std:  [[[0.14302 1.10812]]]\n",
      "mean:  [[[-0.0411   1.45629]]] z: [[[0.439 0.118]]] std:  [[[0.67114 0.57645]]]\n",
      "mean:  [[[-0.03218 -2.31223]]] z: [[[1.289 0.293]]] std:  [[[0.14173 1.11526]]]\n",
      "mean:  [[[-0.03483  1.4274 ]]] z: [[[-0.323 -0.301]]] std:  [[[0.67076 0.60142]]]\n",
      "mean:  [[[-0.03439 -2.30826]]] z: [[[ 1.35 -0.19]]] std:  [[[0.14179 1.09722]]]\n",
      "mean:  [[[-0.03776  1.43483]]] z: [[[0.619 1.212]]] std:  [[[0.66927 0.5987 ]]]\n",
      "mean:  [[[-0.03467 -2.30524]]] z: [[[0.027 1.726]]] std:  [[[0.14141 1.09329]]]\n",
      "2.10 action: [-0.035 -0.98] n_targets: 1 reward: 69.18 cost_for_stop_vel: 30.82\n",
      "mean:  [[[-0.0288   1.40924]]] z: [[[-0.725  1.757]]] std:  [[[0.67232 0.61255]]]\n",
      "mean:  [[[-0.02799 -2.29547]]] z: [[[-1.086 -0.506]]] std:  [[[0.14228 1.1234 ]]]\n",
      "mean:  [[[-0.02515  1.40728]]] z: [[[-0.761  0.815]]] std:  [[[0.66494 0.60729]]]\n",
      "mean:  [[[-0.0415  -2.32837]]] z: [[[-0.109  0.882]]] std:  [[[0.1398  1.11798]]]\n",
      "mean:  [[[-0.02623  1.43184]]] z: [[[-0.313  1.492]]] std:  [[[0.66558 0.5916 ]]]\n",
      "mean:  [[[-0.06656 -2.37987]]] z: [[[ 1.502 -0.883]]] std:  [[[0.13935 1.14905]]]\n",
      "mean:  [[[-0.01944  1.4307 ]]] z: [[[-1.735 -2.35 ]]] std:  [[[0.66657 0.59213]]]\n",
      "mean:  [[[-0.06589 -2.37816]]] z: [[[-2.289  1.015]]] std:  [[[0.13899 1.15322]]]\n",
      "mean:  [[[-0.0212   1.43049]]] z: [[[-0.789 -1.027]]] std:  [[[0.6665  0.59255]]]\n",
      "mean:  [[[-0.07843 -2.40947]]] z: [[[-0.663  0.373]]] std:  [[[0.13659 1.16057]]]\n",
      "mean:  [[[-0.02464  1.48057]]] z: [[[1.765 1.302]]] std:  [[[0.65496 0.56853]]]\n",
      "mean:  [[[-0.06629 -2.37612]]] z: [[[ 0.943 -0.179]]] std:  [[[0.1341  1.14439]]]\n",
      "mean:  [[[-0.02818  1.45325]]] z: [[[-0.421 -1.12 ]]] std:  [[[0.68009 0.59414]]]\n",
      "mean:  [[[-0.0625  -2.39709]]] z: [[[-1.831 -2.02 ]]] std:  [[[0.13033 1.12986]]]\n",
      "mean:  [[[-0.02137  1.43312]]] z: [[[ 0.496 -1.175]]] std:  [[[0.6768  0.59895]]]\n",
      "mean:  [[[-0.0263  -2.31824]]] z: [[[ 1.278 -1.094]]] std:  [[[0.13459 1.12793]]]\n",
      "mean:  [[[-0.0295   1.43046]]] z: [[[-0.19  -0.654]]] std:  [[[0.67373 0.60008]]]\n",
      "mean:  [[[-0.02115 -2.28698]]] z: [[[1.065 1.49 ]]] std:  [[[0.13535 1.12658]]]\n",
      "mean:  [[[-0.03102  1.44934]]] z: [[[-0.271 -0.523]]] std:  [[[0.67078 0.58563]]]\n",
      "mean:  [[[-0.02198 -2.29481]]] z: [[[-0.376 -0.584]]] std:  [[[0.13471 1.13939]]]\n",
      "mean:  [[[-0.03704  1.48077]]] z: [[[-0.157  0.595]]] std:  [[[0.67664 0.56377]]]\n",
      "mean:  [[[-0.02856 -2.31241]]] z: [[[ 0.938 -0.942]]] std:  [[[0.13334 1.13826]]]\n",
      "mean:  [[[-0.03834  1.45881]]] z: [[[-0.788  0.347]]] std:  [[[0.67043 0.57356]]]\n",
      "mean:  [[[-0.01241 -2.27691]]] z: [[[-0.482  0.578]]] std:  [[[0.1414  1.13593]]]\n",
      "mean:  [[[-0.04114  1.45506]]] z: [[[1.93  1.275]]] std:  [[[0.66915 0.57508]]]\n",
      "mean:  [[[-0.01598 -2.28266]]] z: [[[0.356 0.828]]] std:  [[[0.1413  1.13559]]]\n",
      "mean:  [[[-0.04082  1.45813]]] z: [[[1.056 0.786]]] std:  [[[0.66846 0.57182]]]\n",
      "mean:  [[[-0.03451 -2.33419]]] z: [[[-1.551 -0.344]]] std:  [[[0.14093 1.13846]]]\n",
      "4.90 action: [-0.034 -0.981] n_targets: 1 reward: 69.38 cost_for_stop_vel: 30.62\n",
      "mean:  [[[-0.04278  1.4349 ]]] z: [[[0.418 0.462]]] std:  [[[0.66404 0.59223]]]\n",
      "mean:  [[[-0.02413 -2.28621]]] z: [[[-0.54   0.728]]] std:  [[[0.14392 1.10808]]]\n",
      "mean:  [[[-0.03914  1.4619 ]]] z: [[[ 0.224 -0.497]]] std:  [[[0.65748 0.57037]]]\n",
      "mean:  [[[ 0.01373 -2.17155]]] z: [[[-1.672  0.036]]] std:  [[[0.14954 1.1173 ]]]\n",
      "mean:  [[[0.00262 1.46537]]] z: [[[ 0.785 -0.687]]] std:  [[[0.65953 0.57598]]]\n",
      "mean:  [[[ 0.04373 -2.13837]]] z: [[[-0.106  1.749]]] std:  [[[0.15227 1.19123]]]\n",
      "mean:  [[[0.00813 1.43577]]] z: [[[-0.138 -0.339]]] std:  [[[0.6618  0.58295]]]\n",
      "mean:  [[[ 0.05422 -2.13627]]] z: [[[-1.272 -0.128]]] std:  [[[0.15794 1.19627]]]\n",
      "mean:  [[[0.0257  1.43375]]] z: [[[-1.153  0.009]]] std:  [[[0.6623 0.5825]]]\n",
      "mean:  [[[ 0.06981 -2.09577]]] z: [[[ 0.363 -0.333]]] std:  [[[0.16169 1.21212]]]\n",
      "mean:  [[[0.01641 1.39526]]] z: [[[-0.539  0.787]]] std:  [[[0.64645 0.5987 ]]]\n",
      "mean:  [[[ 0.03898 -2.1901 ]]] z: [[[0.254 0.122]]] std:  [[[0.15592 1.16222]]]\n",
      "mean:  [[[0.00184 1.38483]]] z: [[[-0.351 -0.133]]] std:  [[[0.64864 0.60387]]]\n",
      "mean:  [[[ 0.0215 -2.2119]]] z: [[[-0.976  0.233]]] std:  [[[0.14418 1.12018]]]\n",
      "mean:  [[[-0.00728  1.43977]]] z: [[[-0.622  1.268]]] std:  [[[0.66051 0.58592]]]\n",
      "mean:  [[[-0.01209 -2.34888]]] z: [[[0.069 0.051]]] std:  [[[0.14365 1.18986]]]\n",
      "mean:  [[[-0.00262  1.34415]]] z: [[[ 0.287 -2.843]]] std:  [[[0.66552 0.64188]]]\n",
      "mean:  [[[-0.00063 -2.29184]]] z: [[[0.126 1.518]]] std:  [[[0.14728 1.14341]]]\n",
      "mean:  [[[-0.01605  1.4401 ]]] z: [[[-0.699 -1.276]]] std:  [[[0.67568 0.5783 ]]]\n",
      "mean:  [[[ 0.04054 -2.17897]]] z: [[[-0.414 -2.36 ]]] std:  [[[0.15214 1.19247]]]\n",
      "mean:  [[[-0.00526  1.42915]]] z: [[[-2.029  0.42 ]]] std:  [[[0.67262 0.5869 ]]]\n",
      "mean:  [[[ 0.03127 -2.20503]]] z: [[[-0.405  0.923]]] std:  [[[0.15099 1.18744]]]\n",
      "mean:  [[[-0.01081  1.42772]]] z: [[[0.176 0.155]]] std:  [[[0.66978 0.58697]]]\n",
      "mean:  [[[ 0.03397 -2.1659 ]]] z: [[[ 1.281 -0.974]]] std:  [[[0.16285 1.1993 ]]]\n",
      "mean:  [[[0.158   1.38402]]] z: [[[0.172 1.947]]] std:  [[[0.69137 0.60291]]]\n",
      "mean:  [[[ 0.12938 -2.05354]]] z: [[[-1.356 -0.97 ]]] std:  [[[0.20273 1.62563]]]\n",
      "mean:  [[[0.24137 1.27236]]] z: [[[-0.612 -0.447]]] std:  [[[0.73485 0.64419]]]\n",
      "mean:  [[[ 0.23496 -1.82088]]] z: [[[-0.193 -0.099]]] std:  [[[0.2264 1.7506]]]\n",
      "mean:  [[[0.36614 1.21375]]] z: [[[ 0.669 -1.255]]] std:  [[[0.74554 0.64295]]]\n",
      "mean:  [[[ 0.27252 -1.82569]]] z: [[[-1.553 -1.365]]] std:  [[[0.25712 1.97988]]]\n",
      "mean:  [[[0.37379 1.10324]]] z: [[[ 2.118 -1.363]]] std:  [[[0.75722 0.67533]]]\n",
      "mean:  [[[ 0.24649 -1.81544]]] z: [[[ 1.959 -0.562]]] std:  [[[0.23611 1.81903]]]\n",
      "mean:  [[[0.36808 1.19148]]] z: [[[ 1.484 -1.084]]] std:  [[[0.74757 0.64361]]]\n",
      "mean:  [[[ 0.25473 -1.84589]]] z: [[[-1.057 -0.932]]] std:  [[[0.24951 1.94559]]]\n",
      "mean:  [[[0.49795 1.15631]]] z: [[[1.097 0.708]]] std:  [[[0.76994 0.6503 ]]]\n",
      "mean:  [[[ 0.37505 -1.91943]]] z: [[[-0.599  0.429]]] std:  [[[0.21573 2.14897]]]\n",
      "mean:  [[[0.87323 1.33856]]] z: [[[-0.016  0.69 ]]] std:  [[[1.17703 0.574  ]]]\n",
      "mean:  [[[ 0.44568 -1.73084]]] z: [[[0.777 0.209]]] std:  [[[0.21932 2.79923]]]\n",
      "mean:  [[[1.08335 1.13886]]] z: [[[-0.893 -0.196]]] std:  [[[1.11388 0.58845]]]\n",
      "mean:  [[[ 0.48947 -1.79057]]] z: [[[0.75  1.053]]] std:  [[[0.26458 2.35951]]]\n",
      "mean:  [[[0.94384 1.02343]]] z: [[[0.91  0.205]]] std:  [[[1.07765 0.72677]]]\n",
      "mean:  [[[ 0.35836 -1.58753]]] z: [[[-1.935  1.352]]] std:  [[[0.20868 2.08086]]]\n",
      "mean:  [[[1.15471 1.17935]]] z: [[[ 0.619 -0.269]]] std:  [[[1.10855 0.64145]]]\n",
      "mean:  [[[ 0.53679 -1.63807]]] z: [[[0.084 1.187]]] std:  [[[0.27827 2.08031]]]\n",
      "mean:  [[[0.63664 0.52089]]] z: [[[ 0.118 -0.605]]] std:  [[[1.04592 0.85354]]]\n",
      "mean:  [[[ 0.12307 -1.48169]]] z: [[[-0.992 -1.774]]] std:  [[[0.17948 1.70451]]]\n",
      "mean:  [[[1.26168 1.49703]]] z: [[[-2.224 -1.148]]] std:  [[[1.25447 0.54452]]]\n",
      "mean:  [[[ 0.38455 -1.95399]]] z: [[[ 0.87  -0.512]]] std:  [[[0.18387 0.81502]]]\n",
      "mean:  [[[ 0.15959 -0.13872]]] z: [[[0.842 0.199]]] std:  [[[0.8004  1.06735]]]\n",
      "mean:  [[[-0.04173 -1.93289]]] z: [[[-0.783 -1.044]]] std:  [[[0.15036 1.11685]]]\n",
      "mean:  [[[0.51641 1.17067]]] z: [[[-0.699 -0.787]]] std:  [[[0.93712 0.71707]]]\n",
      "mean:  [[[ 0.22407 -1.44313]]] z: [[[-0.633  1.137]]] std:  [[[0.20762 2.03956]]]\n",
      "mean:  [[[0.64222 0.76487]]] z: [[[-0.926 -0.607]]] std:  [[[0.88224 0.69898]]]\n",
      "mean:  [[[ 0.18963 -1.59654]]] z: [[[0.848 1.542]]] std:  [[[0.2178  1.91348]]]\n",
      "mean:  [[[0.20758 1.0423 ]]] z: [[[-0.378 -0.799]]] std:  [[[0.70911 0.65667]]]\n",
      "mean:  [[[-0.04147 -2.34487]]] z: [[[-0.102  1.21 ]]] std:  [[[0.12117 1.12551]]]\n",
      "mean:  [[[-0.01986  1.39341]]] z: [[[-0.088  0.405]]] std:  [[[0.66828 0.62851]]]\n",
      "mean:  [[[-0.07745 -2.4307 ]]] z: [[[-0.662 -0.642]]] std:  [[[0.11618 1.10127]]]\n",
      "mean:  [[[-0.01254  1.38368]]] z: [[[ 0.371 -0.389]]] std:  [[[0.67592 0.63511]]]\n",
      "mean:  [[[-0.05654 -2.3608 ]]] z: [[[1.539 0.65 ]]] std:  [[[0.12058 1.09789]]]\n",
      "mean:  [[[-0.01863  1.37776]]] z: [[[-0.26   1.088]]] std:  [[[0.67739 0.63941]]]\n",
      "mean:  [[[-0.0693  -2.37275]]] z: [[[-1.691  0.272]]] std:  [[[0.12148 1.14046]]]\n",
      "mean:  [[[-0.01158  1.42379]]] z: [[[0.679 1.369]]] std:  [[[0.64214 0.59832]]]\n",
      "mean:  [[[-0.1296  -2.58679]]] z: [[[0.107 0.091]]] std:  [[[0.10245 1.15695]]]\n",
      "mean:  [[[-0.00705  1.44249]]] z: [[[-0.388 -0.474]]] std:  [[[0.66447 0.59886]]]\n",
      "mean:  [[[-0.14461 -2.64624]]] z: [[[0.352 0.232]]] std:  [[[0.09923 1.25891]]]\n",
      "mean:  [[[0.00943 1.41184]]] z: [[[ 0.653 -1.103]]] std:  [[[0.65124 0.61288]]]\n",
      "mean:  [[[-0.11067 -2.62116]]] z: [[[ 0.026 -0.195]]] std:  [[[0.10884 1.32604]]]\n",
      "mean:  [[[0.01543 1.36376]]] z: [[[ 0.163 -0.914]]] std:  [[[0.65999 0.64275]]]\n",
      "mean:  [[[-0.10014 -2.58484]]] z: [[[ 0.015 -1.448]]] std:  [[[0.10996 1.29327]]]\n",
      "mean:  [[[0.01167 1.37303]]] z: [[[1.985 0.353]]] std:  [[[0.65941 0.63654]]]\n",
      "mean:  [[[-0.10073 -2.58859]]] z: [[[-0.167  2.038]]] std:  [[[0.10937 1.30532]]]\n",
      "mean:  [[[0.0155 1.3651]]] z: [[[-0.27  -0.347]]] std:  [[[0.65388 0.64777]]]\n",
      "mean:  [[[-0.0769  -2.50911]]] z: [[[-0.11  -0.071]]] std:  [[[0.11382 1.3084 ]]]\n",
      "mean:  [[[0.01621 1.35131]]] z: [[[ 0.68 -1.77]]] std:  [[[0.65479 0.65395]]]\n",
      "mean:  [[[-0.05747 -2.35467]]] z: [[[-0.076 -2.447]]] std:  [[[0.12342 1.14684]]]\n",
      "mean:  [[[-0.02154  1.47517]]] z: [[[0.817 1.324]]] std:  [[[0.6546  0.57621]]]\n",
      "mean:  [[[-0.05654 -2.3559 ]]] z: [[[-0.182 -0.815]]] std:  [[[0.12027 1.21752]]]\n",
      "mean:  [[[0.00012 1.39091]]] z: [[[1.093 0.398]]] std:  [[[0.66601 0.61138]]]\n",
      "mean:  [[[-0.0546  -2.36525]]] z: [[[-1.012  1.602]]] std:  [[[0.12246 1.20522]]]\n",
      "mean:  [[[-0.00169  1.39872]]] z: [[[-0.253 -2.194]]] std:  [[[0.66124 0.6064 ]]]\n",
      "mean:  [[[-0.03555 -2.32023]]] z: [[[-1.554 -0.152]]] std:  [[[0.13133 1.22315]]]\n",
      "13.10 action: [-0.036 -0.981] n_targets: 1 reward: 68.08 cost_for_stop_vel: 31.92\n",
      "mean:  [[[0.00344 1.36721]]] z: [[[-0.111 -0.387]]] std:  [[[0.64751 0.61179]]]\n",
      "mean:  [[[-0.00514 -2.21462]]] z: [[[-0.345  0.928]]] std:  [[[0.13543 1.17436]]]\n",
      "mean:  [[[0.09411 1.30139]]] z: [[[-0.105  2.499]]] std:  [[[0.65065 0.60426]]]\n",
      "mean:  [[[ 0.31143 -1.66061]]] z: [[[1.722 1.028]]] std:  [[[0.1863  1.65145]]]\n",
      "mean:  [[[0.50724 1.16842]]] z: [[[0.145 1.066]]] std:  [[[0.76187 0.60967]]]\n",
      "mean:  [[[ 0.08607 -2.01574]]] z: [[[0.733 0.209]]] std:  [[[0.16165 1.65221]]]\n",
      "mean:  [[[0.03445 1.46779]]] z: [[[-1.115  1.253]]] std:  [[[0.62294 0.55825]]]\n",
      "mean:  [[[-0.02893 -2.29943]]] z: [[[ 0.014 -2.184]]] std:  [[[0.12872 1.13408]]]\n",
      "mean:  [[[-0.02427  1.46688]]] z: [[[0.803 1.853]]] std:  [[[0.65662 0.57786]]]\n",
      "mean:  [[[-0.03329 -2.31703]]] z: [[[-0.37  -0.802]]] std:  [[[0.12968 1.09745]]]\n",
      "mean:  [[[-0.02696  1.43116]]] z: [[[ 1.148 -1.612]]] std:  [[[0.66083 0.60775]]]\n",
      "mean:  [[[-0.02907 -2.30378]]] z: [[[-0.737  0.068]]] std:  [[[0.13582 1.10324]]]\n",
      "mean:  [[[-0.02987  1.45748]]] z: [[[-0.629  0.981]]] std:  [[[0.65859 0.57901]]]\n",
      "mean:  [[[-0.00498 -2.22901]]] z: [[[0.189 1.024]]] std:  [[[0.14017 1.12577]]]\n",
      "mean:  [[[-0.02093  1.49481]]] z: [[[-0.06   0.198]]] std:  [[[0.66792 0.5561 ]]]\n",
      "mean:  [[[-0.05943 -2.39028]]] z: [[[-0.657  0.909]]] std:  [[[0.132   1.19606]]]\n",
      "mean:  [[[-0.02927  1.46651]]] z: [[[1.124 0.09 ]]] std:  [[[0.66954 0.57113]]]\n",
      "mean:  [[[-0.04881 -2.33728]]] z: [[[-0.066  0.977]]] std:  [[[0.13578 1.16315]]]\n",
      "mean:  [[[-0.03597  1.47371]]] z: [[[0.747 0.162]]] std:  [[[0.66749 0.56714]]]\n",
      "mean:  [[[-0.06321 -2.37415]]] z: [[[-0.335 -2.249]]] std:  [[[0.1332  1.16211]]]\n",
      "mean:  [[[-0.03293  1.45846]]] z: [[[0.209 0.808]]] std:  [[[0.66399 0.5755 ]]]\n",
      "mean:  [[[-0.03408 -2.30092]]] z: [[[ 2.155 -0.421]]] std:  [[[0.13688 1.14206]]]\n",
      "mean:  [[[-0.03223  1.41936]]] z: [[[0.421 0.665]]] std:  [[[0.6551  0.60044]]]\n",
      "mean:  [[[-0.02458 -2.27914]]] z: [[[-0.922  0.954]]] std:  [[[0.14216 1.11836]]]\n",
      "mean:  [[[-0.03543  1.42046]]] z: [[[-0.382 -0.843]]] std:  [[[0.65291 0.60104]]]\n",
      "mean:  [[[-0.02735 -2.28158]]] z: [[[-0.455  0.534]]] std:  [[[0.14162 1.10905]]]\n",
      "mean:  [[[-0.03581  1.42257]]] z: [[[0.871 1.125]]] std:  [[[0.65201 0.60004]]]\n",
      "mean:  [[[-0.04304 -2.33523]]] z: [[[1.172 0.81 ]]] std:  [[[0.13433 1.11293]]]\n",
      "mean:  [[[-0.03151  1.43359]]] z: [[[ 1.36  -1.634]]] std:  [[[0.66273 0.59582]]]\n",
      "mean:  [[[-0.03525 -2.30338]]] z: [[[-0.045 -0.776]]] std:  [[[0.12879 1.09353]]]\n",
      "16.10 action: [-0.035 -0.98] n_targets: 1 reward: 68.46 cost_for_stop_vel: 31.54\n",
      "mean:  [[[-0.0384   1.46964]]] z: [[[-0.3   -0.536]]] std:  [[[0.66967 0.57673]]]\n",
      "mean:  [[[-0.04902 -2.38034]]] z: [[[-0.175 -0.808]]] std:  [[[0.12609 1.14025]]]\n",
      "mean:  [[[-0.02355  1.42775]]] z: [[[ 0.584 -1.04 ]]] std:  [[[0.67522 0.60883]]]\n",
      "mean:  [[[-0.04079 -2.36292]]] z: [[[-0.001 -0.348]]] std:  [[[0.12843 1.12456]]]\n",
      "mean:  [[[-0.03392  1.48273]]] z: [[[ 1.228 -0.094]]] std:  [[[0.66644 0.56974]]]\n",
      "mean:  [[[ 0.00216 -2.21574]]] z: [[[-0.493 -1.187]]] std:  [[[0.13714 1.10698]]]\n",
      "mean:  [[[-0.03791  1.47659]]] z: [[[-0.423 -0.015]]] std:  [[[0.66449 0.57549]]]\n",
      "mean:  [[[ 0.0031  -2.21027]]] z: [[[0.279 0.599]]] std:  [[[0.14023 1.12685]]]\n",
      "mean:  [[[-0.01203  1.47394]]] z: [[[ 0.722 -1.32 ]]] std:  [[[0.65908 0.56782]]]\n",
      "mean:  [[[-0.01092 -2.25489]]] z: [[[ 1.584 -1.591]]] std:  [[[0.14797 1.17131]]]\n",
      "mean:  [[[-0.01255  1.48477]]] z: [[[-0.253 -0.287]]] std:  [[[0.65498 0.5666 ]]]\n",
      "mean:  [[[ 0.00017 -2.14562]]] z: [[[ 1.02  -0.227]]] std:  [[[0.15892 1.30345]]]\n",
      "mean:  [[[0.11188 1.42827]]] z: [[[-1.024 -0.164]]] std:  [[[0.70699 0.5969 ]]]\n",
      "mean:  [[[ 0.05663 -2.00104]]] z: [[[0.826 0.176]]] std:  [[[0.1718  1.50636]]]\n",
      "mean:  [[[0.18978 1.39479]]] z: [[[-0.641 -0.673]]] std:  [[[0.72574 0.61298]]]\n",
      "mean:  [[[ 0.08412 -1.95163]]] z: [[[0.421 0.137]]] std:  [[[0.17848 1.59988]]]\n",
      "mean:  [[[0.23004 1.38578]]] z: [[[ 1.664 -0.26 ]]] std:  [[[0.72968 0.61008]]]\n",
      "mean:  [[[ 0.09932 -1.92424]]] z: [[[ 0.146 -0.972]]] std:  [[[0.18364 1.67475]]]\n",
      "mean:  [[[0.25462 1.37404]]] z: [[[0.778 0.186]]] std:  [[[0.73349 0.61047]]]\n",
      "mean:  [[[ 0.09731 -1.94756]]] z: [[[-0.123  1.187]]] std:  [[[0.1835  1.71054]]]\n",
      "mean:  [[[0.2459  1.36922]]] z: [[[ 0.029 -0.452]]] std:  [[[0.73056 0.61063]]]\n",
      "mean:  [[[ 0.01107 -2.2488 ]]] z: [[[0.766 0.316]]] std:  [[[0.15314 1.45401]]]\n",
      "mean:  [[[-0.00187  1.44227]]] z: [[[ 0.039 -0.797]]] std:  [[[0.65873 0.58274]]]\n",
      "mean:  [[[-0.02238 -2.28972]]] z: [[[-1.334  2.662]]] std:  [[[0.14542 1.16601]]]\n",
      "mean:  [[[-0.02604  1.47086]]] z: [[[-0.048 -1.849]]] std:  [[[0.65207 0.57084]]]\n",
      "mean:  [[[ 0.00354 -2.21825]]] z: [[[-0.974 -1.236]]] std:  [[[0.14667 1.16223]]]\n",
      "mean:  [[[-0.04055  1.42541]]] z: [[[ 0.23  -0.353]]] std:  [[[0.66416 0.60381]]]\n",
      "mean:  [[[-0.04094 -2.3079 ]]] z: [[[ 0.042 -1.235]]] std:  [[[0.12466 1.05022]]]\n",
      "mean:  [[[-0.04036  1.50539]]] z: [[[-2.785 -1.664]]] std:  [[[0.66776 0.55283]]]\n",
      "mean:  [[[-0.01951 -2.2647 ]]] z: [[[ 0.237 -1.181]]] std:  [[[0.12982 1.12811]]]\n",
      "mean:  [[[-0.0397   1.48138]]] z: [[[-0.017 -2.073]]] std:  [[[0.67257 0.56714]]]\n",
      "mean:  [[[-0.01171 -2.25352]]] z: [[[-0.128  0.537]]] std:  [[[0.1354  1.14115]]]\n",
      "mean:  [[[-0.03974  1.46099]]] z: [[[0.067 0.445]]] std:  [[[0.66502 0.57512]]]\n",
      "mean:  [[[-0.07618 -2.46754]]] z: [[[1.224 0.321]]] std:  [[[0.12312 1.13609]]]\n",
      "mean:  [[[-0.02662  1.42469]]] z: [[[ 0.319 -0.16 ]]] std:  [[[0.67781 0.61639]]]\n",
      "mean:  [[[-0.06984 -2.4132 ]]] z: [[[0.359 0.52 ]]] std:  [[[0.12773 1.12983]]]\n",
      "mean:  [[[-0.03287  1.42895]]] z: [[[0.438 0.006]]] std:  [[[0.67621 0.6153 ]]]\n",
      "mean:  [[[-0.07806 -2.42358]]] z: [[[ 1.151 -0.713]]] std:  [[[0.12622 1.12588]]]\n",
      "mean:  [[[-0.02946  1.42279]]] z: [[[0.381 0.115]]] std:  [[[0.67911 0.62669]]]\n",
      "mean:  [[[-0.07604 -2.40748]]] z: [[[-0.103 -0.176]]] std:  [[[0.12707 1.118  ]]]\n",
      "mean:  [[[-0.03357  1.48476]]] z: [[[0.26  0.192]]] std:  [[[0.66834 0.55457]]]\n",
      "mean:  [[[-0.0163  -2.31084]]] z: [[[1.356 0.06 ]]] std:  [[[0.13913 1.17872]]]\n",
      "mean:  [[[-0.04417  1.42427]]] z: [[[-0.273 -1.316]]] std:  [[[0.66762 0.60219]]]\n",
      "mean:  [[[-0.03793 -2.35009]]] z: [[[-1.61  -1.285]]] std:  [[[0.13483 1.10693]]]\n",
      "mean:  [[[-0.04428  1.457  ]]] z: [[[-1.014  2.184]]] std:  [[[0.66268 0.58144]]]\n",
      "mean:  [[[-0.03374 -2.32724]]] z: [[[1.804 0.701]]] std:  [[[0.13995 1.15505]]]\n",
      "mean:  [[[-0.03601  1.42944]]] z: [[[-1.534 -1.219]]] std:  [[[0.65869 0.59251]]]\n",
      "mean:  [[[-0.05369 -2.36999]]] z: [[[ 1.003 -0.466]]] std:  [[[0.12877 1.10243]]]\n",
      "mean:  [[[-0.02931  1.40561]]] z: [[[2.035 1.668]]] std:  [[[0.67334 0.63566]]]\n",
      "mean:  [[[-0.05084 -2.34326]]] z: [[[ 0.604 -0.7  ]]] std:  [[[0.13019 1.09815]]]\n",
      "mean:  [[[-0.03745  1.42473]]] z: [[[-0.255  0.41 ]]] std:  [[[0.68291 0.62562]]]\n",
      "mean:  [[[-0.0406  -2.31123]]] z: [[[0.451 0.717]]] std:  [[[0.12199 1.05527]]]\n",
      "mean:  [[[-0.05139  1.48958]]] z: [[[ 0.127 -0.048]]] std:  [[[0.66611 0.57111]]]\n",
      "mean:  [[[-0.00492 -2.20551]]] z: [[[ 0.881 -0.176]]] std:  [[[0.13436 1.06511]]]\n",
      "mean:  [[[-0.06133  1.45453]]] z: [[[-0.151  0.396]]] std:  [[[0.66241 0.59849]]]\n",
      "mean:  [[[-0.03742 -2.27721]]] z: [[[-0.901 -0.087]]] std:  [[[0.13137 1.04033]]]\n",
      "mean:  [[[-0.05175  1.4753 ]]] z: [[[-0.273  0.102]]] std:  [[[0.66556 0.58542]]]\n",
      "mean:  [[[-0.03119 -2.26906]]] z: [[[0.926 1.662]]] std:  [[[0.13648 1.07449]]]\n",
      "mean:  [[[-0.05155  1.46033]]] z: [[[0.892 0.195]]] std:  [[[0.66335 0.59371]]]\n",
      "mean:  [[[-0.05379 -2.32429]]] z: [[[ 2.101 -0.292]]] std:  [[[0.13346 1.07349]]]\n",
      "mean:  [[[-0.04986  1.49342]]] z: [[[1.868 0.333]]] std:  [[[0.66051 0.56786]]]\n",
      "mean:  [[[-0.03354 -2.25242]]] z: [[[ 0.405 -1.058]]] std:  [[[0.1372  1.07521]]]\n",
      "mean:  [[[-0.05681  1.49377]]] z: [[[-1.9   -1.018]]] std:  [[[0.6572  0.56692]]]\n",
      "mean:  [[[-0.03082 -2.24865]]] z: [[[ 1.369 -0.335]]] std:  [[[0.13786 1.06696]]]\n",
      "mean:  [[[-0.05698  1.49266]]] z: [[[-0.283 -1.008]]] std:  [[[0.65585 0.56682]]]\n",
      "mean:  [[[-0.05984 -2.32442]]] z: [[[ 1.398 -0.295]]] std:  [[[0.13362 1.08532]]]\n",
      "mean:  [[[-0.05363  1.49612]]] z: [[[0.751 1.435]]] std:  [[[0.66372 0.56126]]]\n",
      "mean:  [[[-0.07344 -2.37267]]] z: [[[-0.834  0.191]]] std:  [[[0.13411 1.10151]]]\n",
      "mean:  [[[-0.05123  1.49362]]] z: [[[-0.664 -1.163]]] std:  [[[0.66397 0.56093]]]\n",
      "mean:  [[[-0.04833 -2.30909]]] z: [[[-0.211  0.362]]] std:  [[[0.13984 1.11255]]]\n",
      "mean:  [[[-0.05606  1.46954]]] z: [[[-0.418  0.473]]] std:  [[[0.66014 0.58008]]]\n",
      "mean:  [[[-0.05102 -2.30694]]] z: [[[-1.325  1.468]]] std:  [[[0.1401  1.08152]]]\n",
      "mean:  [[[-0.0565   1.49835]]] z: [[[0.576 0.041]]] std:  [[[0.66665 0.56012]]]\n",
      "mean:  [[[-0.01842 -2.23378]]] z: [[[ 1.323 -1.08 ]]] std:  [[[0.14137 1.10282]]]\n",
      "mean:  [[[-0.059    1.45334]]] z: [[[0.023 1.955]]] std:  [[[0.65649 0.59064]]]\n",
      "mean:  [[[-0.02711 -2.24819]]] z: [[[ 0.591 -2.11 ]]] std:  [[[0.14059 1.06009]]]\n",
      "mean:  [[[-0.05416  1.46761]]] z: [[[ 0.521 -0.56 ]]] std:  [[[0.66334 0.58407]]]\n",
      "mean:  [[[-0.03079 -2.31069]]] z: [[[-0.333 -2.653]]] std:  [[[0.14002 1.10017]]]\n",
      "mean:  [[[-0.04771  1.45078]]] z: [[[-0.085 -0.815]]] std:  [[[0.66239 0.58969]]]\n",
      "mean:  [[[-0.02522 -2.29108]]] z: [[[-1.587  1.041]]] std:  [[[0.14215 1.09222]]]\n",
      "mean:  [[[-0.05365  1.45775]]] z: [[[-0.694  3.924]]] std:  [[[0.66397 0.58758]]]\n",
      "mean:  [[[-0.03522 -2.316  ]]] z: [[[0.405 0.121]]] std:  [[[0.13937 1.09414]]]\n",
      "mean:  [[[-0.04924  1.45426]]] z: [[[-0.222  1.031]]] std:  [[[0.66208 0.59036]]]\n",
      "mean:  [[[-0.03856 -2.31568]]] z: [[[-0.684  0.294]]] std:  [[[0.13974 1.09088]]]\n",
      "mean:  [[[-0.04437  1.47463]]] z: [[[ 0.199 -0.309]]] std:  [[[0.66158 0.57625]]]\n",
      "mean:  [[[ 0.02228 -2.1796 ]]] z: [[[2.174 0.497]]] std:  [[[0.14534 1.09454]]]\n",
      "mean:  [[[-0.03498  1.48882]]] z: [[[ 1.515 -1.553]]] std:  [[[0.66317 0.56408]]]\n",
      "mean:  [[[-0.01146 -2.29598]]] z: [[[-0.012  0.186]]] std:  [[[0.13929 1.12186]]]\n",
      "mean:  [[[-0.01442  1.46031]]] z: [[[-0.311  1.05 ]]] std:  [[[0.67567 0.56824]]]\n",
      "mean:  [[[-0.04544 -2.41252]]] z: [[[ 0.388 -1.329]]] std:  [[[0.12837 1.19132]]]\n",
      "mean:  [[[-0.03591  1.44525]]] z: [[[-1.571 -0.813]]] std:  [[[0.67617 0.58207]]]\n",
      "mean:  [[[-0.00951 -2.27504]]] z: [[[-1.781  0.078]]] std:  [[[0.13829 1.15764]]]\n",
      "mean:  [[[-0.02388  1.47571]]] z: [[[-0.451 -1.215]]] std:  [[[0.66143 0.57611]]]\n",
      "mean:  [[[-0.048   -2.34001]]] z: [[[-0.127 -0.94 ]]] std:  [[[0.12441 1.13327]]]\n",
      "mean:  [[[-0.04506  1.50606]]] z: [[[-0.521 -0.46 ]]] std:  [[[0.66479 0.5561 ]]]\n",
      "mean:  [[[-0.03146 -2.29127]]] z: [[[-2.027 -0.059]]] std:  [[[0.12727 1.12377]]]\n",
      "mean:  [[[-0.04787  1.50227]]] z: [[[ 1.969 -0.172]]] std:  [[[0.66568 0.55839]]]\n",
      "mean:  [[[-0.03361 -2.29018]]] z: [[[-1.375  1.866]]] std:  [[[0.12664 1.11967]]]\n",
      "mean:  [[[-0.04955  1.48574]]] z: [[[ 0.249 -0.966]]] std:  [[[0.66162 0.56205]]]\n",
      "mean:  [[[-0.02355 -2.27844]]] z: [[[0.748 0.99 ]]] std:  [[[0.13351 1.12705]]]\n",
      "mean:  [[[-0.05751  1.47677]]] z: [[[-1.079  0.034]]] std:  [[[0.66941 0.56591]]]\n",
      "mean:  [[[-0.02691 -2.26284]]] z: [[[ 2.219 -0.223]]] std:  [[[0.12447 1.0966 ]]]\n",
      "mean:  [[[-0.05751  1.4882 ]]] z: [[[ 0.654 -0.65 ]]] std:  [[[0.66535 0.55979]]]\n",
      "mean:  [[[-0.03319 -2.29955]]] z: [[[-0.831  0.971]]] std:  [[[0.12286 1.09663]]]\n",
      "mean:  [[[-0.03536  1.39191]]] z: [[[-0.308 -0.612]]] std:  [[[0.67896 0.63729]]]\n",
      "mean:  [[[-0.04551 -2.30736]]] z: [[[-1.088 -0.364]]] std:  [[[0.12153 1.08101]]]\n",
      "mean:  [[[-0.04725  1.46869]]] z: [[[-0.656  1.075]]] std:  [[[0.66519 0.57171]]]\n",
      "mean:  [[[-0.01518 -2.20177]]] z: [[[-1.219 -1.058]]] std:  [[[0.12793 1.07748]]]\n",
      "mean:  [[[-0.05902  1.46393]]] z: [[[-1.226 -0.788]]] std:  [[[0.66438 0.5751 ]]]\n",
      "mean:  [[[-0.01858 -2.2036 ]]] z: [[[-0.061 -2.05 ]]] std:  [[[0.12651 1.06071]]]\n",
      "mean:  [[[-0.05742  1.46348]]] z: [[[-1.225  0.426]]] std:  [[[0.66695 0.58088]]]\n",
      "mean:  [[[-0.02904 -2.24009]]] z: [[[ 1.125 -1.035]]] std:  [[[0.12623 1.05519]]]\n",
      "mean:  [[[-0.05485  1.45573]]] z: [[[ 1.065 -0.914]]] std:  [[[0.66611 0.58742]]]\n",
      "mean:  [[[-0.00938 -2.21201]]] z: [[[2.404 0.595]]] std:  [[[0.12522 1.06474]]]\n",
      "mean:  [[[-0.05414  1.45599]]] z: [[[-0.534  0.501]]] std:  [[[0.66699 0.57747]]]\n",
      "mean:  [[[-0.01586 -2.24281]]] z: [[[-0.519 -0.093]]] std:  [[[0.12283 1.08386]]]\n",
      "mean:  [[[-0.04876  1.44315]]] z: [[[ 0.379 -1.281]]] std:  [[[0.66842 0.58491]]]\n",
      "mean:  [[[-0.04278 -2.3075 ]]] z: [[[-0.829  1.181]]] std:  [[[0.11561 1.06395]]]\n",
      "mean:  [[[-0.03741  1.44807]]] z: [[[-1.138  1.567]]] std:  [[[0.67385 0.58948]]]\n",
      "mean:  [[[-0.03979 -2.28717]]] z: [[[ 0.252 -1.815]]] std:  [[[0.11711 1.07494]]]\n",
      "mean:  [[[-0.03984  1.44931]]] z: [[[-1.525 -0.277]]] std:  [[[0.67234 0.58504]]]\n",
      "mean:  [[[-0.0407  -2.28049]]] z: [[[-0.541  1.916]]] std:  [[[0.11698 1.07108]]]\n",
      "mean:  [[[-0.04264  1.47266]]] z: [[[ 1.043 -0.125]]] std:  [[[0.66271 0.57145]]]\n",
      "mean:  [[[-0.10081 -2.47536]]] z: [[[-2.576 -0.329]]] std:  [[[0.10865 1.17252]]]\n",
      "mean:  [[[-0.00845  1.39075]]] z: [[[-2.766 -1.542]]] std:  [[[0.66768 0.62378]]]\n",
      "mean:  [[[-0.11746 -2.52452]]] z: [[[-1.126 -1.378]]] std:  [[[0.10866 1.20708]]]\n",
      "mean:  [[[-0.00904  1.4395 ]]] z: [[[0.208 1.932]]] std:  [[[0.65602 0.59054]]]\n",
      "mean:  [[[-0.1198  -2.52408]]] z: [[[0.865 1.92 ]]] std:  [[[0.10676 1.22839]]]\n",
      "mean:  [[[-0.00696  1.43175]]] z: [[[0.182 1.144]]] std:  [[[0.65569 0.59604]]]\n",
      "mean:  [[[-0.11733 -2.51286]]] z: [[[-0.758  1.626]]] std:  [[[0.10666 1.22072]]]\n",
      "mean:  [[[-0.01031  1.4401 ]]] z: [[[ 0.782 -0.202]]] std:  [[[0.66063 0.59071]]]\n",
      "mean:  [[[-0.1212  -2.52924]]] z: [[[-1.053  1.445]]] std:  [[[0.09901 1.21596]]]\n",
      "mean:  [[[-0.00882  1.4365 ]]] z: [[[0.215 1.043]]] std:  [[[0.65947 0.59232]]]\n",
      "mean:  [[[-0.1131  -2.52516]]] z: [[[ 0.407 -0.826]]] std:  [[[0.09642 1.20531]]]\n",
      "mean:  [[[-0.00634  1.39772]]] z: [[[-0.362  0.461]]] std:  [[[0.66998 0.61692]]]\n",
      "mean:  [[[-0.09926 -2.49452]]] z: [[[-0.356  1.181]]] std:  [[[0.10444 1.21535]]]\n",
      "mean:  [[[0.00328 1.35175]]] z: [[[-0.482  0.355]]] std:  [[[0.6732  0.63501]]]\n",
      "mean:  [[[-0.036   -2.42025]]] z: [[[ 0.406 -1.243]]] std:  [[[0.11456 1.26624]]]\n",
      "mean:  [[[-0.00179  1.32738]]] z: [[[0.471 0.455]]] std:  [[[0.67555 0.64692]]]\n",
      "mean:  [[[-0.03547 -2.43086]]] z: [[[-0.692 -0.538]]] std:  [[[0.1182  1.26404]]]\n",
      "mean:  [[[-0.01153  1.35308]]] z: [[[-0.242  1.295]]] std:  [[[0.67628 0.62567]]]\n",
      "mean:  [[[-0.04145 -2.46086]]] z: [[[ 0.529 -0.935]]] std:  [[[0.11748 1.29966]]]\n",
      "mean:  [[[0.02199 1.26095]]] z: [[[-1.103  2.378]]] std:  [[[0.67977 0.66878]]]\n",
      "mean:  [[[ 0.02206 -2.30721]]] z: [[[-1.101  0.89 ]]] std:  [[[0.12648 1.25981]]]\n",
      "mean:  [[[0.06382 1.34917]]] z: [[[0.658 0.223]]] std:  [[[0.67547 0.6501 ]]]\n",
      "mean:  [[[ 0.07548 -2.21103]]] z: [[[ 1.216 -0.389]]] std:  [[[0.15516 1.65956]]]\n",
      "mean:  [[[0.08555 1.18419]]] z: [[[ 0.738 -1.147]]] std:  [[[0.70364 0.713  ]]]\n",
      "mean:  [[[ 0.07555 -2.24675]]] z: [[[ 0.621 -0.541]]] std:  [[[0.15635 1.54821]]]\n",
      "mean:  [[[0.07317 1.21594]]] z: [[[-0.809  0.288]]] std:  [[[0.6977  0.69809]]]\n",
      "mean:  [[[ 0.08006 -2.22001]]] z: [[[-0.629  0.11 ]]] std:  [[[0.15838 1.55937]]]\n",
      "mean:  [[[0.07489 1.21081]]] z: [[[-0.668  1.108]]] std:  [[[0.69868 0.69688]]]\n",
      "mean:  [[[ 0.07435 -2.24557]]] z: [[[ 0.137 -0.255]]] std:  [[[0.1583 1.562 ]]]\n",
      "mean:  [[[0.13663 1.12063]]] z: [[[0.101 1.307]]] std:  [[[0.72447 0.73036]]]\n",
      "mean:  [[[ 0.20273 -2.14311]]] z: [[[-1.895  0.294]]] std:  [[[0.19551 1.7164 ]]]\n",
      "mean:  [[[0.22214 1.02592]]] z: [[[ 0.628 -0.564]]] std:  [[[0.85931 0.79563]]]\n",
      "mean:  [[[ 0.3803  -1.66064]]] z: [[[ 0.205 -0.366]]] std:  [[[0.22745 1.85842]]]\n",
      "mean:  [[[0.37228 0.97471]]] z: [[[-0.279  1.275]]] std:  [[[0.9066  0.80864]]]\n",
      "mean:  [[[ 0.49343 -1.60731]]] z: [[[-0.03   0.153]]] std:  [[[0.2632 2.078 ]]]\n",
      "mean:  [[[0.6259  1.06703]]] z: [[[0.55  0.013]]] std:  [[[0.9838  0.69685]]]\n",
      "mean:  [[[ 0.71751 -1.47791]]] z: [[[2.037 0.828]]] std:  [[[0.41638 2.43206]]]\n",
      "mean:  [[[0.58268 0.87337]]] z: [[[ 0.388 -0.505]]] std:  [[[1.05116 0.74884]]]\n",
      "mean:  [[[ 0.62142 -1.51212]]] z: [[[-2.338 -0.484]]] std:  [[[0.3399  2.17057]]]\n",
      "mean:  [[[0.72808 1.21789]]] z: [[[-0.245 -1.219]]] std:  [[[1.07448 0.64877]]]\n",
      "mean:  [[[ 0.68007 -1.45992]]] z: [[[ 0.774 -0.36 ]]] std:  [[[0.43083 2.37597]]]\n",
      "mean:  [[[0.77203 1.63235]]] z: [[[1.482 1.509]]] std:  [[[1.38465 0.4995 ]]]\n",
      "mean:  [[[ 0.45778 -1.79816]]] z: [[[-1.956 -0.716]]] std:  [[[0.21034 2.94694]]]\n",
      "mean:  [[[0.61265 1.37641]]] z: [[[ 0.899 -0.204]]] std:  [[[1.36827 0.53219]]]\n",
      "mean:  [[[ 0.4628  -1.69399]]] z: [[[ 0.019 -0.81 ]]] std:  [[[0.23707 3.62727]]]\n",
      "mean:  [[[0.7283 1.5921]]] z: [[[-0.75 -0.2 ]]] std:  [[[1.47269 0.50749]]]\n",
      "mean:  [[[ 0.61833 -1.66744]]] z: [[[0.11  1.084]]] std:  [[[0.33585 3.14156]]]\n",
      "mean:  [[[0.8765  1.05663]]] z: [[[-1.261  0.725]]] std:  [[[1.27895 0.679  ]]]\n",
      "mean:  [[[ 0.49589 -1.22229]]] z: [[[-1.088  1.121]]] std:  [[[0.32128 3.16202]]]\n",
      "mean:  [[[1.16243 1.41206]]] z: [[[1.428 1.879]]] std:  [[[1.17761 0.64255]]]\n",
      "mean:  [[[ 0.49716 -1.87047]]] z: [[[-0.43  -1.428]]] std:  [[[0.24947 2.27443]]]\n",
      "mean:  [[[0.7508  0.81314]]] z: [[[-1.031 -1.036]]] std:  [[[1.07078 0.8687 ]]]\n",
      "mean:  [[[ 0.1464  -1.61715]]] z: [[[-0.787  0.698]]] std:  [[[0.17464 2.02468]]]\n",
      "mean:  [[[1.32379 1.57299]]] z: [[[-0.254  0.312]]] std:  [[[1.2825  0.55619]]]\n",
      "mean:  [[[ 0.42071 -2.03806]]] z: [[[-0.504 -0.747]]] std:  [[[0.18232 1.03441]]]\n",
      "mean:  [[[0.31438 0.17561]]] z: [[[1.072 0.727]]] std:  [[[1.00549 1.02674]]]\n",
      "mean:  [[[ 0.01896 -1.90646]]] z: [[[0.701 1.468]]] std:  [[[0.14504 0.92362]]]\n",
      "mean:  [[[-0.05023  1.46791]]] z: [[[2.001 0.714]]] std:  [[[0.66503 0.55948]]]\n",
      "mean:  [[[-0.06168 -2.30982]]] z: [[[-0.952  0.011]]] std:  [[[0.12184 0.97052]]]\n",
      "mean:  [[[-0.05061  1.49056]]] z: [[[ 0.586 -1.182]]] std:  [[[0.67921 0.56847]]]\n",
      "mean:  [[[-0.07037 -2.34842]]] z: [[[-1.252 -0.016]]] std:  [[[0.12292 1.00945]]]\n",
      "mean:  [[[-0.04525  1.4554 ]]] z: [[[3.2  0.76]]] std:  [[[0.69156 0.60423]]]\n",
      "mean:  [[[-0.06922 -2.33272]]] z: [[[-0.547  1.717]]] std:  [[[0.12711 1.02034]]]\n",
      "mean:  [[[-0.0473   1.44905]]] z: [[[-0.698 -0.367]]] std:  [[[0.6935  0.61773]]]\n",
      "mean:  [[[-0.06819 -2.31311]]] z: [[[0.665 0.128]]] std:  [[[0.12802 1.00867]]]\n",
      "mean:  [[[-0.0483   1.44656]]] z: [[[ 0.789 -0.571]]] std:  [[[0.68926 0.62549]]]\n",
      "mean:  [[[-0.00319 -2.15052]]] z: [[[-1.324 -1.007]]] std:  [[[0.14562 1.04691]]]\n",
      "mean:  [[[-0.07224  1.46554]]] z: [[[-0.857 -1.009]]] std:  [[[0.65701 0.58343]]]\n",
      "mean:  [[[-0.0588  -2.31263]]] z: [[[-1.864 -0.572]]] std:  [[[0.13505 1.0349 ]]]\n",
      "mean:  [[[-0.04306  1.45033]]] z: [[[-1.685 -0.34 ]]] std:  [[[0.67255 0.60397]]]\n",
      "mean:  [[[-0.05153 -2.28883]]] z: [[[0.796 1.133]]] std:  [[[0.13799 1.05706]]]\n",
      "mean:  [[[-0.04634  1.44224]]] z: [[[ 0.368 -0.449]]] std:  [[[0.67338 0.61088]]]\n",
      "mean:  [[[-0.0574  -2.29799]]] z: [[[0.256 0.156]]] std:  [[[0.13719 1.05282]]]\n",
      "mean:  [[[-0.04551  1.44674]]] z: [[[-1.042 -1.24 ]]] std:  [[[0.67172 0.6083 ]]]\n",
      "mean:  [[[-0.08168 -2.35406]]] z: [[[-1.267 -0.043]]] std:  [[[0.13767 1.08166]]]\n",
      "mean:  [[[-0.03975  1.46072]]] z: [[[ 1.444 -0.401]]] std:  [[[0.6612  0.57851]]]\n",
      "mean:  [[[-0.05323 -2.26977]]] z: [[[-1.229  0.214]]] std:  [[[0.1408  1.09143]]]\n",
      "mean:  [[[-0.05017  1.46031]]] z: [[[-0.012  1.713]]] std:  [[[0.65927 0.57892]]]\n",
      "mean:  [[[-0.04446 -2.23776]]] z: [[[-1.107  0.86 ]]] std:  [[[0.14199 1.07317]]]\n",
      "mean:  [[[-0.05194  1.45234]]] z: [[[ 1.149 -0.987]]] std:  [[[0.66207 0.5783 ]]]\n",
      "mean:  [[[-0.04395 -2.25413]]] z: [[[ 1.45  -0.514]]] std:  [[[0.13852 1.08777]]]\n",
      "mean:  [[[-0.04746  1.45559]]] z: [[[-1.58   1.224]]] std:  [[[0.66953 0.57781]]]\n",
      "mean:  [[[-0.03969 -2.25681]]] z: [[[-0.918  0.619]]] std:  [[[0.13458 1.08769]]]\n",
      "mean:  [[[-0.04777  1.45422]]] z: [[[2.352 1.296]]] std:  [[[0.66883 0.57891]]]\n",
      "mean:  [[[-0.06796 -2.31466]]] z: [[[0.238 0.61 ]]] std:  [[[0.12549 1.0808 ]]]\n",
      "mean:  [[[-0.03034  1.47589]]] z: [[[ 1.585 -1.762]]] std:  [[[0.67775 0.56415]]]\n",
      "mean:  [[[-0.07105 -2.3519 ]]] z: [[[0.848 0.059]]] std:  [[[0.1211  1.14716]]]\n",
      "mean:  [[[-0.01052  1.43361]]] z: [[[-1.146 -1.102]]] std:  [[[0.68125 0.58745]]]\n",
      "mean:  [[[-0.02962 -2.2368 ]]] z: [[[-0.934  0.069]]] std:  [[[0.12737 1.13458]]]\n",
      "mean:  [[[-0.04524  1.49666]]] z: [[[ 2.401 -1.008]]] std:  [[[0.67022 0.55595]]]\n",
      "mean:  [[[-0.02759 -2.22339]]] z: [[[1.488 0.669]]] std:  [[[0.13369 1.12519]]]\n",
      "mean:  [[[-0.03875  1.47694]]] z: [[[ 1.101 -0.533]]] std:  [[[0.66969 0.56504]]]\n",
      "mean:  [[[-0.02541 -2.21996]]] z: [[[-1.989 -1.091]]] std:  [[[0.13458 1.12   ]]]\n",
      "mean:  [[[-0.03871  1.47742]]] z: [[[-2.583 -0.41 ]]] std:  [[[0.66855 0.56384]]]\n",
      "mean:  [[[-0.04709 -2.3016 ]]] z: [[[-1.26 -3.43]]] std:  [[[0.13107 1.1333 ]]]\n",
      "mean:  [[[-0.03005  1.46205]]] z: [[[-1.312 -0.667]]] std:  [[[0.66668 0.57467]]]\n",
      "mean:  [[[-0.06583 -2.36146]]] z: [[[ 1.407 -0.56 ]]] std:  [[[0.13111 1.13983]]]\n",
      "mean:  [[[-0.02438  1.44163]]] z: [[[1.578 0.463]]] std:  [[[0.6645  0.59074]]]\n",
      "mean:  [[[-0.06928 -2.35577]]] z: [[[0.741 0.614]]] std:  [[[0.13206 1.13567]]]\n",
      "mean:  [[[-0.02451  1.44408]]] z: [[[-0.909 -0.194]]] std:  [[[0.66189 0.58865]]]\n",
      "mean:  [[[-0.07819 -2.37224]]] z: [[[-0.392  1.463]]] std:  [[[0.13112 1.14604]]]\n",
      "mean:  [[[-0.0212  1.444 ]]] z: [[[-1.34   0.704]]] std:  [[[0.65953 0.5876 ]]]\n",
      "mean:  [[[-0.01796 -2.22893]]] z: [[[-1.376 -0.646]]] std:  [[[0.1396  1.16028]]]\n",
      "mean:  [[[-0.02318  1.39831]]] z: [[[-0.646 -1.465]]] std:  [[[0.64851 0.60211]]]\n",
      "mean:  [[[-0.01743 -2.22626]]] z: [[[-1.523  1.39 ]]] std:  [[[0.14025 1.12342]]]\n",
      "mean:  [[[-0.02562  1.40531]]] z: [[[-0.982  0.162]]] std:  [[[0.6469  0.59688]]]\n",
      "mean:  [[[-0.02253 -2.23639]]] z: [[[ 0.88  -1.298]]] std:  [[[0.14003 1.13113]]]\n",
      "mean:  [[[-0.01997  1.39221]]] z: [[[ 1.239 -0.288]]] std:  [[[0.64555 0.60302]]]\n",
      "mean:  [[[-0.07047 -2.37007]]] z: [[[-1.737  0.461]]] std:  [[[0.12474 1.12611]]]\n",
      "mean:  [[[-0.0188   1.44613]]] z: [[[0.293 0.12 ]]] std:  [[[0.67476 0.5794 ]]]\n",
      "mean:  [[[-0.07423 -2.39867]]] z: [[[ 2.893 -1.552]]] std:  [[[0.1182  1.20112]]]\n",
      "mean:  [[[-0.01167  1.4251 ]]] z: [[[-0.728 -0.201]]] std:  [[[0.67614 0.59338]]]\n",
      "mean:  [[[-0.06566 -2.37695]]] z: [[[-0.976  0.903]]] std:  [[[0.11853 1.17915]]]\n",
      "mean:  [[[-0.01717  1.4295 ]]] z: [[[0.988 1.109]]] std:  [[[0.67437 0.59071]]]\n",
      "mean:  [[[-0.06039 -2.35152]]] z: [[[0.316 0.359]]] std:  [[[0.11853 1.16806]]]\n",
      "mean:  [[[-0.02082  1.45733]]] z: [[[ 0.67  -1.189]]] std:  [[[0.67542 0.57373]]]\n",
      "mean:  [[[-0.02282 -2.24628]]] z: [[[ 0.619 -0.611]]] std:  [[[0.12288 1.16721]]]\n",
      "mean:  [[[-0.02506  1.43092]]] z: [[[-1.658 -1.276]]] std:  [[[0.66513 0.58578]]]\n",
      "mean:  [[[-0.00132 -2.19892]]] z: [[[-0.345  0.182]]] std:  [[[0.13118 1.15361]]]\n",
      "mean:  [[[-0.03175  1.4317 ]]] z: [[[ 0.581 -0.163]]] std:  [[[0.66441 0.5836 ]]]\n",
      "mean:  [[[-0.01061 -2.22511]]] z: [[[-1.226  1.381]]] std:  [[[0.12882 1.15026]]]\n",
      "mean:  [[[0.03576 1.42216]]] z: [[[1.565 0.278]]] std:  [[[0.66229 0.58028]]]\n",
      "mean:  [[[ 0.0503  -2.10394]]] z: [[[-0.221  1.091]]] std:  [[[0.1534  1.32683]]]\n",
      "mean:  [[[0.07938 1.38024]]] z: [[[-0.893 -1.09 ]]] std:  [[[0.6621  0.59425]]]\n",
      "mean:  [[[ 0.07502 -2.05977]]] z: [[[0.241 0.988]]] std:  [[[0.15866 1.35551]]]\n",
      "mean:  [[[0.09948 1.37631]]] z: [[[ 1.645 -0.611]]] std:  [[[0.66219 0.5938 ]]]\n",
      "mean:  [[[ 0.09988 -2.02774]]] z: [[[-0.877 -1.376]]] std:  [[[0.16936 1.41888]]]\n",
      "mean:  [[[0.46007 1.26729]]] z: [[[1.32  0.847]]] std:  [[[0.75502 0.61998]]]\n",
      "mean:  [[[ 0.39619 -1.69453]]] z: [[[ 0.355 -0.719]]] std:  [[[0.29848 1.66488]]]\n",
      "mean:  [[[0.25333 0.40994]]] z: [[[0.207 0.109]]] std:  [[[0.90002 0.9757 ]]]\n",
      "mean:  [[[ 0.2    -1.9815]]] z: [[[-0.84   0.625]]] std:  [[[0.17517 1.25024]]]\n",
      "mean:  [[[0.41759 1.22155]]] z: [[[-0.674 -0.089]]] std:  [[[0.77096 0.64833]]]\n",
      "mean:  [[[ 0.40515 -1.79852]]] z: [[[ 1.987 -0.157]]] std:  [[[0.32098 1.83101]]]\n",
      "mean:  [[[0.24317 0.32809]]] z: [[[ 0.786 -0.003]]] std:  [[[0.85324 0.9851 ]]]\n",
      "mean:  [[[ 0.21602 -2.02769]]] z: [[[-1.314 -1.271]]] std:  [[[0.17167 1.22428]]]\n",
      "mean:  [[[0.41838 1.20559]]] z: [[[0.656 0.337]]] std:  [[[0.75434 0.65237]]]\n",
      "mean:  [[[ 0.48567 -1.85384]]] z: [[[-0.702 -0.415]]] std:  [[[0.21817 2.42399]]]\n",
      "mean:  [[[0.53766 0.93111]]] z: [[[-0.811 -0.748]]] std:  [[[1.21993 0.77433]]]\n",
      "mean:  [[[ 0.07274 -1.88376]]] z: [[[0.498 0.358]]] std:  [[[0.1846  1.80607]]]\n",
      "mean:  [[[0.93886 1.49333]]] z: [[[0.045 0.579]]] std:  [[[1.08208 0.64299]]]\n",
      "mean:  [[[ 0.4627  -1.85239]]] z: [[[0.58  1.127]]] std:  [[[0.26382 2.33328]]]\n",
      "mean:  [[[0.46863 0.47337]]] z: [[[ 1.246 -1.684]]] std:  [[[0.98358 1.01396]]]\n",
      "mean:  [[[-0.00353 -1.98424]]] z: [[[-0.091 -0.044]]] std:  [[[0.15107 1.1604 ]]]\n",
      "mean:  [[[-0.06208  1.47922]]] z: [[[0.244 0.677]]] std:  [[[0.65229 0.56785]]]\n",
      "mean:  [[[-0.04576 -2.25909]]] z: [[[1.401 1.766]]] std:  [[[0.13695 1.03908]]]\n",
      "mean:  [[[-0.04727  1.43195]]] z: [[[-1.745 -0.919]]] std:  [[[0.6844  0.61864]]]\n",
      "mean:  [[[-0.09107 -2.40354]]] z: [[[ 0.559 -0.373]]] std:  [[[0.12621 1.06374]]]\n",
      "mean:  [[[-0.03231  1.43916]]] z: [[[0.447 0.374]]] std:  [[[0.6841  0.61491]]]\n",
      "mean:  [[[-0.08913 -2.39129]]] z: [[[ 0.819 -0.258]]] std:  [[[0.1276  1.08276]]]\n",
      "mean:  [[[-0.03418  1.45058]]] z: [[[-1.203 -1.255]]] std:  [[[0.67824 0.59901]]]\n",
      "mean:  [[[-0.05383 -2.30946]]] z: [[[-0.069 -1.125]]] std:  [[[0.13387 1.08909]]]\n",
      "mean:  [[[-0.04351  1.43864]]] z: [[[ 0.101 -0.266]]] std:  [[[0.67641 0.60806]]]\n",
      "mean:  [[[-0.06309 -2.33034]]] z: [[[-0.337  0.178]]] std:  [[[0.13231 1.0727 ]]]\n",
      "mean:  [[[-0.04124  1.44465]]] z: [[[ 0.479 -1.331]]] std:  [[[0.67472 0.60326]]]\n",
      "mean:  [[[-0.0673  -2.34322]]] z: [[[-1.692  0.035]]] std:  [[[0.13172 1.08188]]]\n",
      "mean:  [[[-0.04152  1.46422]]] z: [[[-1.364 -0.392]]] std:  [[[0.67006 0.57802]]]\n",
      "mean:  [[[-0.06096 -2.31522]]] z: [[[-0.888  0.186]]] std:  [[[0.13287 1.10337]]]\n",
      "mean:  [[[-0.04335  1.46431]]] z: [[[-1.223 -0.64 ]]] std:  [[[0.66806 0.57736]]]\n",
      "mean:  [[[-0.0718  -2.34543]]] z: [[[1.089 0.355]]] std:  [[[0.13312 1.10031]]]\n",
      "mean:  [[[-0.04538  1.46028]]] z: [[[-1.132 -0.317]]] std:  [[[0.6674  0.58534]]]\n",
      "mean:  [[[-0.05312 -2.2916 ]]] z: [[[0.357 0.583]]] std:  [[[0.13742 1.10836]]]\n",
      "mean:  [[[-0.05115  1.45902]]] z: [[[ 0.481 -1.478]]] std:  [[[0.66228 0.58012]]]\n",
      "mean:  [[[-0.04937 -2.2557 ]]] z: [[[-0.62  -0.287]]] std:  [[[0.13973 1.14101]]]\n",
      "mean:  [[[-0.03503  1.44846]]] z: [[[ 1.343 -0.507]]] std:  [[[0.64094 0.58149]]]\n",
      "mean:  [[[-0.0169  -2.11573]]] z: [[[ 0.363 -0.403]]] std:  [[[0.14562 1.12785]]]\n",
      "mean:  [[[-0.03165  1.45508]]] z: [[[-0.25  -0.659]]] std:  [[[0.64027 0.5877 ]]]\n",
      "mean:  [[[-0.01044 -2.07927]]] z: [[[-0.246 -0.158]]] std:  [[[0.14574 1.14211]]]\n",
      "mean:  [[[-0.02922  1.43667]]] z: [[[-0.345  1.907]]] std:  [[[0.64124 0.59464]]]\n",
      "mean:  [[[-0.01685 -2.10126]]] z: [[[ 0.662 -0.135]]] std:  [[[0.14365 1.13104]]]\n",
      "mean:  [[[-0.00988  1.44145]]] z: [[[ 0.249 -1.87 ]]] std:  [[[0.62078 0.59844]]]\n",
      "mean:  [[[ 0.04559 -1.8861 ]]] z: [[[-0.455  0.682]]] std:  [[[0.14943 1.21378]]]\n",
      "mean:  [[[0.07781 1.43639]]] z: [[[-0.254 -0.417]]] std:  [[[0.61632 0.58136]]]\n",
      "mean:  [[[-0.01127 -2.03153]]] z: [[[-0.421  0.957]]] std:  [[[0.14197 1.16079]]]\n",
      "mean:  [[[-0.03851  1.4662 ]]] z: [[[-0.712  0.944]]] std:  [[[0.63633 0.57969]]]\n",
      "mean:  [[[-0.02591 -1.75662]]] z: [[[0.017 0.192]]] std:  [[[0.15566 1.34262]]]\n",
      "mean:  [[[0.13843 1.0491 ]]] z: [[[-0.351 -2.053]]] std:  [[[0.71091 0.71251]]]\n",
      "mean:  [[[ 0.04364 -1.70238]]] z: [[[-0.7    0.839]]] std:  [[[0.16476 1.35403]]]\n",
      "mean:  [[[0.47177 0.89771]]] z: [[[1.146 0.578]]] std:  [[[0.68139 0.68228]]]\n",
      "mean:  [[[ 0.31007 -1.42326]]] z: [[[-0.662  1.855]]] std:  [[[0.22941 1.95633]]]\n",
      "mean:  [[[0.93679 1.2971 ]]] z: [[[-0.518 -1.638]]] std:  [[[1.03986 0.63657]]]\n",
      "mean:  [[[ 0.34703 -2.1048 ]]] z: [[[0.209 0.937]]] std:  [[[0.19403 2.02518]]]\n",
      "mean:  [[[0.79035 0.86375]]] z: [[[-1.221 -0.348]]] std:  [[[1.0707  0.78331]]]\n",
      "mean:  [[[ 0.10899 -2.04942]]] z: [[[1.545 0.246]]] std:  [[[0.1515  1.79002]]]\n",
      "mean:  [[[0.92338 0.96413]]] z: [[[ 0.004 -1.314]]] std:  [[[1.02309 0.65743]]]\n",
      "mean:  [[[ 0.37028 -1.67785]]] z: [[[-1.321  0.17 ]]] std:  [[[0.2616  2.27886]]]\n",
      "mean:  [[[0.59746 0.7358 ]]] z: [[[-1.378  0.221]]] std:  [[[1.07321 0.81025]]]\n",
      "mean:  [[[ 0.08941 -1.62868]]] z: [[[-0.683 -1.327]]] std:  [[[0.18119 1.59669]]]\n",
      "mean:  [[[0.85942 1.00803]]] z: [[[-0.184  0.897]]] std:  [[[0.97244 0.63392]]]\n",
      "mean:  [[[ 0.35286 -1.73418]]] z: [[[ 0.851 -1.269]]] std:  [[[0.24372 2.20839]]]\n",
      "mean:  [[[0.58526 0.69398]]] z: [[[ 0.994 -1.499]]] std:  [[[1.02585 0.8102 ]]]\n",
      "mean:  [[[ 0.11357 -1.65146]]] z: [[[0.197 0.201]]] std:  [[[0.19439 1.55367]]]\n",
      "mean:  [[[0.22356 1.07208]]] z: [[[0.864 0.421]]] std:  [[[0.71483 0.61925]]]\n",
      "mean:  [[[-0.07358 -2.44258]]] z: [[[-0.329  0.287]]] std:  [[[0.11744 1.13608]]]\n",
      "mean:  [[[-0.03164  1.40534]]] z: [[[0.507 0.035]]] std:  [[[0.69748 0.65178]]]\n",
      "mean:  [[[-0.09309 -2.5118 ]]] z: [[[ 0.193 -1.513]]] std:  [[[0.11709 1.16937]]]\n",
      "mean:  [[[-0.00111  1.35262]]] z: [[[-0.074 -0.658]]] std:  [[[0.69257 0.6633 ]]]\n",
      "mean:  [[[-0.10723 -2.57774]]] z: [[[-0.268  0.503]]] std:  [[[0.11517 1.2055 ]]]\n",
      "mean:  [[[-0.00144  1.40575]]] z: [[[0.124 0.308]]] std:  [[[0.68031 0.61395]]]\n",
      "mean:  [[[-0.1279  -2.54048]]] z: [[[ 1.446 -0.147]]] std:  [[[0.11372 1.16333]]]\n",
      "mean:  [[[-0.02305  1.48551]]] z: [[[-0.807  0.233]]] std:  [[[0.66017 0.57282]]]\n",
      "mean:  [[[-0.09927 -2.43647]]] z: [[[0.424 2.181]]] std:  [[[0.11994 1.20913]]]\n",
      "mean:  [[[-0.02517  1.44855]]] z: [[[-1.184  0.856]]] std:  [[[0.65404 0.58882]]]\n",
      "mean:  [[[-0.0639  -2.31406]]] z: [[[-0.329 -1.354]]] std:  [[[0.12568 1.11567]]]\n",
      "mean:  [[[-0.05422  1.49486]]] z: [[[ 0.681 -0.007]]] std:  [[[0.64464 0.56489]]]\n",
      "mean:  [[[-0.05714 -2.2853 ]]] z: [[[ 1.401 -1.295]]] std:  [[[0.12519 1.10202]]]\n",
      "mean:  [[[-0.05531  1.48646]]] z: [[[0.04  0.658]]] std:  [[[0.64576 0.56886]]]\n",
      "mean:  [[[-0.0616  -2.30282]]] z: [[[1.61  0.828]]] std:  [[[0.12369 1.09727]]]\n",
      "mean:  [[[-0.05444  1.48589]]] z: [[[-0.758  0.712]]] std:  [[[0.64556 0.56863]]]\n",
      "mean:  [[[-0.06613 -2.31705]]] z: [[[-0.228  0.635]]] std:  [[[0.12241 1.1016 ]]]\n",
      "mean:  [[[-0.04049  1.46385]]] z: [[[ 0.271 -0.116]]] std:  [[[0.66539 0.57389]]]\n",
      "mean:  [[[-0.05947 -2.34373]]] z: [[[0.107 1.517]]] std:  [[[0.1149  1.11415]]]\n",
      "mean:  [[[-0.03389  1.45762]]] z: [[[0.666 3.474]]] std:  [[[0.67316 0.57837]]]\n",
      "mean:  [[[-0.03932 -2.29542]]] z: [[[ 1.022 -0.32 ]]] std:  [[[0.11934 1.12164]]]\n",
      "mean:  [[[-0.04061  1.45572]]] z: [[[-1.968 -0.276]]] std:  [[[0.67351 0.57793]]]\n",
      "mean:  [[[-0.0508  -2.32665]]] z: [[[-0.788  1.414]]] std:  [[[0.11607 1.1208 ]]]\n",
      "mean:  [[[-0.03593  1.4383 ]]] z: [[[-1.268 -1.035]]] std:  [[[0.67215 0.59339]]]\n",
      "mean:  [[[-0.06715 -2.38667]]] z: [[[1.426 1.242]]] std:  [[[0.116  1.0847]]]\n",
      "mean:  [[[-0.03389  1.41018]]] z: [[[-0.703  0.232]]] std:  [[[0.68497 0.63855]]]\n",
      "mean:  [[[-0.05231 -2.3179 ]]] z: [[[-0.552 -1.245]]] std:  [[[0.12127 1.06709]]]\n",
      "mean:  [[[-0.04036  1.44282]]] z: [[[-0.512 -0.051]]] std:  [[[0.67904 0.60101]]]\n",
      "mean:  [[[-0.11218 -2.54089]]] z: [[[-0.719 -2.24 ]]] std:  [[[0.10357 1.12739]]]\n",
      "mean:  [[[-0.01908  1.37513]]] z: [[[-0.204 -0.062]]] std:  [[[0.70222 0.67914]]]\n",
      "mean:  [[[-0.10412 -2.46509]]] z: [[[-0.563  0.528]]] std:  [[[0.10959 1.10896]]]\n",
      "mean:  [[[-0.02419  1.37671]]] z: [[[ 1.684 -0.571]]] std:  [[[0.70086 0.67839]]]\n",
      "mean:  [[[-0.11656 -2.49194]]] z: [[[-0.293  1.08 ]]] std:  [[[0.10686 1.11571]]]\n",
      "mean:  [[[-0.02157  1.37965]]] z: [[[ 0.076 -1.122]]] std:  [[[0.69867 0.67621]]]\n",
      "mean:  [[[-0.11063 -2.47119]]] z: [[[-1.529  1.567]]] std:  [[[0.10783 1.10882]]]\n",
      "mean:  [[[-0.02347  1.37445]]] z: [[[-0.389  1.9  ]]] std:  [[[0.69841 0.67813]]]\n",
      "Firely capture rate for the episode:  4 ff for 51.20000000000046 s: -------------------> 0.08\n",
      "Total reward for the episode:  275.0944819301367\n",
      "Cost breakdown:  {'dv_cost': 0.0, 'dw_cost': 0.0, 'w_cost': 0.0}\n",
      "Reward for each ff:  [69.18046 69.3769  68.07788 68.45925]\n",
      "Best average reward: 328.91060991678387, Current average reward: 247.25454924628139\n"
     ]
    }
   ],
   "source": [
    "avg_reward = lstm_utils.evaluate_agent(\n",
    "    rl.env, rl.sac_model, 512, 2, deterministic=True)\n",
    "print(\n",
    "    f\"Best average reward: {rl.best_avg_reward}, Current average reward: {avg_reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeca84c",
   "metadata": {},
   "source": [
    "# class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve old model\n",
    "# env_kwargs = {'num_obs_ff': 2,\n",
    "#               'add_action_to_obs': True,\n",
    "#               'angular_terminal_vel': 1,\n",
    "#               \"reward_per_ff\": 100,\n",
    "#           \n",
    "#               \"dv_cost_factor\": 0,\n",
    "#               \"dw_cost_factor\": 0,\n",
    "#               \"w_cost_factor\": 0,\n",
    "#               \"dt\": 0.25,\n",
    "#               \"flash_on_interval\": 0.3\n",
    "#             }\n",
    "\n",
    "\n",
    "# rl = lstm_class.LSTMforMultifirefly(overall_folder='multiff_analysis/RL_models/LSTM_stored_models/all_agents/gen_-1/',\n",
    "#                                                 model_folder_name='multiff_analysis/RL_models/LSTM_stored_models/all_agents/gen_-1/LSTM_Jan_2',\n",
    "#                                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_kwargs = {'num_obs_ff': 3,\n",
    "              'add_action_to_obs': True,\n",
    "              'angular_terminal_vel': 1,\n",
    "              \"reward_per_ff\": 80,\n",
    "          \n",
    "              \"dv_cost_factor\": 0,\n",
    "              \"dw_cost_factor\": 0,\n",
    "              \"w_cost_factor\": 0,\n",
    "              \"dt\": 0.25,\n",
    "              \"flash_on_interval\": 0.3\n",
    "            }   \n",
    "rl = lstm_class.LSTMforMultifirefly(overall_folder='multiff_analysis/RL_models/LSTM_stored_models/all_agents/gen_1_3ff/',\n",
    "                                                **env_kwargs)\n",
    "\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0abce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl = lstm_class.LSTMforMultifirefly()\n",
    "\n",
    "env_kwargs = {\n",
    "              'num_obs_ff': 10,\n",
    "              'add_action_to_obs': True,\n",
    "              'angular_terminal_vel': 1,\n",
    "              \"dt\": 0.25,\n",
    "              \"flash_on_interval\": 0.3,\n",
    "          \n",
    "              \"dv_cost_factor\": 0,\n",
    "              \"dw_cost_factor\": 0,\n",
    "              \"w_cost_factor\": 0,\n",
    "            }   \n",
    "\n",
    "rl = lstm_class.LSTMforMultifirefly(overall_folder='multiff_analysis/RL_models/LSTM_stored_models/all_agents/gen_8_env2/',\n",
    "                                                \n",
    "                                                **env_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.make_env(**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.make_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.save_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.load_agent(load_replay_buffer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac06133",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.test_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.monkey_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl.ff_dataframe['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b573d59",
   "metadata": {},
   "source": [
    "## animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172ebfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curriculum_training kwargs\n",
    "env_kwargs = {\n",
    "              \n",
    "              'angular_terminal_vel': 1,\n",
    "              \"reward_per_ff\": 100,\n",
    "          \n",
    "              \"dv_cost_factor\": 0,\n",
    "              \"dw_cost_factor\": 0,\n",
    "              \"w_cost_factor\": 0,\n",
    "              \"dt\": 0.25,\n",
    "              \"flash_on_interval\": 2.1\n",
    "            }\n",
    "rl.env_kwargs.update(env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6537ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curriculum_training kwargs\n",
    "env_kwargs = {\n",
    "              \n",
    "              'angular_terminal_vel': 1,\n",
    "              \"reward_per_ff\": 100,\n",
    "          \n",
    "              \"dv_cost_factor\": 0,\n",
    "              \"dw_cost_factor\": 0,\n",
    "              \"w_cost_factor\": 0,\n",
    "              \"dt\": 0.25,\n",
    "              \"flash_on_interval\": 2.1\n",
    "            }\n",
    "rl.env_kwargs.update(env_kwargs)\n",
    "\n",
    "rl.streamline_making_animation(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40], n_steps=1000, video_dir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PkFUlYfELK_e",
   "metadata": {
    "id": "PkFUlYfELK_e"
   },
   "source": [
    "# Optuna (LSTM)\n",
    "\n",
    "(my own codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0vtL5qnLQ0e",
   "metadata": {
    "id": "d0vtL5qnLQ0e"
   },
   "source": [
    "##### sample_sac_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CM9Yhsb7LQ0e",
   "metadata": {
    "id": "CM9Yhsb7LQ0e"
   },
   "outputs": [],
   "source": [
    "def sample_sac_params(trial):\n",
    "    \"\"\"\n",
    "    Sampler for SAC hyperparams.\n",
    "    :param trial: (optuna.trial)\n",
    "    :return: (dict)\n",
    "    \"\"\"\n",
    "  \n",
    "    gamma = 1.0 - trial.suggest_float(\"1-gamma\", 1e-4, 0.1, log=True)\n",
    "    soft_q_lr = trial.suggest_float(\"soft_q_lr\", 1e-5, 1, log=True)\n",
    "    policy_lr = trial.suggest_float(\"policy_lr\", 1e-5, 1, log=True)\n",
    "    alpha_lr  = trial.suggest_float(\"alpha_lr\", 1e-5, 1, log=True)\n",
    "    batch_size  = trial.suggest_categorical('batch_size', [5, 10, 15, 20, 25, 30])\n",
    "    update_itr = trial.suggest_categorical('update_itr', [1, 2, 3, 5])\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [16, 32, 64, 100, 150, 200, 256])\n",
    "    reward_scale = trial.suggest_categorical('reward_scale', [1, 3, 5, 10, 15, 20]) # I updated after running\n",
    "    target_entropy = trial.suggest_categorical('target_entropy', [-1, -2, -3, -5, -8, -10]) # I updated after running\n",
    "    soft_tau= trial.suggest_float(\"soft_tau\", 1e-6, 1, log=True)\n",
    "    #activation_fn\n",
    "\n",
    "\n",
    "    return {\n",
    "        'gamma': gamma,\n",
    "        'soft_q_lr':soft_q_lr,\n",
    "        'policy_lr':policy_lr,\n",
    "        'alpha_lr':alpha_lr,\n",
    "        'batch_size': batch_size,\n",
    "        'update_itr':update_itr,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'reward_scale':reward_scale,\n",
    "        'target_entropy':target_entropy,\n",
    "        'soft_tau':soft_tau\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w8snZtlopA-9",
   "metadata": {
    "id": "w8snZtlopA-9"
   },
   "source": [
    "## put_in_fixed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1RFcdEk5pAmv",
   "metadata": {
    "id": "1RFcdEk5pAmv"
   },
   "outputs": [],
   "source": [
    "def put_in_fixed_params():\n",
    "    return {\n",
    "        'model_folder_name':  None, \n",
    "        'train_freq': 100, \n",
    "        'batch_size': 10, \n",
    "        'update_itr': 1,\n",
    "        'num_train_episodes': 50, \n",
    "        'eval_eps_freq': 10, \n",
    "        'max_steps_per_eps': 1024, \n",
    "        'auto_entropy': True, \n",
    "        'DETERMINISTIC': False, \n",
    "        'num_eval_episodes': 3, \n",
    "        'print_episode_reward':  True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9TMGTKP3LTVV",
   "metadata": {
    "id": "9TMGTKP3LTVV"
   },
   "source": [
    "## objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NhoGtlzHqxKY",
   "metadata": {
    "id": "NhoGtlzHqxKY"
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float: \n",
    "  try:\n",
    "    # Sample hyperparameters\n",
    "    kwargs = sample_sac_params(trial)\n",
    "    kwargs = put_in_fixed_params()\n",
    "\n",
    "    num_train_episodes = kwargs['num_train_episodes'] \n",
    "    eval_eps_freq = kwargs['eval_eps_freq']\n",
    "    max_steps_per_eps = kwargs['max_steps_per_eps'] \n",
    "    auto_entropy = kwargs['auto_entropy'] \n",
    "    num_eval_episodes = kwargs['num_eval_episodes'] \n",
    "    print_episode_reward = kwargs['print_episode_reward']\n",
    "\n",
    "\n",
    "    env = env_for_rnn.EnvForRNN()\n",
    "    sac_model = lstm_utils.SAC_Trainer(**kwargs)\n",
    "    rl2 = lstm_class.LSTMforMultifirefly()\n",
    "    rl2.sac_model = sac_model\n",
    "    sac_model, best_avg_reward_record, alpha_df = rl2.train_agent(env, device,\n",
    "                                                         num_train_episodes=num_train_episodes, eval_eps_freq=eval_eps_freq, max_steps_per_eps=max_steps_per_eps, \n",
    "                                                         num_eval_episodes=num_eval_episodes, print_episode_reward=print_episode_reward, auto_entropy=auto_entropy)\n",
    "\n",
    "  except ValueError as e:\n",
    "    # Sometimes, random hyperparams can generate NaN\n",
    "      print(e)\n",
    "\n",
    "  return best_avg_reward_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zWLQGb9cW2TQ",
   "metadata": {
    "id": "zWLQGb9cW2TQ"
   },
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L4wV8ncwW2TQ",
   "metadata": {
    "id": "L4wV8ncwW2TQ"
   },
   "outputs": [],
   "source": [
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "\n",
    "# Set pytorch num threads to 1 for faster training\n",
    "torch.set_num_threads(1)\n",
    " \n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "## Do not prune before 1/3 of the max budget is used\n",
    "# pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS 2//3 3)\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QvPXVRFfIbVD",
   "metadata": {
    "id": "QvPXVRFfIbVD"
   },
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z5vjDrdHrSn2",
   "metadata": {
    "id": "Z5vjDrdHrSn2"
   },
   "source": [
    "## collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yDZgRZMNHnZl",
   "metadata": {
    "id": "yDZgRZMNHnZl"
   },
   "outputs": [],
   "source": [
    "env = env_for_sb3.CollectInformationLSTM()\n",
    "env.flash_on_interval = 0.3\n",
    "env.distance2center_cost = 0\n",
    "sac_model.load_model(model_folder_name)\n",
    "\n",
    "env._run_agent_to_collect_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JlxfIO9YFFHe",
   "metadata": {
    "id": "JlxfIO9YFFHe"
   },
   "source": [
    "## prepare for animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6DqTSaOz6s38",
   "metadata": {
    "id": "6DqTSaOz6s38"
   },
   "outputs": [],
   "source": [
    "currentTrial = 2\n",
    "num_trials = 7\n",
    "k = 1\n",
    "fig, ax = plt.subplots()\n",
    "num_frames, anim_monkey_info, flash_on_ff_dict, alive_ff_dict, believed_ff_dict, new_num_trials, ff_dataframe_anim \\\n",
    "            = animation_utils.prepare_for_animation(ff_dataframe, ff_caught_T_new, ff_life_sorted, ff_believed_position_sorted, \n",
    "            ff_real_position_sorted, ff_flash_sorted, monkey_information, k=k, currentTrial=currentTrial, num_trials=num_trials)\n",
    "print(\"Number of frames is:\", num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AesCxkpsFbVn",
   "metadata": {
    "id": "AesCxkpsFbVn"
   },
   "source": [
    "## make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pUcR1X-0-OQo",
   "metadata": {
    "id": "pUcR1X-0-OQo"
   },
   "outputs": [],
   "source": [
    "animate_func = partial(animation_func.animate, ax=ax, anim_monkey_info=anim_monkey_info, ff_dataframe_anim=ff_dataframe_anim, ff_real_position_sorted=ff_real_position_sorted, \\\n",
    "                         flash_on_ff_dict=flash_on_ff_dict, alive_ff_dict=alive_ff_dict, believed_ff_dict=believed_ff_dict, margin = 400)\n",
    "anim = animation.FuncAnimation(fig, animate_func, frames=num_frames, interval=100, repeat=True) \n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-BX7XwsnFc4k",
   "metadata": {
    "id": "-BX7XwsnFc4k"
   },
   "source": [
    "## make animation with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aE9lp9YZ-H7c",
   "metadata": {
    "id": "aE9lp9YZ-H7c"
   },
   "outputs": [],
   "source": [
    "annotation_info = animation_utils.make_annotation_info(caught_ff_num+1, max_point_index, n_ff_in_a_row, visible_before_last_one_trials, disappear_latest_trials, \\\n",
    "                                        ignore_sudden_flash_indices, give_up_after_trying_indices, try_a_few_times_indices)\n",
    "animate_annotated_func = partial(animation_func.animate_annotated, ax=ax, anim_monkey_info=anim_monkey_info, margin=margin, ff_dataframe=ff_dataframe, \\\n",
    "                                   flash_on_ff_dict=flash_on_ff_dict, alive_ff_dict=alive_ff_dict, believed_ff_dict=believed_ff_dict, ff_caught_T_new=ff_caught_T_new, annotation_info=annotation_info)\n",
    "anim_annotated = animation.FuncAnimation(fig, animate_annotated_func, frames=num_frames, interval=100, repeat=True) \n",
    "HTML(anim_annotated.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8mO9eLF5U7Y",
   "metadata": {
    "id": "h8mO9eLF5U7Y"
   },
   "source": [
    "# Debug"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1FShUys0iUmi3huyQwtaEdyhGivLG2R_5",
     "timestamp": 1681095282536
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
