{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76cf94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cicid/miniconda3/envs/multiff_clean/bin/ffmpeg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.which(\"ffmpeg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1t_MmbnQxz3f",
   "metadata": {
    "id": "1t_MmbnQxz3f"
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (0.14.2)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from neo) (25.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from neo) (1.26.4)\n",
      "Requirement already satisfied: quantities>=0.16.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from neo) (0.16.2)\n",
      "Requirement already satisfied: matplotlib_scalebar in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib_scalebar) (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->matplotlib_scalebar) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->matplotlib_scalebar) (1.17.0)\n",
      "Collecting ffmpeg\n",
      "  Using cached ffmpeg-1.4-py3-none-any.whl\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "Requirement already satisfied: wheel==0.38.4 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (0.38.4)\n",
      "Collecting setuptools==65.5.0\n",
      "  Using cached setuptools-65.5.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Using cached setuptools-65.5.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 72.1.0\n",
      "    Uninstalling setuptools-72.1.0:\n",
      "      Successfully uninstalled setuptools-72.1.0\n",
      "Successfully installed setuptools-65.5.0\n",
      "Requirement already satisfied: stable_baselines3 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from stable_baselines3) (1.2.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from stable_baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from stable_baselines3) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from stable_baselines3) (3.1.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from stable_baselines3) (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from stable_baselines3) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.13.1)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from pandas->stable_baselines3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from pandas->stable_baselines3) (2025.2)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.43-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: sqlalchemy, Mako, colorlog, alembic, optuna\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [optuna]2m4/5\u001b[0m [optuna]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 alembic-1.16.5 colorlog-6.9.0 optuna-4.5.0 sqlalchemy-2.0.43\n"
     ]
    }
   ],
   "source": [
    "# !pip install neo\n",
    "# !pip install matplotlib_scalebar\n",
    "# !pip install ffmpeg\n",
    "# !pip install wheel==0.38.4\n",
    "# !pip3 install setuptools==65.5.0\n",
    "# !pip install stable_baselines3\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9904b001",
   "metadata": {
    "id": "9904b001"
   },
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d7921b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32160,
     "status": "ok",
     "timestamp": 1684945803461,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "78d7921b",
    "outputId": "68f69138-fbc7-40e8-db4e-f3bea17f3a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    " \n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information\n",
    "from pattern_discovery import pattern_by_trials, make_ff_dataframe, pattern_by_trials, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_trials, plot_polar, additional_plots, plot_behaviors_utils, plot_statistics\n",
    "from visualization.animation import animation_func, animation_utils, animation_class\n",
    "from machine_learning.RL.env_related import env_for_lstm, env_utils, base_env, collect_agent_data, process_agent_data, env_for_sb3\n",
    "from machine_learning.RL.lstm import GRU_functions, LSTM_functions\n",
    "from machine_learning.RL.SB3 import interpret_neural_network, sb3_for_multiff_class, rl_for_multiff_utils, SB3_functions\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.results_plotter import plot_results\n",
    "from stable_baselines3.common.callbacks import StopTrainingOnNoModelImprovement\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from IPython.display import HTML\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import random\n",
    "from importlib import reload\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement, StopTrainingOnRewardThreshold\n",
    "import gc\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "matplotlib.rcParams[\"animation.ffmpeg_path\"] = shutil.which(\"ffmpeg\")\n",
    "matplotlib.rcParams[\"animation.writer\"] = \"ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b4cb6e9",
   "metadata": {
    "id": "2b4cb6e9"
   },
   "source": [
    "## basic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f61c2",
   "metadata": {
    "id": "d64f61c2"
   },
   "outputs": [],
   "source": [
    "overall_folder = \"RL_models/SB3_stored_models/all_agents/gen_5/\"\n",
    "os.makedirs(overall_folder, exist_ok=True)\n",
    "PLAYER = \"agent\"\n",
    "# NEW_DATASET = True\n",
    "# MONKEY_DATA = False\n",
    "# NO_PLOT_NEEDED = True\n",
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0219\"\n",
    "# data_folder_name = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0219/processed_data\"\n",
    "#data_num = 19\n",
    "\n",
    "\n",
    "# # for agent\n",
    "# PLAYER = \"agent\"\n",
    "# NEW_DATASET = True\n",
    "# MONKEY_DATA = False\n",
    "# NO_PLOT_NEEDED = True\n",
    "# data_folder_name = \"env.multiff_analysis/RL_models/LSTM_July_29\"\n",
    "# data_num = 721\n",
    "# trial_total_num = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac8034",
   "metadata": {},
   "source": [
    "# Streamline training agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2542d",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3eac088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"RL_models/SB3_stored_models/all_agents/regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_folder_name = \"RL_models/SB3_stored_models/all_agents/temp_10_11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME before resetting: 0\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -5056.8419241677575\n",
      "Cost breakdown:  {'dv_cost': 4599.850343783376, 'dw_cost': 279.4307915093483, 'w_cost': 177.56078887503423}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  1\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4696.892005801193\n",
      "Cost breakdown:  {'dv_cost': 4279.769888663881, 'dw_cost': 251.98250530548208, 'w_cost': 165.13961183182332}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  2\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4888.147028866372\n",
      "Cost breakdown:  {'dv_cost': 4438.161956948115, 'dw_cost': 277.83980917780906, 'w_cost': 172.1452627404483}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  3\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4708.880618203562\n",
      "Cost breakdown:  {'dv_cost': 4239.996223327801, 'dw_cost': 288.10100075003, 'w_cost': 180.78339412574496}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  4\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -5160.751181640856\n",
      "Cost breakdown:  {'dv_cost': 4708.470968262796, 'dw_cost': 274.7257311000618, 'w_cost': 177.55448227800392}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  5\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4783.660142133785\n",
      "Cost breakdown:  {'dv_cost': 4347.414702499479, 'dw_cost': 269.8722643409354, 'w_cost': 166.3731752933852}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  6\n",
      "59.4 action:  [0.0004, -0.9893] n_targets:  1 reward:  100\n",
      "Firely capture rate for the episode:  1 ff for 102.49999999999845 s: -------------------> 0.01\n",
      "Total reward for the episode:  -4738.127828836951\n",
      "Cost breakdown:  {'dv_cost': 4387.85040418352, 'dw_cost': 278.0305941636243, 'w_cost': 172.24683048981706}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  7\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4824.942524233356\n",
      "Cost breakdown:  {'dv_cost': 4377.811003397795, 'dw_cost': 273.245595507645, 'w_cost': 173.88592532791793}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  8\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4636.008533588514\n",
      "Cost breakdown:  {'dv_cost': 4183.326245468334, 'dw_cost': 281.36761262652476, 'w_cost': 171.31467549365792}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  9\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4920.4160175572615\n",
      "Cost breakdown:  {'dv_cost': 4495.686754221333, 'dw_cost': 257.6423479050244, 'w_cost': 167.0869154308995}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  10\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -4903.80298536505\n",
      "Cost breakdown:  {'dv_cost': 4433.498750990614, 'dw_cost': 292.08627107066854, 'w_cost': 178.217963303775}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  11\n",
      "74.3 action:  [-0.0061, -0.995] n_targets:  1 reward:  100\n",
      "Firely capture rate for the episode:  1 ff for 102.49999999999845 s: -------------------> 0.01\n",
      "Total reward for the episode:  -2240.775890071013\n",
      "Cost breakdown:  {'dv_cost': 1864.252351309974, 'dw_cost': 291.4329776309432, 'w_cost': 185.09056113009783}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  12\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -1236.782933608034\n",
      "Cost breakdown:  {'dv_cost': 791.4763006963993, 'dw_cost': 265.11915323942225, 'w_cost': 180.18747967221202}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  13\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -822.3697743073855\n",
      "Cost breakdown:  {'dv_cost': 351.8420340850741, 'dw_cost': 284.81710331112816, 'w_cost': 185.71063691118448}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  14\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -682.5228784537414\n",
      "Cost breakdown:  {'dv_cost': 212.79629958025924, 'dw_cost': 284.1393417008527, 'w_cost': 185.58723717263015}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  15\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -655.4638087061547\n",
      "Cost breakdown:  {'dv_cost': 186.37057702947897, 'dw_cost': 287.0054399424842, 'w_cost': 182.0877917341912}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  16\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -577.8531868434151\n",
      "Cost breakdown:  {'dv_cost': 176.57438862525527, 'dw_cost': 220.54487613939415, 'w_cost': 180.73392207876608}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  17\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -530.1756345246224\n",
      "Cost breakdown:  {'dv_cost': 154.88548586065332, 'dw_cost': 203.47884290420103, 'w_cost': 171.8113057597687}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  18\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -467.93151760410456\n",
      "Cost breakdown:  {'dv_cost': 158.36491023343976, 'dw_cost': 154.9833387688444, 'w_cost': 154.58326860182032}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  19\n",
      " \n",
      "Current timesteps: 20000\n",
      "Current mean training reward per episode: -3185.91 compared to best mean training reward on record: -inf\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -441.1041649014926\n",
      "Cost breakdown:  {'dv_cost': 159.52076473072344, 'dw_cost': 131.51924234374167, 'w_cost': 150.0641578270276}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  20\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -399.5637591988889\n",
      "Cost breakdown:  {'dv_cost': 150.73368790382344, 'dw_cost': 108.13925867083748, 'w_cost': 140.6908126242279}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  21\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -351.1406159135955\n",
      "Cost breakdown:  {'dv_cost': 129.87956924310225, 'dw_cost': 96.86273266705288, 'w_cost': 124.39831400344069}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  22\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -348.70305602010535\n",
      "Cost breakdown:  {'dv_cost': 143.83357245122824, 'dw_cost': 90.6971772808277, 'w_cost': 114.17230628804958}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  23\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -315.5447439737755\n",
      "Cost breakdown:  {'dv_cost': 135.69142549387044, 'dw_cost': 81.85528989313173, 'w_cost': 97.99802858677303}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  24\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -291.96356148475434\n",
      "Cost breakdown:  {'dv_cost': 138.62542380352215, 'dw_cost': 65.29529613589189, 'w_cost': 88.04284154533995}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  25\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -299.6516563008826\n",
      "Cost breakdown:  {'dv_cost': 141.10771854937678, 'dw_cost': 68.32058154182738, 'w_cost': 90.22335620967831}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  26\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -262.77425394407476\n",
      "Cost breakdown:  {'dv_cost': 119.66270743019076, 'dw_cost': 66.45444536164152, 'w_cost': 76.65710115224215}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  27\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -241.83823481516777\n",
      "Cost breakdown:  {'dv_cost': 109.36557327730223, 'dw_cost': 56.6629971268493, 'w_cost': 75.80966441101634}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  28\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -237.3638286072198\n",
      "Cost breakdown:  {'dv_cost': 116.45897604636197, 'dw_cost': 52.054934724227685, 'w_cost': 68.84991783662994}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  29\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -242.8242270789398\n",
      "Cost breakdown:  {'dv_cost': 125.84629242821582, 'dw_cost': 49.60715474748564, 'w_cost': 67.37077990323849}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  30\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -199.1434740164946\n",
      "Cost breakdown:  {'dv_cost': 111.97347056853698, 'dw_cost': 37.74774017357343, 'w_cost': 49.4222632743842}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  31\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -200.47778829465474\n",
      "Cost breakdown:  {'dv_cost': 109.37023803106753, 'dw_cost': 39.40917927353114, 'w_cost': 51.698370990056}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  32\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -190.68674387765313\n",
      "Cost breakdown:  {'dv_cost': 102.40274024047748, 'dw_cost': 36.49502630993203, 'w_cost': 51.788977327243494}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  33\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -183.37835839379224\n",
      "Cost breakdown:  {'dv_cost': 104.74402915118702, 'dw_cost': 35.36854303180536, 'w_cost': 43.26578621079994}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  34\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -171.70424407427464\n",
      "Cost breakdown:  {'dv_cost': 99.24462494201241, 'dw_cost': 30.08295361815474, 'w_cost': 42.376665514107216}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  35\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -162.28712562280157\n",
      "Cost breakdown:  {'dv_cost': 96.65967363178427, 'dw_cost': 28.23928509032725, 'w_cost': 37.38816690069003}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  36\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -167.7192346556427\n",
      "Cost breakdown:  {'dv_cost': 103.74218620413498, 'dw_cost': 27.91540866112072, 'w_cost': 36.06163979038722}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  37\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -162.82964935394057\n",
      "Cost breakdown:  {'dv_cost': 98.09647317588538, 'dw_cost': 28.991454163888065, 'w_cost': 35.74172201416719}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  38\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.9560383551431\n",
      "Cost breakdown:  {'dv_cost': 94.8179885987731, 'dw_cost': 26.758836850019335, 'w_cost': 28.37921290635034}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  39\n",
      " \n",
      "Current timesteps: 40000\n",
      "Current mean training reward per episode: -1680.85 compared to best mean training reward on record: -3185.91\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -150.56733657668752\n",
      "Cost breakdown:  {'dv_cost': 88.83711872405934, 'dw_cost': 28.236090670537962, 'w_cost': 33.4941271820899}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  40\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -159.06634929735955\n",
      "Cost breakdown:  {'dv_cost': 100.70207529511126, 'dw_cost': 25.191819035854948, 'w_cost': 33.17245496639299}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  41\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.11980501857502\n",
      "Cost breakdown:  {'dv_cost': 88.46514427228315, 'dw_cost': 23.09787242468365, 'w_cost': 28.55678832160821}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  42\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -131.73769114396313\n",
      "Cost breakdown:  {'dv_cost': 79.37187176274475, 'dw_cost': 24.212074838969553, 'w_cost': 28.153744542248475}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  43\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.12207910610957\n",
      "Cost breakdown:  {'dv_cost': 85.93743993896221, 'dw_cost': 26.61116129609502, 'w_cost': 32.57347787105202}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  44\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.17085258257845\n",
      "Cost breakdown:  {'dv_cost': 90.12474494077864, 'dw_cost': 24.66233880712226, 'w_cost': 34.383768834677454}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  45\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -151.98760451163042\n",
      "Cost breakdown:  {'dv_cost': 94.60811124632852, 'dw_cost': 27.43888463151811, 'w_cost': 29.940608633783608}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  46\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -154.28174791312514\n",
      "Cost breakdown:  {'dv_cost': 100.09540834856698, 'dw_cost': 23.028222897625643, 'w_cost': 31.158116666932248}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  47\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -148.80463101979745\n",
      "Cost breakdown:  {'dv_cost': 92.68444213864018, 'dw_cost': 25.877299973039946, 'w_cost': 30.242888908117322}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  48\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.18584027426292\n",
      "Cost breakdown:  {'dv_cost': 80.81221650434313, 'dw_cost': 23.537863697771442, 'w_cost': 32.83576007214803}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  49\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.43039398920322\n",
      "Cost breakdown:  {'dv_cost': 87.41258203568731, 'dw_cost': 25.783941396212448, 'w_cost': 28.233870557303323}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  50\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -134.60799700031708\n",
      "Cost breakdown:  {'dv_cost': 80.28568646981833, 'dw_cost': 25.89786885573113, 'w_cost': 28.42444167476719}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  51\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -130.25269313931588\n",
      "Cost breakdown:  {'dv_cost': 79.18398779315599, 'dw_cost': 22.92597419345283, 'w_cost': 28.14273115270684}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  52\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.8313103213804\n",
      "Cost breakdown:  {'dv_cost': 93.57770543120553, 'dw_cost': 23.584595645555368, 'w_cost': 24.66900924461936}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  53\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -146.80110534545926\n",
      "Cost breakdown:  {'dv_cost': 92.1736642890297, 'dw_cost': 24.60393568013663, 'w_cost': 30.023505376292906}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  54\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.72890966046776\n",
      "Cost breakdown:  {'dv_cost': 89.8207100762086, 'dw_cost': 22.260860062288714, 'w_cost': 27.647339521970405}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  55\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -136.2311671724855\n",
      "Cost breakdown:  {'dv_cost': 83.07955925453106, 'dw_cost': 25.92883654467702, 'w_cost': 27.222771373277276}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  56\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.63540753881227\n",
      "Cost breakdown:  {'dv_cost': 93.98552928668352, 'dw_cost': 26.67248195007616, 'w_cost': 28.97739630205274}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  57\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.0909897637987\n",
      "Cost breakdown:  {'dv_cost': 92.20583409485852, 'dw_cost': 23.48011608839499, 'w_cost': 25.40503958054491}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  58\n",
      " \n",
      "Current timesteps: 60000\n",
      "Current mean training reward per episode: -1177.29 compared to best mean training reward on record: -1680.85\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -127.5681672581054\n",
      "Cost breakdown:  {'dv_cost': 78.80126101483091, 'dw_cost': 23.138996266460012, 'w_cost': 25.627909976814323}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  59\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -148.58081468197707\n",
      "Cost breakdown:  {'dv_cost': 97.22077226381828, 'dw_cost': 24.517458307163658, 'w_cost': 26.842584110994842}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  60\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -132.2530556202568\n",
      "Cost breakdown:  {'dv_cost': 78.52790879556514, 'dw_cost': 25.900017966108265, 'w_cost': 27.825128858583245}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  61\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -142.97082875940052\n",
      "Cost breakdown:  {'dv_cost': 87.60915194211381, 'dw_cost': 25.76228249203188, 'w_cost': 29.599394325254433}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  62\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -152.80789575962083\n",
      "Cost breakdown:  {'dv_cost': 98.48147155379013, 'dw_cost': 25.358014615530728, 'w_cost': 28.968409590299895}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  63\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -138.28336788412238\n",
      "Cost breakdown:  {'dv_cost': 88.52095797825352, 'dw_cost': 25.04621654029131, 'w_cost': 24.71619336557746}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  64\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -154.55527004045453\n",
      "Cost breakdown:  {'dv_cost': 103.76568224985209, 'dw_cost': 24.235379268669053, 'w_cost': 26.55420852193312}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  65\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.22976989699595\n",
      "Cost breakdown:  {'dv_cost': 92.27423703126126, 'dw_cost': 24.442406751418822, 'w_cost': 26.51312611431578}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  66\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -150.15278893565215\n",
      "Cost breakdown:  {'dv_cost': 102.01293360662196, 'dw_cost': 23.658520600774313, 'w_cost': 24.481334728255632}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  67\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.8254498770317\n",
      "Cost breakdown:  {'dv_cost': 94.78373855087874, 'dw_cost': 25.08608924187587, 'w_cost': 25.955622084276815}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  68\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.814371516482\n",
      "Cost breakdown:  {'dv_cost': 93.14209488770891, 'dw_cost': 26.24760947139536, 'w_cost': 25.42466715737752}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  69\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.0774204829723\n",
      "Cost breakdown:  {'dv_cost': 92.71577813994061, 'dw_cost': 24.182266307738487, 'w_cost': 27.179376035293114}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  70\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -154.34337068133308\n",
      "Cost breakdown:  {'dv_cost': 102.39028975109974, 'dw_cost': 24.63613731571958, 'w_cost': 27.31694361451371}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  71\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -136.84107491129333\n",
      "Cost breakdown:  {'dv_cost': 86.5679209101602, 'dw_cost': 25.176976207398663, 'w_cost': 25.09617779373414}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  72\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.96188406591173\n",
      "Cost breakdown:  {'dv_cost': 89.50177389350938, 'dw_cost': 26.371364836764524, 'w_cost': 26.088745335637707}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  73\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.02167255213953\n",
      "Cost breakdown:  {'dv_cost': 93.26131000923012, 'dw_cost': 24.735180889163765, 'w_cost': 25.025181653745314}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  74\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.6780042649558\n",
      "Cost breakdown:  {'dv_cost': 94.68419038338259, 'dw_cost': 26.03085585946782, 'w_cost': 24.96295802210514}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  75\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.47416788569046\n",
      "Cost breakdown:  {'dv_cost': 96.19057204312489, 'dw_cost': 24.4517098859885, 'w_cost': 24.831885956577352}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  76\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -135.39382899287094\n",
      "Cost breakdown:  {'dv_cost': 85.78857015088509, 'dw_cost': 25.420075526260437, 'w_cost': 24.185183315725208}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  77\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.17677860637525\n",
      "Cost breakdown:  {'dv_cost': 94.04882111449913, 'dw_cost': 22.81228793955441, 'w_cost': 26.315669552321534}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  78\n",
      " \n",
      "Current timesteps: 80000\n",
      "Current mean training reward per episode: -912.23 compared to best mean training reward on record: -1177.29\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -135.6031635504502\n",
      "Cost breakdown:  {'dv_cost': 84.42429515807007, 'dw_cost': 24.44923067320801, 'w_cost': 26.72963771917223}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  79\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -128.6033122648017\n",
      "Cost breakdown:  {'dv_cost': 82.73585883828717, 'dw_cost': 23.212725337144036, 'w_cost': 22.654728089370355}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  80\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.9363795095376\n",
      "Cost breakdown:  {'dv_cost': 91.38904076026844, 'dw_cost': 25.014852269058203, 'w_cost': 25.532486480210686}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  81\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -148.08725768003916\n",
      "Cost breakdown:  {'dv_cost': 97.74520322178184, 'dw_cost': 25.83873507651516, 'w_cost': 24.503319381741832}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  82\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.73890011376872\n",
      "Cost breakdown:  {'dv_cost': 92.5200609978143, 'dw_cost': 23.188046333572423, 'w_cost': 24.030792782381894}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  83\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -150.03726989394505\n",
      "Cost breakdown:  {'dv_cost': 97.43016867641487, 'dw_cost': 25.695196721974863, 'w_cost': 26.911904495555422}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  84\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -138.95620609814924\n",
      "Cost breakdown:  {'dv_cost': 89.74917145632472, 'dw_cost': 23.59949818812126, 'w_cost': 25.60753645370309}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  85\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.86667135487957\n",
      "Cost breakdown:  {'dv_cost': 92.25441120118246, 'dw_cost': 24.411148529716236, 'w_cost': 24.201111623980612}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  86\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.3017900583307\n",
      "Cost breakdown:  {'dv_cost': 98.7164963228037, 'dw_cost': 25.12131399593817, 'w_cost': 23.463979739588964}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  87\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.76368523456247\n",
      "Cost breakdown:  {'dv_cost': 85.8177455451637, 'dw_cost': 26.628656409377843, 'w_cost': 25.317283280020654}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  88\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.1611427894999\n",
      "Cost breakdown:  {'dv_cost': 85.53933777611594, 'dw_cost': 26.49816738615413, 'w_cost': 25.123637627229478}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  89\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.7358057507351\n",
      "Cost breakdown:  {'dv_cost': 88.48419931397864, 'dw_cost': 25.34931330914883, 'w_cost': 25.902293127607248}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  90\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.90521085165884\n",
      "Cost breakdown:  {'dv_cost': 93.27776925274858, 'dw_cost': 21.72877170017006, 'w_cost': 22.898669898739907}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  91\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -132.6881904521741\n",
      "Cost breakdown:  {'dv_cost': 87.04789486850343, 'dw_cost': 23.66921759849744, 'w_cost': 21.97107798517291}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  92\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -126.9433974798338\n",
      "Cost breakdown:  {'dv_cost': 81.07813783062251, 'dw_cost': 22.98484832369227, 'w_cost': 22.88041132551885}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  93\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.30620559669336\n",
      "Cost breakdown:  {'dv_cost': 93.67068972374688, 'dw_cost': 21.95266603014359, 'w_cost': 23.682849842802735}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  94\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.60163100575238\n",
      "Cost breakdown:  {'dv_cost': 91.3768595368834, 'dw_cost': 27.248112694126043, 'w_cost': 24.97665877474296}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  95\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.27665064009344\n",
      "Cost breakdown:  {'dv_cost': 91.95555853655593, 'dw_cost': 24.17718239038978, 'w_cost': 24.143909713147355}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  96\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.0486709516891\n",
      "Cost breakdown:  {'dv_cost': 95.41580779566506, 'dw_cost': 24.998377880691482, 'w_cost': 23.634485275332235}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  97\n",
      " \n",
      "Current timesteps: 100000\n",
      "Current mean training reward per episode: -760.87 compared to best mean training reward on record: -912.23\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -146.6214031487701\n",
      "Cost breakdown:  {'dv_cost': 98.67887960458914, 'dw_cost': 24.78032472550644, 'w_cost': 23.162198818674}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  98\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -135.03166579748654\n",
      "Cost breakdown:  {'dv_cost': 86.28302475174264, 'dw_cost': 24.900329558966213, 'w_cost': 23.848311486777376}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  99\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.38349005230532\n",
      "Cost breakdown:  {'dv_cost': 86.23598550301745, 'dw_cost': 26.235537413405133, 'w_cost': 24.911967135882758}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  100\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.55973738202246\n",
      "Cost breakdown:  {'dv_cost': 89.45054225841606, 'dw_cost': 24.50530734288128, 'w_cost': 23.60388778072512}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  101\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.47098009779234\n",
      "Cost breakdown:  {'dv_cost': 95.66988042159917, 'dw_cost': 24.27028117408241, 'w_cost': 23.530818502110925}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  102\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.8368610174007\n",
      "Cost breakdown:  {'dv_cost': 98.2897039181033, 'dw_cost': 24.349650886596578, 'w_cost': 25.19750621270068}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  103\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.7106189004079\n",
      "Cost breakdown:  {'dv_cost': 89.25812962659874, 'dw_cost': 25.07360063462506, 'w_cost': 25.37888863918395}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  104\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.3692545172659\n",
      "Cost breakdown:  {'dv_cost': 91.11477237903873, 'dw_cost': 27.642321073825595, 'w_cost': 25.612161064401246}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  105\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -132.51414427704228\n",
      "Cost breakdown:  {'dv_cost': 82.87996763911443, 'dw_cost': 25.162557757015577, 'w_cost': 24.471618880911887}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  106\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.71796158196477\n",
      "Cost breakdown:  {'dv_cost': 90.86127281938782, 'dw_cost': 23.969485482502527, 'w_cost': 22.887203280074168}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  107\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.73400159569889\n",
      "Cost breakdown:  {'dv_cost': 88.74600438925376, 'dw_cost': 24.347110109747707, 'w_cost': 26.640887096697384}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  108\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -133.15575282545117\n",
      "Cost breakdown:  {'dv_cost': 85.6490903655581, 'dw_cost': 23.686157659957058, 'w_cost': 23.82050479993598}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  109\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.39230560732506\n",
      "Cost breakdown:  {'dv_cost': 93.85061676567695, 'dw_cost': 25.482796389078874, 'w_cost': 24.05889245256906}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  110\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -138.4516606887097\n",
      "Cost breakdown:  {'dv_cost': 87.55322500448592, 'dw_cost': 25.380867647984402, 'w_cost': 25.517568036238945}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  111\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.57664277080252\n",
      "Cost breakdown:  {'dv_cost': 92.95789912488011, 'dw_cost': 24.759934368522668, 'w_cost': 21.85880927739963}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  112\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -133.24725866088352\n",
      "Cost breakdown:  {'dv_cost': 88.50360262709576, 'dw_cost': 22.339806127678315, 'w_cost': 22.403849906109365}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  113\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.50963067594915\n",
      "Cost breakdown:  {'dv_cost': 94.1067280344083, 'dw_cost': 24.298710051587218, 'w_cost': 25.104192589953627}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  114\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.8523721178685\n",
      "Cost breakdown:  {'dv_cost': 89.24126766172583, 'dw_cost': 25.747155777776126, 'w_cost': 24.8639486783662}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  115\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -138.6166744664466\n",
      "Cost breakdown:  {'dv_cost': 92.85302411641467, 'dw_cost': 23.155827868310134, 'w_cost': 22.607822481721996}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  116\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -132.9736132645241\n",
      "Cost breakdown:  {'dv_cost': 87.81912221891244, 'dw_cost': 23.27372264760109, 'w_cost': 21.880768398010346}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  117\n",
      " \n",
      "Current timesteps: 120000\n",
      "Current mean training reward per episode: -170.55 compared to best mean training reward on record: -760.87\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -136.02654831896703\n",
      "Cost breakdown:  {'dv_cost': 85.00768083586789, 'dw_cost': 25.56729569397083, 'w_cost': 25.451571789128124}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  118\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.24768917435924\n",
      "Cost breakdown:  {'dv_cost': 90.77168501496597, 'dw_cost': 23.813960527112034, 'w_cost': 25.66204363228099}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  119\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.42355784601352\n",
      "Cost breakdown:  {'dv_cost': 92.14811279081913, 'dw_cost': 24.470368623553174, 'w_cost': 23.80507643164109}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  120\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.81050500185168\n",
      "Cost breakdown:  {'dv_cost': 97.11770907028948, 'dw_cost': 23.44613850226789, 'w_cost': 25.24665742929413}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  121\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -148.67442179829047\n",
      "Cost breakdown:  {'dv_cost': 98.8726911701635, 'dw_cost': 25.51809469783024, 'w_cost': 24.28363593029686}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  122\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.41512982594634\n",
      "Cost breakdown:  {'dv_cost': 93.9923031233088, 'dw_cost': 22.96103354175472, 'w_cost': 22.46179316088273}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  123\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.0028515061825\n",
      "Cost breakdown:  {'dv_cost': 95.89559545582324, 'dw_cost': 23.847047150379534, 'w_cost': 24.26020889997984}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  124\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.2066069574464\n",
      "Cost breakdown:  {'dv_cost': 88.61575522450457, 'dw_cost': 24.53643908810611, 'w_cost': 24.05441264483548}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  125\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.1102588713535\n",
      "Cost breakdown:  {'dv_cost': 89.34192027498216, 'dw_cost': 25.79384670098257, 'w_cost': 24.974491895388333}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  126\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.880851157002\n",
      "Cost breakdown:  {'dv_cost': 93.87785468200937, 'dw_cost': 23.323739927991337, 'w_cost': 24.67925654700116}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  127\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.30149083654092\n",
      "Cost breakdown:  {'dv_cost': 92.15910708239177, 'dw_cost': 26.824960491559576, 'w_cost': 25.317423262589703}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  128\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -142.19225754880475\n",
      "Cost breakdown:  {'dv_cost': 89.01990981656014, 'dw_cost': 26.492991992636696, 'w_cost': 26.679355739607445}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  129\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.09302751087728\n",
      "Cost breakdown:  {'dv_cost': 88.58854291979003, 'dw_cost': 25.51826649235563, 'w_cost': 24.986218098731474}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  130\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -153.81648540810465\n",
      "Cost breakdown:  {'dv_cost': 103.53400242872554, 'dw_cost': 25.60006495002584, 'w_cost': 24.682418029353233}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  131\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.3866649628779\n",
      "Cost breakdown:  {'dv_cost': 85.65006149412393, 'dw_cost': 26.391626187370523, 'w_cost': 25.34497728138319}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  132\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -125.08668673075506\n",
      "Cost breakdown:  {'dv_cost': 79.82842657632331, 'dw_cost': 22.83207532170428, 'w_cost': 22.426184832727223}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  133\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.85893560075868\n",
      "Cost breakdown:  {'dv_cost': 92.027356225053, 'dw_cost': 22.38375812305043, 'w_cost': 23.447821252655096}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  134\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.36949773644793\n",
      "Cost breakdown:  {'dv_cost': 89.5293323369305, 'dw_cost': 24.969899926605176, 'w_cost': 24.870265472912102}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  135\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.22512884006636\n",
      "Cost breakdown:  {'dv_cost': 95.39910601255664, 'dw_cost': 21.826789994172497, 'w_cost': 22.99923283333701}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  136\n",
      " \n",
      "Current timesteps: 140000\n",
      "Current mean training reward per episode: -141.90 compared to best mean training reward on record: -170.55\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -135.55183757154796\n",
      "Cost breakdown:  {'dv_cost': 79.24914723182472, 'dw_cost': 28.920427646866166, 'w_cost': 27.382262692856873}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  137\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.4797776050973\n",
      "Cost breakdown:  {'dv_cost': 92.22577609646068, 'dw_cost': 24.119552545938458, 'w_cost': 23.134448962697945}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  138\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.95915460116868\n",
      "Cost breakdown:  {'dv_cost': 94.53197937185209, 'dw_cost': 27.179549991282993, 'w_cost': 24.247625238033528}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  139\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.1118707435095\n",
      "Cost breakdown:  {'dv_cost': 92.21731386826151, 'dw_cost': 23.746421665753562, 'w_cost': 27.14813520949443}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  140\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.35886517288725\n",
      "Cost breakdown:  {'dv_cost': 90.24860040368281, 'dw_cost': 23.590568365140406, 'w_cost': 23.51969640406387}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  141\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.48760081710248\n",
      "Cost breakdown:  {'dv_cost': 91.48896595288257, 'dw_cost': 25.00095505634772, 'w_cost': 26.99767980787224}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  142\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.2425890073197\n",
      "Cost breakdown:  {'dv_cost': 98.43479431958315, 'dw_cost': 25.26214067147608, 'w_cost': 23.545654016260084}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  143\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -152.66920198835527\n",
      "Cost breakdown:  {'dv_cost': 99.25784710451224, 'dw_cost': 26.260510695764186, 'w_cost': 27.150844188078743}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  144\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -152.81512557004348\n",
      "Cost breakdown:  {'dv_cost': 103.0462992245831, 'dw_cost': 25.356032713154033, 'w_cost': 24.41279363230631}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  145\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -133.25736605860504\n",
      "Cost breakdown:  {'dv_cost': 85.05486706857842, 'dw_cost': 24.66739531446792, 'w_cost': 23.535103675558368}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  146\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.84998803669902\n",
      "Cost breakdown:  {'dv_cost': 89.74941996914923, 'dw_cost': 27.143359792523963, 'w_cost': 28.95720827502558}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  147\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.2009826442548\n",
      "Cost breakdown:  {'dv_cost': 91.39266706552947, 'dw_cost': 24.389388487676044, 'w_cost': 24.418927091049266}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  148\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.1246967480198\n",
      "Cost breakdown:  {'dv_cost': 100.61001741010651, 'dw_cost': 23.40841446845189, 'w_cost': 25.10626486946136}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  149\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -136.27595468178907\n",
      "Cost breakdown:  {'dv_cost': 88.6876621019737, 'dw_cost': 22.737132380535968, 'w_cost': 24.85116019927939}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  150\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -135.2993916748833\n",
      "Cost breakdown:  {'dv_cost': 84.56042800819279, 'dw_cost': 24.093467758600625, 'w_cost': 26.6454959080901}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  151\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.45421271861457\n",
      "Cost breakdown:  {'dv_cost': 92.4512295066436, 'dw_cost': 26.03787884395353, 'w_cost': 25.96510436801725}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  152\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.6822092642336\n",
      "Cost breakdown:  {'dv_cost': 96.39904887006972, 'dw_cost': 24.146075366642823, 'w_cost': 23.137085027521024}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  153\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.18158967930782\n",
      "Cost breakdown:  {'dv_cost': 100.2874157562045, 'dw_cost': 24.26033595578887, 'w_cost': 24.6338379673144}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  154\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -150.32081664737873\n",
      "Cost breakdown:  {'dv_cost': 101.5577469398128, 'dw_cost': 24.67472778435005, 'w_cost': 24.088341923215623}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  155\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -137.5769909731948\n",
      "Cost breakdown:  {'dv_cost': 88.31989256285775, 'dw_cost': 24.17017659802112, 'w_cost': 25.086921812315694}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  156\n",
      " \n",
      "Current timesteps: 160000\n",
      "Current mean training reward per episode: -141.33 compared to best mean training reward on record: -141.90\n",
      "Saving new best model to RL_models/SB3_stored_models/all_agents/oct_12_6/best_model\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -150.44741172911574\n",
      "Cost breakdown:  {'dv_cost': 97.15444061493403, 'dw_cost': 27.226343296369173, 'w_cost': 26.066627817812247}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  157\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -138.564218278679\n",
      "Cost breakdown:  {'dv_cost': 89.8960784653035, 'dw_cost': 24.672198766274843, 'w_cost': 23.995941047100477}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  158\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -146.81894569033446\n",
      "Cost breakdown:  {'dv_cost': 96.2992929088464, 'dw_cost': 25.45748989273597, 'w_cost': 25.06216288875186}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  159\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.56493844858582\n",
      "Cost breakdown:  {'dv_cost': 94.99688630753202, 'dw_cost': 26.39695143635076, 'w_cost': 26.17110070470296}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  160\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.3730229533116\n",
      "Cost breakdown:  {'dv_cost': 91.66004521121101, 'dw_cost': 26.252553341454878, 'w_cost': 25.46042440064546}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  161\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.82756103374922\n",
      "Cost breakdown:  {'dv_cost': 96.53094764492532, 'dw_cost': 24.365940445263828, 'w_cost': 24.930672943559976}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  162\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.9943796997859\n",
      "Cost breakdown:  {'dv_cost': 92.81076469885917, 'dw_cost': 26.346216120925288, 'w_cost': 26.83739888000119}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  163\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -142.1236776664679\n",
      "Cost breakdown:  {'dv_cost': 88.19936047823919, 'dw_cost': 26.483132496884927, 'w_cost': 27.441184691343874}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  164\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -144.01328789423147\n",
      "Cost breakdown:  {'dv_cost': 95.46702097986116, 'dw_cost': 24.683898373410894, 'w_cost': 23.862368540959377}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  165\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.26638117404696\n",
      "Cost breakdown:  {'dv_cost': 98.86199428293115, 'dw_cost': 24.661815755379013, 'w_cost': 25.7425711357367}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  166\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -153.2654405669419\n",
      "Cost breakdown:  {'dv_cost': 105.87861362677286, 'dw_cost': 24.181323674098056, 'w_cost': 23.205503266070814}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  167\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -149.60049794745078\n",
      "Cost breakdown:  {'dv_cost': 101.00327425065599, 'dw_cost': 24.66478125323592, 'w_cost': 23.932442443558983}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  168\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -146.49725067086652\n",
      "Cost breakdown:  {'dv_cost': 95.60433247796438, 'dw_cost': 25.034590068682075, 'w_cost': 25.858328124219756}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  169\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.1516227665409\n",
      "Cost breakdown:  {'dv_cost': 97.4986706795389, 'dw_cost': 25.165577798044446, 'w_cost': 24.48737428895744}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  170\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.5267070385516\n",
      "Cost breakdown:  {'dv_cost': 92.95023809651185, 'dw_cost': 23.72790278321217, 'w_cost': 23.848566158827317}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  171\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.67409835618588\n",
      "Cost breakdown:  {'dv_cost': 97.36400621440181, 'dw_cost': 25.499934335816764, 'w_cost': 24.810157805967116}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  172\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -146.76526265753398\n",
      "Cost breakdown:  {'dv_cost': 98.4690619935324, 'dw_cost': 24.227187624909806, 'w_cost': 24.06901303909142}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  173\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.20934010469713\n",
      "Cost breakdown:  {'dv_cost': 90.11760650623617, 'dw_cost': 24.574314927073253, 'w_cost': 26.517418671387457}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  174\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.70133593558901\n",
      "Cost breakdown:  {'dv_cost': 99.6746835749985, 'dw_cost': 23.3349936898408, 'w_cost': 24.69165867074972}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  175\n",
      " \n",
      "Current timesteps: 180000\n",
      "Current mean training reward per episode: -141.70 compared to best mean training reward on record: -141.33\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.1103501244996\n",
      "Cost breakdown:  {'dv_cost': 91.51386949105205, 'dw_cost': 22.81745954998504, 'w_cost': 24.77902108346232}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  176\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -157.45148162086673\n",
      "Cost breakdown:  {'dv_cost': 106.76638166173575, 'dw_cost': 23.443923497904553, 'w_cost': 27.241176461226477}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  177\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -143.18473429797143\n",
      "Cost breakdown:  {'dv_cost': 92.95012397519217, 'dw_cost': 25.824865389195597, 'w_cost': 24.409744933583635}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  178\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -136.45264520927668\n",
      "Cost breakdown:  {'dv_cost': 87.83616638883119, 'dw_cost': 24.412755415840767, 'w_cost': 24.203723404604396}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  179\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -141.2224076966621\n",
      "Cost breakdown:  {'dv_cost': 89.6031292663588, 'dw_cost': 25.72742891457593, 'w_cost': 25.891849515727337}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  180\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -139.5172705040631\n",
      "Cost breakdown:  {'dv_cost': 89.68382742651391, 'dw_cost': 25.033583018038602, 'w_cost': 24.799860059510582}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  181\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -140.44163854201028\n",
      "Cost breakdown:  {'dv_cost': 92.3718936655545, 'dw_cost': 23.77688093890185, 'w_cost': 24.292863937553502}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  182\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.47771774666063\n",
      "Cost breakdown:  {'dv_cost': 94.77623584332595, 'dw_cost': 25.82645384499604, 'w_cost': 26.87502805833836}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  183\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -145.53227460236613\n",
      "Cost breakdown:  {'dv_cost': 94.02054191339184, 'dw_cost': 25.846382676235837, 'w_cost': 25.66535001273818}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  184\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -133.0286752556827\n",
      "Cost breakdown:  {'dv_cost': 81.59760813047448, 'dw_cost': 26.70485644642906, 'w_cost': 24.72621067877889}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  185\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -151.89027180318635\n",
      "Cost breakdown:  {'dv_cost': 100.53575812975565, 'dw_cost': 25.83449392701276, 'w_cost': 25.520019746417873}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  186\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -153.2825899594878\n",
      "Cost breakdown:  {'dv_cost': 105.35610655436633, 'dw_cost': 25.03446296444043, 'w_cost': 22.89202044068085}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  187\n",
      "Firely capture rate for the episode:  0 ff for 102.49999999999845 s: -------------------> 0.0\n",
      "Total reward for the episode:  -147.90472516718037\n",
      "Cost breakdown:  {'dv_cost': 98.51683988912652, 'dw_cost': 23.330511180139677, 'w_cost': 26.057374097914096}\n",
      "TIME before resetting: 102.49999999999845\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  10\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "\n",
      " episode:  188\n"
     ]
    }
   ],
   "source": [
    "model_folder_name = \"RL_models/SB3_stored_models/all_agents/oct_12_6\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "\n",
    "env_kwargs = {}\n",
    "env = env_for_sb3.EnvForSB3(**env_kwargs)\n",
    "env = Monitor(env, model_folder_name)\n",
    "\n",
    "# For direct training\n",
    "sac_model = SAC(\"MlpPolicy\", \n",
    "            env,\n",
    "            gamma=0.995,\n",
    "            learning_rate=0.0015,\n",
    "            batch_size=1024,\n",
    "            target_update_interval=50,\n",
    "            buffer_size=1000000,\n",
    "            learning_starts=10000,\n",
    "            train_freq=10,\n",
    "            ent_coef='auto',\n",
    "            policy_kwargs=dict(activation_fn=nn.Tanh, net_arch=[128, 128])\n",
    "            )\n",
    "\n",
    "\n",
    "callback = SB3_functions.SaveOnBestTrainingRewardCallback(check_freq=20000, model_folder_name=model_folder_name)\n",
    "#timesteps = 50000000\n",
    "timesteps = 200000\n",
    "sac_model.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "plot_results([model_folder_name], timesteps, results_plotter.X_TIMESTEPS, \"env.MultiFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5dd467",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4efbb0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_folder_name: RL_models/SB3_stored_models/all_agents/oct_12_5\n",
      "Made agent with the following params: {'learning_rate': 0.0003, 'batch_size': 1024, 'target_update_interval': 50, 'buffer_size': 1000000, 'learning_starts': 10000, 'train_freq': TrainFreq(frequency=100, unit=<TrainFrequencyUnit.STEP: 'step'>), 'gradient_steps': 10, 'ent_coef': 'auto', 'policy_kwargs': {'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': [256, 128], 'use_sde': False}, 'gamma': 0.998}\n",
      "Loaded existing agent: RL_models/SB3_stored_models/all_agents/oct_12_5/best_model.zip\n",
      "Params from agent after loading:\n",
      "{'learning_rate': 0.0003, 'batch_size': 1024, 'target_update_interval': 50, 'buffer_size': 1000000, 'learning_starts': 10000, 'train_freq': TrainFreq(frequency=100, unit=<TrainFrequencyUnit.STEP: 'step'>), 'gradient_steps': 10, 'ent_coef': 'auto', 'policy_kwargs': {'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': [256, 128], 'use_sde': False}, 'gamma': 0.998}\n",
      "Loaded existing agent\n",
      "Failed to retrieve monkey data. Will make new monkey data. Error:  [Errno 2] No such file or directory: 'RL_models/SB3_stored_models/all_collected_data/processed_data/oct_12_5/individual_data_sessions/data_0/ff_basic_info.npz'\n",
      "Warning: failed to retrieve env params. Will use the env params passed in. Error message: [Errno 2] No such file or directory: 'RL_models/SB3_stored_models/all_agents/oct_12_5/env_params.txt'\n",
      "Collecting new agent data......\n",
      "Cleaning contents of: RL_models/SB3_stored_models/all_collected_data/planning/oct_12_5/individual_data_sessions/data_0\n",
      "Cleaning contents of: RL_models/SB3_stored_models/all_collected_data/processed_data/oct_12_5/individual_data_sessions/data_0\n",
      "Cleaning contents of: RL_models/SB3_stored_models/all_collected_data/decision_making/oct_12_5/individual_data_sessions/data_0\n",
      "Cleaning contents of: RL_models/SB3_stored_models/all_collected_data/patterns_and_features/oct_12_5/individual_data_sessions/data_0\n",
      "TIME before resetting: 0\n",
      "current linear_terminal_vel:  0.01\n",
      "current angular_terminal_vel:  0.01\n",
      "current dt:  0.1\n",
      "current dv_cost_factor:  10\n",
      "current dw_cost_factor:  10\n",
      "current w_cost_factor:  3\n",
      "current distance2center_cost:  0\n",
      "current flash_on_interval:  0.3\n",
      "current num_obs_ff:  5\n",
      "current max_in_memory_time:  3\n",
      "2025-10-12 21:59:17,395 - INFO - Step: 1000 / 8000\n",
      "2025-10-12 21:59:19,711 - INFO - Step: 2000 / 8000\n",
      "2025-10-12 21:59:21,905 - INFO - Step: 3000 / 8000\n",
      "2025-10-12 21:59:24,149 - INFO - Step: 4000 / 8000\n",
      "2025-10-12 21:59:26,116 - INFO - Step: 5000 / 8000\n",
      "2025-10-12 21:59:28,020 - INFO - Step: 6000 / 8000\n",
      "2025-10-12 21:59:29,892 - INFO - Step: 7000 / 8000\n",
      "2025-10-12 21:59:32,492 - INFO - Firefly capture rate: 0.0000\n",
      "saved monkey_information and ff info at RL_models/SB3_stored_models/all_collected_data/processed_data/oct_12_5/individual_data_sessions/data_0\n",
      "Warnings: currently, only ff in obs at each step are used in ff_dataframe. All ff are labeled 'visible' regardless of their actual time since last visible.\n",
      "made ff_dataframe\n",
      "saved ff_dataframe at RL_models/SB3_stored_models/all_collected_data/processed_data/oct_12_5/individual_data_sessions/data_0/ff_dataframe.csv\n",
      "No closest stop to capture found\n"
     ]
    }
   ],
   "source": [
    "RLforFF = sb3_for_multiff_class.SB3forMultifirefly(\n",
    "    model_folder_name=model_folder_name)\n",
    "RLforFF.streamline_everything(currentTrial_for_animation = 10, num_trials_for_animation = 5)\n",
    "RLforFF.collect_data(exists_ok=True, save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3778cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mRLforFF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_animation_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrentTrial\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m RLforFF.call_animation_function()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/visualization/animation/animation_class.py:36\u001b[39m, in \u001b[36mAnimationClass.set_animation_parameters\u001b[39m\u001b[34m(self, currentTrial, num_trials, duration, animation_plot_kwargs, k, static_plot_on_the_left, max_num_frames, max_duration, min_duration, rotated)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_animation_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m, currentTrial=\u001b[38;5;28;01mNone\u001b[39;00m, num_trials=\u001b[38;5;28;01mNone\u001b[39;00m, duration=\u001b[38;5;28;01mNone\u001b[39;00m, animation_plot_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m, k=\u001b[32m3\u001b[39m, static_plot_on_the_left=\u001b[38;5;28;01mFalse\u001b[39;00m, max_num_frames=\u001b[32m150\u001b[39m, max_duration=\u001b[32m30\u001b[39m, min_duration=\u001b[32m1\u001b[39m, rotated=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Among currentTrial, num_trials, duration, either currentTrial and num_trials must be specified, or duration must be specified\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     currentTrial, num_trials, duration = \u001b[43mspecific_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_currentTrial_or_num_trials_or_duration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_caught_T_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrentTrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# if the duration is too short, then increase the number of trials\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m duration[\u001b[32m1\u001b[39m] - duration[\u001b[32m0\u001b[39m] < \u001b[32m0.1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/user_data/cicid/Multifirefly-Project/multiff_analysis/multiff_code/methods/data_wrangling/specific_utils.py:206\u001b[39m, in \u001b[36mfind_currentTrial_or_num_trials_or_duration\u001b[39m\u001b[34m(ff_caught_T_new, currentTrial, num_trials, duration)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_currentTrial_or_num_trials_or_duration\u001b[39m(ff_caught_T_new, currentTrial=\u001b[38;5;28;01mNone\u001b[39;00m, num_trials=\u001b[38;5;28;01mNone\u001b[39;00m, duration=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    204\u001b[39m     \u001b[38;5;66;03m# Among currentTrial, num_trials, duration, either currentTrial and num_trials must be specified, or duration must be specified\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m duration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         duration = [\u001b[43mff_caught_T_new\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrentTrial\u001b[49m\u001b[43m-\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m    207\u001b[39m                     ff_caught_T_new[currentTrial]]\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# elif duration[1] > ff_caught_T_new[-1]:\u001b[39;00m\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m#    raise ValueError(\"The second element of duration must be smaller than the last element of ff_caught_T_new\")\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m currentTrial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: index 5 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "RLforFF.set_animation_parameters(currentTrial=10, num_trials=5, k=1)\n",
    "RLforFF.call_animation_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9f4eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video('/user_data/cicid/Multifirefly-Project/RL_models/SB3_stored_models/all_collected_data/processed_data/oct_12/individual_data_sessions/data_0/dv10_dw10_w3_memT3__6-10_rate_0.26.mp4', embed=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b254917d",
   "metadata": {
    "id": "b254917d"
   },
   "source": [
    "# Streamline loading agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd105957",
   "metadata": {
    "id": "bd105957"
   },
   "source": [
    "## Make files for logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e447c5f9",
   "metadata": {
    "id": "e447c5f9"
   },
   "source": [
    "(Only have to do once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuE-aO1digZv",
   "metadata": {
    "id": "nuE-aO1digZv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_csv(folder: str, filename: str, columns: list[str]) -> None:\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        pd.DataFrame(columns=columns).to_csv(filepath, index=False)\n",
    "\n",
    "common_cols = ['dv_cost_factor', 'dw_cost_factor', 'w_cost_factor',\n",
    "               'v_noise_std', 'w_noise_std', 'ffr_noise_scale', 'num_obs_ff', 'max_in_memory_time']\n",
    "\n",
    "ensure_csv(overall_folder, 'family_of_agents_log.csv',\n",
    "           common_cols + ['finished_training', 'year', 'month', 'date',\n",
    "                          'training_time', 'successful_training'])\n",
    "\n",
    "ensure_csv(overall_folder, 'parameters_record.csv',\n",
    "           common_cols + ['working'])\n",
    "\n",
    "ensure_csv(overall_folder, 'pattern_frequencies_record.csv',\n",
    "           common_cols + ['two_in_a_row', 'three_in_a_row', 'four_in_a_row', 'one_in_a_row',\n",
    "                          'multiple_in_a_row', 'multiple_in_a_row_all', 'visible_before_last_one',\n",
    "                          'disappear_latest', 'ignore_sudden_flash', 'try_a_few_times',\n",
    "                          'give_up_after_trying', 'cluster_around_target',\n",
    "                          'waste_cluster_around_target', 'ff_capture_rate', 'stop_success_rate'])\n",
    "\n",
    "feature_cols = common_cols + ['t', 't_last_vis', 'd_last_vis', 'abs_angle_last_vis',\n",
    "                              'hitting_arena_edge', 'num_stops', 'num_stops_since_last_vis',\n",
    "                              'num_stops_near_target', 'num_alive_ff_around_target', 'n_ff_in_a_row']\n",
    "\n",
    "ensure_csv(overall_folder, 'feature_means_record.csv', feature_cols)\n",
    "ensure_csv(overall_folder, 'feature_medians_record.csv', feature_cols)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f22ab42",
   "metadata": {
    "id": "0f22ab42"
   },
   "source": [
    "Make daily backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245d8ed",
   "metadata": {
    "id": "d245d8ed"
   },
   "outputs": [],
   "source": [
    "# back_up_path = overall_folder + 'family_of_agents_log_' + str(time_package.localtime().tm_mon) + '_' + str(time_package.localtime().tm_mday) + '.csv'\n",
    "# if not exists(back_up_path):\n",
    "#     family_of_agents_log = pd.read_csv(overall_folder + 'family_of_agents_log.csv').drop([\"Unnamed: 0\"], axis=1)\n",
    "#     family_of_agents_log.to_csv(back_up_path)\n",
    "#     print('A back up of family_of_agents_log is stored in', back_up_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1558f19f",
   "metadata": {
    "id": "1558f19f"
   },
   "source": [
    "## Get monkey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c2e1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31188,
     "status": "ok",
     "timestamp": 1684945834636,
     "user": {
      "displayName": "Cici Du",
      "userId": "17701548280142155870"
     },
     "user_tz": -480
    },
    "id": "c86c2e1f",
    "outputId": "250ac96e-7813-4618-a219-2dab7c7e9556"
   },
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0220\"\n",
    "data_item = further_processing_class.FurtherProcessing(raw_data_folder_path=raw_data_folder_path)\n",
    "data_item.retrieve_or_make_monkey_data()\n",
    "data_item.make_or_retrieve_ff_dataframe(exists_ok=True)\n",
    "data_item.find_patterns()\n",
    "data_item.make_or_retrieve_all_trial_patterns(exists_ok=True)\n",
    "data_item.make_or_retrieve_pattern_frequencies(exists_ok=True)\n",
    "data_item.make_or_retrieve_all_trial_features(exists_ok=True)\n",
    "data_item.make_or_retrieve_feature_statistics(exists_ok=True)\n",
    "data_item.make_info_of_monkey()\n",
    "\n",
    "all_trial_patterns_m = data_item.all_trial_patterns\n",
    "pattern_frequencies_m = data_item.pattern_frequencies\n",
    "all_trial_features_m = data_item.all_trial_features\n",
    "feature_statistics_m = data_item.feature_statistics\n",
    "info_of_monkey = data_item.info_of_monkey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27fc48d",
   "metadata": {},
   "source": [
    "## Run the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'RL_models/SB3_stored_models/all_agents/gen_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49318ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLforFF = sb3_for_multiff_class.SB3forMultifirefly(overall_folder=overall_folder, add_date_to_model_folder_name=False)\n",
    "#RLforFF.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "RLforFF.streamline_everything(currentTrial_for_animation = 10, num_trials_for_animation = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLforFF.lstm = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timesteps = 10000000        \n",
    "# stop_train_callback = SB3_functions.StopTrainingOnNoModelImprovement(max_no_improvement_evals=20, min_evals=20, verbose=1, model_folder_name=RLforFF.model_folder_name,                                                   overall_folder=RLforFF.overall_folder, agent_id=RLforFF.agent_id)\n",
    "# callback = EvalCallback(RLforFF.env, eval_freq=12000, callback_after_eval=stop_train_callback, verbose=1, best_model_save_path=RLforFF.model_folder_name, n_eval_episodes=3)\n",
    "# RLforFF.sac_model.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "# RLforFF.successful_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0edc7f",
   "metadata": {},
   "source": [
    "## Collect data (experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e658475",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLforFF.collect_data(exists_ok=True, save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25cf7cf",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8747d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'overall_folder': overall_folder, \n",
    "            #   'v_noise_std': 0, \n",
    "            #   \"w_noise_std\": 0,\n",
    "            #   'ffr_noise_scale': 0, \n",
    "            #   'num_obs_ff': 2, \n",
    "            #   'max_in_memory_time': 2.5, \n",
    "            #   'add_date_to_model_folder_name': False,\n",
    "            #   \n",
    "            #   'dv_cost_factor': 10,\n",
    "            #   'dw_cost_factor': 10,\n",
    "              }\n",
    "\n",
    "# alternatively...\n",
    "RLforFF = sb3_for_multiff_class.SB3forMultifirefly(**env_kwargs)\n",
    "RLforFF.make_env()\n",
    "RLforFF.make_agent()\n",
    "RLforFF.load_agent(load_replay_buffer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1046e",
   "metadata": {},
   "source": [
    "## call_animation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "918921f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RLforFF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mRLforFF\u001b[49m.set_animation_parameters(currentTrial=\u001b[32m10\u001b[39m, num_trials=\u001b[32m5\u001b[39m, k=\u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m RLforFF.call_animation_function()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# RLforFF.combine_6_plots_for_neural_network()\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# RLforFF.calculate_pattern_frequencies_and_feature_statistics()\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# RLforFF.plot_side_by_side()\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# plot_statistics.plot_pattern_frequencies(RLforFF.combd_pattern_frequencies, compare_monkey_and_agent=True, data_folder_name=RLforFF.model_folder_name)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# #plot_statistics.plot_feature_statistics_for_monkey_and_agent(RLforFF.combd_feature_statistics, data_folder_name = RLforFF.model_folder_name)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# plot_statistics.plot_feature_histograms_for_monkey_and_agent(RLforFF.all_trial_features_valid, RLforFF.all_trial_features_valid, data_folder_name = RLforFF.model_folder_name)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'RLforFF' is not defined"
     ]
    }
   ],
   "source": [
    "RLforFF.set_animation_parameters(currentTrial=10, num_trials=5, k=1)\n",
    "RLforFF.call_animation_function()\n",
    "# RLforFF.combine_6_plots_for_neural_network()\n",
    "# RLforFF.calculate_pattern_frequencies_and_feature_statistics()\n",
    "# RLforFF.plot_side_by_side()\n",
    "# plot_statistics.plot_pattern_frequencies(RLforFF.combd_pattern_frequencies, compare_monkey_and_agent=True, data_folder_name=RLforFF.model_folder_name)\n",
    "# #plot_statistics.plot_feature_statistics_for_monkey_and_agent(RLforFF.combd_feature_statistics, data_folder_name = RLforFF.model_folder_name)\n",
    "# plot_statistics.plot_feature_histograms_for_monkey_and_agent(RLforFF.all_trial_features_valid, RLforFF.all_trial_features_valid, data_folder_name = RLforFF.model_folder_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da26c42f",
   "metadata": {
    "id": "da26c42f"
   },
   "source": [
    "# Loop (for hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95e9a6",
   "metadata": {},
   "source": [
    "## test params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93592d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dw_cost_factor in range(30, 100, 10):\n",
    "    params = {\n",
    "        'dv_cost_factor': 10,\n",
    "        'dw_cost_factor': dw_cost_factor,\n",
    "        'w_cost_factor': 10,\n",
    "    }\n",
    "\n",
    "    num_obs_ff = 3\n",
    "    max_in_memory_time = 3\n",
    "    overall_folder = f'RL_models/SB3_stored_models/all_agents/env1_test_params/ff{num_obs_ff}/'\n",
    "\n",
    "    env_kwargs = {'num_obs_ff': num_obs_ff,\n",
    "                'max_in_memory_time': max_in_memory_time,\n",
    "                'print_ff_capture_incidents': False\n",
    "                #'reward_per_ff': 120,\n",
    "    }\n",
    "\n",
    "    # check if num_obs_ff is consistent with the name in overall_folder. If not, raise an error\n",
    "    if not f'ff{env_kwargs[\"num_obs_ff\"]}' in overall_folder:\n",
    "        raise ValueError('num_obs_ff is not consistent with the name in overall_folder')\n",
    "\n",
    "    gc.collect()\n",
    "    print(\"Current parameters: \", params)\n",
    "\n",
    "    # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "    RLforFF = sb3_for_multiff_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                        **env_kwargs)\n",
    "\n",
    "    #RLforFF.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "    RLforFF.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                    best_model_after_curriculum_exists_ok=True, model_exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260b092",
   "metadata": {},
   "source": [
    "## env1 loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#           'dv_cost_factor': 10,\n",
    "#           'dw_cost_factor': 10,\n",
    "#           'w_cost_factor': 10,\n",
    "# }\n",
    "\n",
    "params = {\n",
    "          'dv_cost_factor': 0,\n",
    "          'dw_cost_factor': 0,\n",
    "          'w_cost_factor': 0,\n",
    "}\n",
    "\n",
    "for max_in_memory_time in [3, 2, 1]:\n",
    "    for num_obs_ff in [2, 1, 3, 4, 5]:\n",
    "        overall_folder = f'RL_models/SB3_stored_models/all_agents/env1_relu/ff{num_obs_ff}/'\n",
    "\n",
    "        env_kwargs = {'num_obs_ff': num_obs_ff,\n",
    "                    'max_in_memory_time': max_in_memory_time,\n",
    "                    'print_ff_capture_incidents': False\n",
    "                    #'reward_per_ff': 120,\n",
    "        }\n",
    "\n",
    "        # check if num_obs_ff is consistent with the name in overall_folder. If not, raise an error\n",
    "        if not f'ff{env_kwargs[\"num_obs_ff\"]}' in overall_folder:\n",
    "            raise ValueError('num_obs_ff is not consistent with the name in overall_folder')\n",
    "\n",
    "        gc.collect()\n",
    "        print(\"Current parameters: \", params)\n",
    "\n",
    "        # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "        RLforFF = sb3_for_multiff_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                            **env_kwargs)\n",
    "\n",
    "        #RLforFF.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "        RLforFF.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                        best_model_after_curriculum_exists_ok=True, model_exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b893a2",
   "metadata": {},
   "source": [
    "## combos of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26965f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample from a range\n",
    "param_combinations = []\n",
    "num_param_combinations = 20\n",
    "for i in range(num_param_combinations):\n",
    "    combo = dict()\n",
    "    #combo[\"time_cost\"] = round(random.uniform(20, 50), 2)\n",
    "    combo[\"dv_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"dw_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"w_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    param_combinations.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224212ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'RL_models/SB3_stored_models/all_agents/env1_relu/ff3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'num_obs_ff': 3,\n",
    "              'print_ff_capture_incidents': False\n",
    "              #'reward_per_ff': 120,\n",
    "}\n",
    "\n",
    "for count, params in enumerate(param_combinations):\n",
    "    gc.collect()\n",
    "    print(\"Running\", str(count), \"out of\", len(param_combinations), \"combinations of parameters\")\n",
    "    print(\"Current parameters: \", params)\n",
    "\n",
    "    # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "\n",
    "    RLforFF = sb3_for_multiff_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                     **env_kwargs)\n",
    "\n",
    "    #RLforFF.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "    RLforFF.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                  best_model_after_curriculum_exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5061dae",
   "metadata": {},
   "source": [
    "### make animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81448918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RLforFF.load_best_model_after_curriculum()\n",
    "RLforFF.streamline_making_animation(duration=[10, 40])\n",
    "#RLforFF.streamline_loading_and_making_animation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d25498",
   "metadata": {},
   "source": [
    "## env2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077effa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample from a range\n",
    "param_combinations = []\n",
    "num_param_combinations = 10\n",
    "for i in range(num_param_combinations):\n",
    "    combo = dict()\n",
    "    #combo[\"time_cost\"] = round(random.uniform(20, 50), 2)\n",
    "    combo[\"dv_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"dw_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    combo[\"w_cost_factor\"] = round(random.uniform(50, 150), 2)\n",
    "    param_combinations.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_folder = 'RL_models/SB3_stored_models/all_agents/gen_28_env2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935605e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'num_obs_ff': 10,\n",
    "              'make_ff_always_flash_on': False,\n",
    "              'max_in_memory_time': 3,\n",
    "              'linear_terminal_vel': 0.01,\n",
    "              'angular_terminal_vel': 0.01,\n",
    "              'reward_per_ff': 100,\n",
    "              'dt': 0.1,\n",
    "              'add_cost_when_catching_ff_only': False,\n",
    "              #'reward_per_ff': 120,\n",
    "}\n",
    "\n",
    "for count, params in enumerate(param_combinations):\n",
    "    gc.collect()\n",
    "    print(\"Running\", str(count), \"out of\", len(param_combinations), \"combinations of parameters\")\n",
    "    print(\"Current parameters: \", params)\n",
    "\n",
    "    # params = {'time_cost': 0.0, 'dv_cost_factor': 0.0, 'dw_cost_factor': 0.0, 'w_cost_factor': 0.0, 'v_noise_std': 0.0, 'w_noise_std': 0.0}\n",
    "\n",
    "    RLforFF = sb3_for_multiff_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "                                                     **env_kwargs,\n",
    "                                                     use_env2=True)\n",
    "\n",
    "    #RLforFF.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "    RLforFF.streamline_everything(currentTrial_for_animation=None, num_trials_for_animation=None, duration=[10, 40],\n",
    "                                  best_model_after_curriculum_exists_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb305a",
   "metadata": {},
   "source": [
    "## remake animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94af079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For every folder in slow:\n",
    "# # Extract parameters from the folder name\n",
    "# # Re-make the env\n",
    "# # Load agent\n",
    "# # And then make animation\n",
    "\n",
    "# overall_folder = 'RL_models/SB3_stored_models/all_agents/gen_30_env1_4ff'\n",
    "# folders = os.listdir(overall_folder)\n",
    "# for folder in folders:\n",
    "#     if 'time' not in folder:\n",
    "#         continue\n",
    "#     print(\"Currently working on\", folder)\n",
    "#     folder_path = overall_folder + '/' + folder\n",
    "#     params = rl_for_multiff_utils.extract_cost_params_from_folder_name(folder)\n",
    "#     RLforFF = sb3_for_multiff_class.SB3forMultifirefly(**params, overall_folder=overall_folder,\n",
    "#                                                      make_ff_always_flash_on=True)\n",
    "#     #RLforFF.import_monkey_data(info_of_monkey, all_trial_features_m, pattern_frequencies_m, feature_statistics_m)\n",
    "#     RLforFF.model_folder_name = folder_path\n",
    "#     RLforFF.make_env()\n",
    "#     RLforFF.make_agent()\n",
    "#     RLforFF.load_agent(load_replay_buffer=False)\n",
    "#     RLforFF.collect_data()\n",
    "#     RLforFF.set_animation_parameters(currentTrial=5, num_trials=5, k=1)\n",
    "#     RLforFF.call_animation_function()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5409a0bd",
   "metadata": {
    "id": "5409a0bd"
   },
   "source": [
    "# Env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9703eb0c",
   "metadata": {
    "id": "9703eb0c"
   },
   "source": [
    "## regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a34ff5",
   "metadata": {
    "id": "30a34ff5"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {}\n",
    "env = env_for_sb3.EnvForSB3(**env_kwargs)\n",
    "model_folder_name = \"RL_models/SB3_stored_models/all_agents/regular\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "env = Monitor(env, model_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32d7b0",
   "metadata": {},
   "source": [
    "## make_ff_always_flash_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {'make_ff_always_flash_on': True,\n",
    "              'ffr_noise_scale': 0,}\n",
    "env = env_for_sb3.EnvForSB3(**env_kwargs)\n",
    "model_folder_name = \"RL_models/SB3_stored_models/all_agents/regular\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)\n",
    "env = Monitor(env, model_folder_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83d0be92",
   "metadata": {
    "id": "83d0be92"
   },
   "source": [
    "## one-ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7fb7e",
   "metadata": {
    "id": "08c7fb7e"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {'num_obs_ff': 1}\n",
    "env = env_for_sb3.EnvForSB3(**env_kwargs)\n",
    "env = Monitor(env, model_folder_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d8ef0c3",
   "metadata": {
    "id": "6d8ef0c3"
   },
   "source": [
    "## with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70417219",
   "metadata": {
    "id": "70417219"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\"v_noise_std\": 0.1, \n",
    "              \"w_noise_std\": 0.1,\n",
    "              \"ffr_noise_scale\": 4, \n",
    "              \"num_obs_ff\": 2,\n",
    "              \"max_in_memory_time\": 2.5}\n",
    "# model_folder_name =overall_folder + \"/SB3_stored_models/all_agents/v\" +\n",
    "#                        str(v_noise_std) + \"_w_\" + str(w_noise_std) + \"_o_\" + str(ffr_noise_scale) + \\\n",
    "#                        \"_ff_\" + str(num_obs_ff) + \"_m_\" + str(max_in_memory_time)\n",
    "env = env.MultiFF(**env_kwargs)\n",
    "env = Monitor(env, model_folder_name)\n",
    "model_folder_name = \"RL_models/SB3_stored_models/all_agents/A0.2_O4_ff2_M3\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50d88dc9",
   "metadata": {
    "id": "50d88dc9"
   },
   "source": [
    "# Agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea153406",
   "metadata": {
    "id": "ea153406"
   },
   "source": [
    "## make agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c411166",
   "metadata": {
    "id": "4c411166"
   },
   "outputs": [],
   "source": [
    "# For direct training\n",
    "sac_model = SAC(\"MlpPolicy\", \n",
    "            env,\n",
    "            gamma=0.995,\n",
    "            learning_rate=0.0015,\n",
    "            batch_size=1024,\n",
    "            target_update_interval=50,\n",
    "            buffer_size=1000000,\n",
    "            learning_starts=10000,\n",
    "            train_freq=10,\n",
    "            ent_coef='auto',\n",
    "            policy_kwargs=dict(activation_fn=nn.Tanh, net_arch=[128, 128])\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37268cc4",
   "metadata": {
    "id": "37268cc4"
   },
   "source": [
    "## load agent (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd640727",
   "metadata": {
    "id": "fd640727"
   },
   "outputs": [],
   "source": [
    "path = os.path.join(model_folder_name, 'best_model.zip')\n",
    "path2 = os.path.join(model_folder_name, 'buffer.pkl')\n",
    "sac_model = sac_model.load(path,env=env) \n",
    "sac_model.load_replay_buffer(path2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b372808d",
   "metadata": {
    "id": "b372808d"
   },
   "source": [
    "## Train agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_name = \"RL_models/SB3_stored_models/all_agents/temp_9_29\"\n",
    "os.makedirs(model_folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a908ec",
   "metadata": {
    "id": "21a908ec"
   },
   "outputs": [],
   "source": [
    "callback = SB3_functions.SaveOnBestTrainingRewardCallback(check_freq=20000, model_folder_name=model_folder_name)\n",
    "#timesteps = 50000000\n",
    "timesteps = 500000\n",
    "sac_model.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "plot_results([model_folder_name], timesteps, results_plotter.X_TIMESTEPS, \"env.MultiFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919e84e",
   "metadata": {
    "id": "1919e84e"
   },
   "outputs": [],
   "source": [
    "plot_results([model_folder_name], timesteps, results_plotter.X_TIMESTEPS, \"env.MultiFF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3d27b8",
   "metadata": {
    "id": "9c3d27b8"
   },
   "outputs": [],
   "source": [
    "sac_model.save(os.path.join(model_folder_name, 'best_model'))\n",
    "sac_model.save_replay_buffer(os.path.join(model_folder_name, 'buffer')) # I added this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f1169",
   "metadata": {
    "id": "492f1169"
   },
   "outputs": [],
   "source": [
    "stop_train_callback = SB3_functions.StopTrainingOnNoModelImprovement(max_no_improvement_evals=10, min_evals=20, verbose=1)\n",
    "callback = EvalCallback(env, eval_freq=5000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "# timesteps = 50000000\n",
    "timesteps = 5000000\n",
    "sac_model.learn(total_timesteps=int(timesteps), callback=callback)\n",
    "\n",
    "sac_model.save(os.path.join(model_folder_name, 'best_model'))\n",
    "sac_model.save_replay_buffer(os.path.join(model_folder_name, 'buffer')) # I added this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d075400f",
   "metadata": {
    "id": "d075400f"
   },
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382fcebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_anim = sb3_for_multiff_class.SB3forMultifirefly(overall_folder='RL_models/SB3_stored_models/all_agents/gen_12/', **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_anim.sac_model = sac_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_anim.streamline_making_animation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b056b5cc",
   "metadata": {
    "id": "b056b5cc"
   },
   "source": [
    "# Interpret neural network (only works on 1-ff env rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use combine_6_plots_for_neural_network from rl_for_multiff_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efeeb570",
   "metadata": {
    "id": "efeeb570"
   },
   "source": [
    "# Plot statistics (pasted from visualization.ipynb)\n",
    "compare monkey and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a06c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function above from rl_for_multiff_class:   \n",
    "    # def save_plots_in_data_folders(self):\n",
    "    #     plot_statistics.plot_pattern_frequencies(self.agent_monkey_pattern_frequencies, compare_monkey_and_agent=True, data_folder_name=self.processed_data_folder_path)\n",
    "    #     plot_statistics.plot_feature_statistics(self.agent_monkey_feature_statistics, compare_monkey_and_agent=True, data_folder_name = self.processed_data_folder_path)\n",
    "\n",
    "    #     plot_statistics.plot_feature_histograms_for_monkey_and_agent(self.all_trial_features_valid_m, self.all_trial_features_valid, data_folder_name = self.model_folder_name)\n",
    "    #     print(\"Made new plots\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "TQMCDI-FqP6s",
   "metadata": {
    "id": "TQMCDI-FqP6s"
   },
   "source": [
    "# Plot side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function plot_side_by_side from rl_for_multiff_class:   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "xIYoWAIyDieu",
   "metadata": {
    "id": "xIYoWAIyDieu"
   },
   "source": [
    "# Polar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aoaz1_ng6QMt",
   "metadata": {
    "id": "aoaz1_ng6QMt"
   },
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZrSbMmCJ5uN1",
   "metadata": {
    "id": "ZrSbMmCJ5uN1"
   },
   "outputs": [],
   "source": [
    "num_trials = 1\n",
    "for currentTrial in range(40,43):\n",
    "    print(currentTrial)\n",
    "    #duration = [ff_caught_T_new[currentTrial-num_trials], ff_caught_T_new[currentTrial]]\n",
    "    duration = [ff_caught_T_new[currentTrial]-1.25, ff_caught_T_new[currentTrial]]\n",
    "\n",
    "\n",
    "    plot_polar.PlotPolar(duration,\n",
    "              monkey_information,\n",
    "              ff_dataframe, \n",
    "              ff_life_sorted,\n",
    "              ff_real_position_sorted,\n",
    "              ff_caught_T_new,\n",
    "              ff_flash_sorted,\n",
    "              rmax = 100,\n",
    "              currentTrial = currentTrial,\n",
    "              num_trials = num_trials,\n",
    "              show_visible_ff = True,\n",
    "              show_visible_target = True,\n",
    "              show_ff_in_memory = True,\n",
    "              show_target_in_memory = True,\n",
    "              show_alive_ff = True\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ZLNksPtjduik",
   "metadata": {
    "id": "ZLNksPtjduik"
   },
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79OZSKw1duBP",
   "metadata": {
    "id": "79OZSKw1duBP"
   },
   "outputs": [],
   "source": [
    "currentTrial = 10\n",
    "num_trials = 2\n",
    "filename = f\"Trials {currentTrial-num_trials+1}-{currentTrial}\"\n",
    "print(filename)\n",
    "k = 4\n",
    "rmax = 100\n",
    "colors_Reds = plt.get_cmap(\"Reds\")(np.linspace(0,1,101))\n",
    "colors_YlGn = plt.get_cmap(\"YlGn\")(np.linspace(0,1,101))\n",
    "cum_pos_index = np.where((monkey_information['time'] > ff_caught_T_new[currentTrial-num_trials]) & \n",
    "                       (monkey_information['time'] <= ff_caught_T_new[currentTrial]))\n",
    "\n",
    "if len(cum_pos_index) > 0:\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.8, 0.8], polar=True)\n",
    "    ax = plot_behaviors_utils.set_polar_background_for_animation(ax, rmax)\n",
    "\n",
    "    ff_in_time_frame, ff_visible, ff_in_memory = animation_func.subset_ff_dataframe(ff_dataframe, currentTrial, num_trials)\n",
    "    anim_indices = cum_pos_index[0][0:-1:k]\n",
    "    num_frames = anim_indices.size\n",
    "    animate_func = partial(animation_func.animate_polar, ax=ax, anim_indices=anim_indices, rmax=400, ff_in_time_frame=ff_in_time_frame, ff_visible=ff_visible, ff_in_memory=ff_in_memory)\n",
    "    anim = animation.FuncAnimation(fig, animate_func, frames=num_frames, interval=int(250*k), repeat=True) \n",
    "\n",
    "    #gif_dir = '/content/gdrive/My Drive/fireflies_anim/???'\n",
    "    #anim.save(f\"{gif_dir}/{filename}.gif\", writer='pillow', fps=60)\n",
    "else:\n",
    "    print(\"Please try another number for currentTrial, or increase num_trials.\")\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "r6j1e2uxq5OG",
   "metadata": {
    "id": "r6j1e2uxq5OG"
   },
   "source": [
    "# Test agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k9-tdbAHq5_U",
   "metadata": {
    "id": "k9-tdbAHq5_U"
   },
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "cum_rewards = 0\n",
    "for step in range(1000):\n",
    "    action, _ = sac_model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, _, info = env.step(action)\n",
    "    cum_rewards += reward\n",
    "    if done:\n",
    "        obs, _ = env.reset()\n",
    "    # print(step, ffxy_visible[-1])\n",
    "print(cum_rewards)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1Inbx37xwycW",
   "metadata": {
    "id": "1Inbx37xwycW"
   },
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "hfHYXONdz7qJ",
   "metadata": {
    "id": "hfHYXONdz7qJ"
   },
   "source": [
    "## parameters to sample from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xhBysB7hz_F8",
   "metadata": {
    "id": "xhBysB7hz_F8"
   },
   "outputs": [],
   "source": [
    "def sample_sac_params(trial):\n",
    "    \"\"\"\n",
    "    Sampler for SAC hyperparams.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trial: (optuna.trial)\n",
    "\n",
    "    Return: (dict)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
    "    tau = trial.suggest_float(\"tau\", 1e-6, 1, log=True)\n",
    "    #batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256, 512, 1024])\n",
    "    target_update_interval = trial.suggest_categorical('target_update_interval', [5, 10, 20, 40, 60, 100, 200])\n",
    "    #buffer_size = trial.suggest_categorical('buffer_size', [int(1e5), int(1e6)]) # This actually doesn't matter much here because of limited timesteps\n",
    "    learning_starts = trial.suggest_categorical('learning_starts', [5000, 10000, 15000])\n",
    "    train_freq = trial.suggest_categorical('train_freq', [1, 10, 100, 300])\n",
    "    ## gradient_steps takes too much time\n",
    "    # gradient_steps = trial.suggest_categorical('gradient_steps', [1, 100, 300])\n",
    "    gradient_steps = train_freq\n",
    "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
    "    net_arch = trial.suggest_categorical('net_arch', [\"small\", \"medium\", \"big\"])\n",
    "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\"])\n",
    "\n",
    "    net_arch = {\n",
    "        'small': [100, 100],\n",
    "        'medium': [128, 128],\n",
    "        'big': [200, 200],\n",
    "    }[net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
    "\n",
    "    target_entropy = 'auto'\n",
    "    if ent_coef == 'auto':\n",
    "        target_entropy = trial.suggest_categorical('target_entropy', ['auto', -1, -10, -20, -50, -100])\n",
    "\n",
    "\n",
    "    ## Display true values\n",
    "    # trial.set_user_attr(\"gamma_\", gamma)\n",
    "    # trial.set_user_attr(\"n_steps\", n_steps)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'gamma': gamma,\n",
    "        'learning_rate': learning_rate,\n",
    "        'tau': tau,\n",
    "        #'batch_size': batch_size,\n",
    "        'target_update_interval': target_update_interval,\n",
    "        #'buffer_size': buffer_size,\n",
    "        'learning_starts': learning_starts,\n",
    "        'train_freq': train_freq,\n",
    "        'gradient_steps': gradient_steps,\n",
    "        'ent_coef': ent_coef,\n",
    "        'target_entropy': target_entropy,\n",
    "        'policy_kwargs': {\n",
    "            \"net_arch\": net_arch,\n",
    "            \"activation_fn\": activation_fn\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "iV2OVSz10Bve",
   "metadata": {
    "id": "iV2OVSz10Bve"
   },
   "source": [
    "## objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3YZk9SVxCWh",
   "metadata": {
    "id": "-3YZk9SVxCWh"
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    # Sample hyperparameters\n",
    "    kwargs.update(sample_sac_params(trial))\n",
    "    # Create the RL model\n",
    "    model = SAC(**kwargs)\n",
    "    # Create env used for evaluation\n",
    "    eval_env = env\n",
    "    # Create the callback that will periodically evaluate\n",
    "    # and report the performance\n",
    "    eval_callback = SB3_functions.TrialEvalCallback(\n",
    "      eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=eval_freq, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "      model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "      # Sometimes, random hyperparams can generate NaN\n",
    "      print(e)\n",
    "      nan_encountered = True\n",
    "    finally:\n",
    "      # Free memory\n",
    "      model.env.close()\n",
    "      eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "      return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "      raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "UVyTUNFzHtLP",
   "metadata": {
    "id": "UVyTUNFzHtLP"
   },
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dhl9rpZPH0w6",
   "metadata": {
    "id": "Dhl9rpZPH0w6"
   },
   "outputs": [],
   "source": [
    "env = env_for_sb3.EnvForSB3()\n",
    "env.reset()\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"env\": env,\n",
    "}\n",
    "\n",
    "N_TRIALS = 100\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "\n",
    "\n",
    "N_TIMESTEPS = 100000\n",
    "eval_freq = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 1\n",
    "\n",
    "\n",
    "\n",
    "# Set pytorch num threads to 1 for faster training\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "# Do not prune before 1/3 of the max budget is used\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS//3)\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "try:\n",
    "    study.optimize(objective, n_trials=N_TRIALS)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "print(\"  User attrs:\")\n",
    "for key, value in trial.user_attrs.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "Pj9Wo6ylF0MI",
   "metadata": {
    "id": "Pj9Wo6ylF0MI"
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HQmdse_eWe-F",
   "metadata": {
    "id": "HQmdse_eWe-F"
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq ipdb\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hkdgF8xfWgS-",
   "metadata": {
    "id": "hkdgF8xfWgS-"
   },
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3743ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_item.clean_out_cross_boundary_trials()\n",
    "category_item.clean_out_trials_where_target_cluster_was_not_seen_for_a_long_time_before_capture()\n",
    "category_item.make_polar_plot_of_target_last_seen_positions()\n",
    "category_item.make_histograms_of_target_last_seen_attributes()\n",
    "category_item.make_histogram_of_distances_from_previous_targets()\n",
    "category_item.make_polar_plot_of_positions_from_previous_targets()\n",
    "category_item.plot_trajectories(trials=category_item.sort_1_trials[17:18])\n",
    "category_item.plot_distributions_of_visible_ff_and_in_memory_ff()\n",
    "#category_item.make_and_visualize_free_selection_predictions_using_trained_model(trained_model = gnb)\n",
    "# category_item.inspect_special_cases(weird_trials=[98, 180, 212, 649])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1GN5Y_MBqDlaM8t8KZqZZKeERvOau11W_",
     "timestamp": 1681009447473
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
