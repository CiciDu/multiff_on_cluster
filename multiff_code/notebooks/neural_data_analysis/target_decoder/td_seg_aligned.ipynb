{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "    \n",
    "from data_wrangling import general_utils, specific_utils, process_monkey_information\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, ml_decoder_class, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils\n",
    "from neural_data_analysis.topic_based_neural_analysis.target_decoder import behav_features_to_keep, target_decoder_class, prep_target_decoder, eval_target_decoder, td_seg_aligned_class\n",
    "from neural_data_analysis.neural_analysis_tools.gpfa_methods import elephant_utils, fit_gpfa_utils, plot_gpfa_utils, gpfa_tuning, gpfa_helper_class\n",
    "from machine_learning.ml_methods import regression_utils, classification_utils, prep_ml_data_utils\n",
    "from neural_data_analysis.neural_analysis_tools.align_trials import time_resolved_regression, time_resolved_gpfa_regression,plot_time_resolved_regression\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from numpy import pi\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "# To fit gpfa\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "from scipy.integrate import odeint\n",
    "import quantities as pq\n",
    "import neo\n",
    "from elephant.spike_train_generation import inhomogeneous_poisson_process\n",
    "from elephant.gpfa import GPFA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from elephant.gpfa import gpfa_core, gpfa_util\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.monkey_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.behav_data_by_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0416\"\n",
    "#raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0328\"\n",
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Schro/data_0321\"\n",
    "bin_width = 0.1\n",
    "dec = td_seg_aligned_class.TargetDecoderSegmentAlignedClass(raw_data_folder_path=raw_data_folder_path,\n",
    "                                                               bin_width=bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_data_exists_ok = True\n",
    "x_and_y_var_exists_ok = False\n",
    "dec.streamline_making_behav_and_neural_data(exists_ok=behav_data_exists_ok)\n",
    "dec.get_x_and_y_var(exists_ok=x_and_y_var_exists_ok)\n",
    "dec.get_x_and_y_data_for_modeling(exists_ok=x_and_y_var_exists_ok)\n",
    "# dec._free_up_memory()\n",
    "print('x_var.shape:', dec.x_var.shape)\n",
    "print('y_var_reduced.shape:', dec.y_var_reduced.shape)\n",
    "\n",
    "print('x_var_lags.shape:', dec.x_var_lags.shape)\n",
    "print('y_var_lags_reduced.shape:', dec.y_var_lags_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data and fit gpfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.prepare_seg_aligned_data(align_at_beginning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.get_gpfa_traj(latent_dimensionality=7, exists_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dec.trajectories.shape) # number of segments\n",
    "print(dec.trajectories[2].shape) # num_latent_dimensions x num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_raw_spike_data_instead = False\n",
    "dec.get_concat_data_for_regression(use_raw_spike_data_instead=False,\n",
    "                                    use_lagged_raw_spike_data=False,\n",
    "                                    apply_pca_on_raw_spike_data=False,\n",
    "                                    num_pca_components=7)\n",
    "\n",
    "dec.print_data_dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## point-wise segment regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.time_resolved_regression_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.plot_time_resolved_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.plot_trial_counts_by_timepoint()  # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat data regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate linear regression\n",
    "dec.y_var_lr_df = neural_data_modeling.get_y_var_lr_df(\n",
    "                dec.concat_neural_trials.drop(columns=['new_segment', 'new_bin'], errors='ignore'),\n",
    "                dec.concat_behav_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_raw_spike_data_instead=True,\n",
    "# use_lagged_raw_spike_data=True,\n",
    "# apply_pca_on_raw_spike_data=True,\n",
    "dec.y_var_lr_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_raw_spike_data_instead = True\n",
    "dec.y_var_lr_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_raw_spike_data_instead=True,\n",
    "# use_lagged_raw_spike_data=True,\n",
    "\n",
    "dec.y_var_lr_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_raw_spike_data_instead = False\n",
    "dec.y_var_lr_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-test split by segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # x_var, y_var = pn.get_concat_x_and_y_var_for_lr(test_or_control=test_or_control)\n",
    "    \n",
    "    # results_summary = ml_methods_utils.run_segment_split_regression_cv(\n",
    "    #     x_var, \n",
    "    #     y_var, \n",
    "    #     columns_of_interest, \n",
    "    #     num_folds=5, \n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning.ml_methods import ml_methods_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['target_distance']\n",
    "\n",
    "x_var = dec.concat_neural_trials\n",
    "y_var = dec.concat_behav_trials\n",
    "\n",
    "results_summary = ml_methods_utils.run_segment_split_regression_cv(\n",
    "    x_var, \n",
    "    y_var, \n",
    "    columns_of_interest, \n",
    "    num_folds=5, \n",
    "    segment_column='new_segment',\n",
    ")\n",
    "\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = ml_methods_utils.convert_results_to_wide_df(results_summary, index_columns=['Target', 'Model'])\n",
    "wide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gpfa_utils.plot_gpfa_traj_3d_uniform_color(dec.trajectories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plot_gpfa_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, enable interactive mode in your notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# Create the interactive plot\n",
    "fig, ax = plot_gpfa_utils.plot_gpfa_traj_3d(\n",
    "    num_traj_to_plot=30,\n",
    "    trajectories=dec.trajectories,\n",
    "    figsize=(15, 5),\n",
    "    linewidth_single_trial=0.75,\n",
    "    alpha_single_trial=0.3,\n",
    "    linewidth_trial_average=2,\n",
    "    title='Latent dynamics extracted by GPFA',\n",
    "    view_azim=-5,\n",
    "    view_elev=60\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_gpfa_utils.plot_gpfa_traj_3d_plotly(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find variance explained by each latent dimension\n",
    "traj_stack = np.stack(dec.trajectories, axis=0)  # shape: (n_trials, 3, T)\n",
    "var_by_dim = np.var(traj_stack, axis=(0, 2))    # variance across trials and time\n",
    "var_by_dim /= var_by_dim.sum()               # normalize to get explained variance ratio\n",
    "print(\"Variance explained by each latent dimension:\", var_by_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.set_title('Latent dynamics extracted by GPFA')\n",
    "ax.set_xlabel('Time [s]')\n",
    "\n",
    "average_trajectory = np.mean(dec.trajectories, axis=0)\n",
    "time = np.arange(len(average_trajectory[0])) * dec.bin_width  # assuming all trajectories have the same length\n",
    "\n",
    "for i, x in enumerate(average_trajectory):\n",
    "    ax.plot(time, x, label=f'Dim {i+1}')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why poor performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_data_analysis.neural_analysis_tools.gpfa_methods.time_resolved_regression as time_resolved_regression\n",
    "\n",
    "# 1. Print number of trials per timepoint\n",
    "time_resolved_regression.print_trials_per_timepoint(dec.gpfa_neural_trials)\n",
    "\n",
    "# 2. Check for NaNs\n",
    "time_resolved_regression.check_for_nans_in_trials(dec.gpfa_neural_trials, name='latent')\n",
    "time_resolved_regression.check_for_nans_in_trials(dec.behav_trials, name='behavioral')\n",
    "\n",
    "# 3. Standardize trials\n",
    "latent_trials_std = time_resolved_regression.standardize_trials(dec.gpfa_neural_trials)\n",
    "behav_trials_std = time_resolved_regression.standardize_trials(dec.behav_trials)\n",
    "\n",
    "# 4. Print number of points per trial\n",
    "plot_time_resolved_regression.plot_trial_point_distribution(dec.pursuit_data)\n",
    "\n",
    "# 5. Plot latent and behavioral variables for a few trials\n",
    "time_resolved_regression.plot_latents_and_behav_trials(latent_trials_std, behav_trials_std, bin_width=dec.bin_width, n_trials=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams (still need to debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop! # this section is not finished yet\n",
    "\n",
    "# grid search\n",
    "\n",
    "import itertools\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "print(f\"Detected CPU cores: {cpu_count()}\")\n",
    "\n",
    "# # can add for smoothing:\n",
    "# # other forms of smoothing like (currently it's only uniform_filter1d)\n",
    "# from scipy.ndimage import gaussian_filter1d\n",
    "# # gpfa_neural_trials: list of trials, each trial shape (time_bins, n_neurons)\n",
    "# smoothed_trials = [\n",
    "#     gaussian_filter1d(trial, sigma=smooth_sigma, axis=0)\n",
    "#     for trial in gpfa_neural_trials\n",
    "# ]\n",
    "\n",
    "\n",
    "# Define your grid\n",
    "smoothing_windows = [1, 3]\n",
    "use_sqrt = [True, False]\n",
    "gpfa_dims = [3, 5]\n",
    "bin_widths = [0.02]\n",
    "ridge_alphas = [0.1, 1]\n",
    "regression_types = ['ridge']\n",
    "align_at_beginning_opts = [True]\n",
    "pca_components = [5, 10]\n",
    "\n",
    "param_grid_gpfa = list(itertools.product(\n",
    "    smoothing_windows, use_sqrt, gpfa_dims, bin_widths, ridge_alphas, regression_types, align_at_beginning_opts\n",
    "))\n",
    "\n",
    "# Baseline configs\n",
    "param_grid_raw = list(itertools.product(\n",
    "    smoothing_windows, use_sqrt, bin_widths, ridge_alphas, regression_types, align_at_beginning_opts\n",
    "))\n",
    "param_grid_pca = list(itertools.product(\n",
    "    smoothing_windows, use_sqrt, bin_widths, ridge_alphas, regression_types, align_at_beginning_opts, pca_components\n",
    "))\n",
    "\n",
    "# Run GPFA grid\n",
    "results_gpfa = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(gpfa_tuning.run_gpfa_experiment_time_resolved)(\n",
    "        dec, smoothing, sqrt, gpfa_dim, bin_width, ridge_alpha, regression_type, align_at_beginning, baseline=None\n",
    "    )\n",
    "    for (smoothing, sqrt, gpfa_dim, bin_width, ridge_alpha, regression_type, align_at_beginning) in param_grid_gpfa\n",
    ")\n",
    "\n",
    "# Run raw baseline grid\n",
    "results_raw = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(gpfa_tuning.run_gpfa_experiment_time_resolved)(\n",
    "        dec, smoothing, sqrt, None, bin_width, ridge_alpha, regression_type, align_at_beginning, baseline='raw'\n",
    "    )\n",
    "    for (smoothing, sqrt, bin_width, ridge_alpha, regression_type, align_at_beginning) in param_grid_raw\n",
    ")\n",
    "\n",
    "# Run PCA baseline grid\n",
    "results_pca = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(gpfa_tuning.run_gpfa_experiment_time_resolved)(\n",
    "        dec, smoothing, sqrt, None, bin_width, ridge_alpha, regression_type, align_at_beginning, baseline='pca', pca_components=pca_comp\n",
    "    )\n",
    "    for (smoothing, sqrt, bin_width, ridge_alpha, regression_type, align_at_beginning, pca_comp) in param_grid_pca\n",
    ")\n",
    "\n",
    "# Combine all results\n",
    "all_results = results_gpfa + results_raw + results_pca\n",
    "df = pd.DataFrame(all_results)\n",
    "print(df.sort_values('mean_r2', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "best = df.iloc[df['mean_r2'].idxmax()]\n",
    "plt.plot(best['times'], np.nanmean(np.array(best['r2_by_time']), axis=1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Mean R²')\n",
    "plt.title(f\"Best config: {best['model']} R² by time\")\n",
    "plt.show()\n",
    "\n",
    "# Compare models\n",
    "import seaborn as sns\n",
    "sns.catplot(data=df, x='model', y='mean_r2', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML to decode single vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_data = dec.x_var_lags\n",
    "# behavioral_data = dec.y_var_reduced\n",
    "\n",
    "neural_data = dec.concat_neural_trials\n",
    "behavioral_data = dec.concat_behav_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General usage for any behavioral variable\n",
    "decoder = ml_decoder_class.MLBehavioralDecoder()\n",
    "models_to_use=['rf', 'nn', 'lr']\n",
    "successful_decodings = {}\n",
    "\n",
    "for var in ['target_rel_y', 'target_rel_x']:\n",
    "    result = decoder.decode_variable(neural_data, behavioral_data, var, models_to_use=models_to_use)\n",
    "    if result is not None:\n",
    "        successful_decodings[var] = result\n",
    "\n",
    "best_model, best_results = decoder.get_best_model('target_rel_y', 'test_r2')\n",
    "\n",
    "# Plot rf results for any variable\n",
    "decoder.plot_ml_results('target_rel_y', 'rf')\n",
    "\n",
    "successful_decodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare different Models\n",
    "\n",
    "Let's compare the performance of different machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = eval_target_decoder.compare_models(successful_decodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot feature importance for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for Random Forest models\n",
    "for target_var in successful_decodings.keys():\n",
    "    if 'rf' in successful_decodings[target_var]:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"FEATURE IMPORTANCE: {target_var}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        rf_model = successful_decodings[target_var]['rf']['model']\n",
    "        \n",
    "        if hasattr(rf_model, 'feature_importances_'):\n",
    "            # Get feature importance\n",
    "            importance_df = regression_utils._get_rf_feature_importances(rf_model, dec.neural_data.columns)\n",
    "            # Show top 10 most important features\n",
    "            print(f\"Top 10 most important neurons for {target_var}:\")\n",
    "            print(importance_df.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            regression_utils.plot_feature_importance(importance_df, target_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results (have yet to try)\n",
    "\n",
    "Finally, let's save our results for future analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "def create_experiment_info(decoder, monkey: str, session: str) -> Dict[str, Any]:\n",
    "    \"\"\"Create experiment information dictionary.\"\"\"\n",
    "    return {\n",
    "        'monkey': monkey,\n",
    "        'session': session,\n",
    "        'bin_width': decoder.bin_width,\n",
    "        'neural_data_shape': decoder.neural_data.shape,\n",
    "        'target_data_shape': decoder.target_data.shape\n",
    "    }\n",
    "\n",
    "def create_cca_results(decoder) -> Dict[str, Any]:\n",
    "    \"\"\"Create CCA results summary.\"\"\"\n",
    "    return {\n",
    "        'top_3_correlations': (\n",
    "            decoder.results['cca']['canonical_correlations'][:3].tolist() \n",
    "            if 'cca' in decoder.results else None\n",
    "        )\n",
    "    }\n",
    "\n",
    "def find_best_performances(successful_decodings: Dict) -> Dict[str, Dict[str, Any]]:\n",
    "    \"\"\"Find best performing model for each target variable.\"\"\"\n",
    "    best_performances = {}\n",
    "    for target_var, models in successful_decodings.items():\n",
    "        best_model = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for model_name, results in models.items():\n",
    "            score = results.get('test_r2', results.get('test_accuracy', results.get('cv_mean', 0)))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model_name\n",
    "        \n",
    "        best_performances[target_var] = {\n",
    "            'best_model': best_model,\n",
    "            'best_score': best_score\n",
    "        }\n",
    "    return best_performances\n",
    "\n",
    "def create_summary_report(decoder, successful_decodings: Dict, monkey: str, session: str) -> Dict[str, Any]:\n",
    "    \"\"\"Create complete summary report.\"\"\"\n",
    "    return {\n",
    "        'experiment_info': create_experiment_info(decoder, monkey, session),\n",
    "        'cca_results': create_cca_results(decoder),\n",
    "        'ml_results_summary': {\n",
    "            'successful_targets': list(successful_decodings.keys()),\n",
    "            'best_performances': find_best_performances(successful_decodings)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def print_summary_report(summary_report: Dict[str, Any]):\n",
    "    \"\"\"Print formatted summary report.\"\"\"\n",
    "    print(\"\\nEXPERIMENT SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Neural data shape: {summary_report['experiment_info']['neural_data_shape']}\")\n",
    "    print(f\"Target data shape: {summary_report['experiment_info']['target_data_shape']}\")\n",
    "    \n",
    "    if summary_report['cca_results']['top_3_correlations']:\n",
    "        print(f\"Top 3 CCA correlations: {summary_report['cca_results']['top_3_correlations']}\")\n",
    "    \n",
    "    print(f\"Successfully decoded targets: {summary_report['ml_results_summary']['successful_targets']}\")\n",
    "    \n",
    "    print(\"\\nBest model performance for each target:\")\n",
    "    for target, perf in summary_report['ml_results_summary']['best_performances'].items():\n",
    "        print(f\"  {target}: {perf['best_model']} (score: {perf['best_score']:.4f})\")\n",
    "\n",
    "def save_experiment_results(decoder, successful_decodings: Dict, monkey: str, session: str, \n",
    "                          base_filename: str = None):\n",
    "    \"\"\"Save both detailed results and summary report.\"\"\"\n",
    "    if base_filename is None:\n",
    "        base_filename = f\"target_decoding_results_{monkey}_{session}\"\n",
    "    \n",
    "    pkl_filename = f\"{base_filename}.pkl\"\n",
    "    json_filename = f\"{base_filename}_summary.json\"\n",
    "    \n",
    "    # Save detailed results\n",
    "    print(\"Saving results...\")\n",
    "    decoder.save_results(pkl_filename)\n",
    "    \n",
    "    # Create and save summary report\n",
    "    summary_report = create_summary_report(decoder, successful_decodings, monkey, session)\n",
    "    print_summary_report(summary_report)\n",
    "    \n",
    "    with open(json_filename, 'w') as f:\n",
    "        json.dump(summary_report, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {pkl_filename}\")\n",
    "    print(f\"Summary saved to: {json_filename}\")\n",
    "    \n",
    "    return pkl_filename, json_filename\n",
    "\n",
    "def load_experiment_results(base_filename: str = None, monkey: str = None, session: str = None):\n",
    "    \"\"\"Load both detailed results and summary report.\"\"\"\n",
    "    if base_filename is None:\n",
    "        if monkey and session:\n",
    "            base_filename = f\"target_decoding_results_{monkey}_{session}\"\n",
    "        else:\n",
    "            raise ValueError(\"Must provide either base_filename or both monkey and session\")\n",
    "    \n",
    "    pkl_filename = f\"{base_filename}.pkl\"\n",
    "    json_filename = f\"{base_filename}_summary.json\"\n",
    "    \n",
    "    try:\n",
    "        # Load detailed results\n",
    "        with open(pkl_filename, 'rb') as f:\n",
    "            decoder_results = pickle.load(f)\n",
    "        \n",
    "        # Load summary report\n",
    "        with open(json_filename, 'r') as f:\n",
    "            summary_report = json.load(f)\n",
    "        \n",
    "        print(f\"Loaded results from: {pkl_filename}\")\n",
    "        print(f\"Loaded summary from: {json_filename}\")\n",
    "        \n",
    "        return decoder_results, summary_report\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# --- Usage Examples ---\n",
    "\n",
    "# Saving (replaces your original code):\n",
    "# save_experiment_results(decoder, successful_decodings, 'Bruno', 'data_0328')\n",
    "\n",
    "# Loading:\n",
    "# decoder_results, summary_report = load_experiment_results(monkey='Bruno', session='data_0328')\n",
    "# OR\n",
    "# decoder_results, summary_report = load_experiment_results(base_filename=\"target_decoding_results_bruno_0328\")\n",
    "\n",
    "# If you want to print the loaded summary:\n",
    "# if summary_report:\n",
    "#     print_summary_report(summary_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything with one function call\n",
    "save_experiment_results(decoder, successful_decodings, 'Bruno', 'data_0328')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load everything with one function call\n",
    "decoder_results, summary_report = load_experiment_results(monkey='Bruno', session='data_0328')\n",
    "## OR\n",
    "# decoder_results, summary_report = load_experiment_results(base_filename=\"target_decoding_results_bruno_0328\")\n",
    "\n",
    "# If you want to print the loaded summary:\n",
    "if summary_report:\n",
    "    print_summary_report(summary_report)\n",
    "\n",
    "# Access successful_decodings\n",
    "if decoder_results and 'successful_decodings' in decoder_results:\n",
    "    successful_decodings = decoder_results['successful_decodings']\n",
    "    # Use with your model comparison functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more columns (possibly get in the future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get also get: (but to be honest, it doesn't make that much sense to get them....so let's skip for now.)\n",
    "'distance traversed since target last visible',\n",
    "'d angle since target last visible', 'target_at_right',\n",
    "'time_till_capture', 'time from last visible to capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there might be multicollinearity. For example, duration from last visible to capture = time since target last visible + time till capture\n",
    "\n",
    "Similarly, target angle = target angle last seen frozen - d angle since target last visible\n",
    "\n",
    "(For distance it's not exactly the same because of the difference between distance and distance traversed, but it's still similar)\n",
    "\n",
    "The multicollinearity is fine in linear regression (when each feature here is a y var), but need to be dealt with in cca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## possible things to try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should i actually align each section, as if they are trials???\n",
    "maybe i can try both that and continuous time... both can shed light on different behavioral variables\n",
    "but for aligning trials, it may require alignment or warping since trial durations vary.\n",
    "\n",
    "btw, what does it mean to stitch data?\n",
    "\n",
    "also, what does it look like to use RNN to model it?\n",
    "I thought about the paper that Noah presented on RNN\n",
    "\n",
    "\n",
    "btw.......IME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot trial segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot trial segments in pursuit_data\n",
    "from visualization.matplotlib_tools import plot_trials,\n",
    "dec.make_PlotTrials_args()\n",
    "plt.rcParams['figure.figsize'] = [10, 10]                     \n",
    "\n",
    "max_plot_to_make = 2\n",
    "plot_counter = 0\n",
    "\n",
    "for index, row in dec.single_vis_target_df.iloc[2:].iterrows():\n",
    "\n",
    "    duration = [row['last_vis_time'], row['ff_caught_time']]\n",
    "\n",
    "    returned_info = plot_trials.PlotTrials(\n",
    "                duration, \n",
    "                *dec.PlotTrials_args,  \n",
    "                adjust_xy_limits=True,       \n",
    "                minimal_margin=50,\n",
    "                show_reward_boundary=True,\n",
    "                show_alive_fireflies=False,\n",
    "                show_visible_fireflies=True,\n",
    "                show_in_memory_fireflies=True,\n",
    "                show_believed_target_positions=True,\n",
    "                )\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plot_counter += 1\n",
    "    if plot_counter >= max_plot_to_make:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.behav_data_by_bin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Custom function for mode (returns first mode if multiple)\n",
    "def get_mode(x):\n",
    "    return x.mode().iloc[0] if not x.mode().empty else pd.NA\n",
    "\n",
    "# Define strict median function\n",
    "def strict_median(series, method='lower'):\n",
    "    sorted_vals = np.sort(series.dropna().values)\n",
    "    n = len(sorted_vals)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    elif n % 2 == 1:\n",
    "        return sorted_vals[n // 2]\n",
    "    else:\n",
    "        if method == 'lower':\n",
    "            return sorted_vals[n // 2 - 1]\n",
    "        elif method == 'upper':\n",
    "            return sorted_vals[n // 2]\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'lower' or 'upper'\")\n",
    "\n",
    "# Define column groups\n",
    "col_max = ['target_visible_dummy', 'target_cluster_visible_dummy', 'capture_ff',\n",
    "           'num_visible_ff', 'any_ff_visible', 'catching_ff']\n",
    "col_strict_median = ['point_index', 'valid_view_point']\n",
    "\n",
    "# Combine aggregation functions\n",
    "agg_funcs = {col: 'max' for col in col_max}\n",
    "agg_funcs.update({col: strict_median for col in col_strict_median})\n",
    "\n",
    "# Perform groupby\n",
    "result = df.groupby('bin').agg(agg_funcs).reset_index()\n",
    "\n",
    "# Drop unwanted columns (corrected)\n",
    "result = result.drop(columns=[\n",
    "    'target_index', \n",
    "    'target_has_disappeared_for_last_time_dummy', \n",
    "    'target_cluster_has_disappeared_for_last_time_dummy'\n",
    "])\n",
    "\n",
    "# Merge back relevant columns (corrected)\n",
    "result = result.merge(\n",
    "    df[['point_index', 'target_index', 'target_has_disappeared_for_last_time_dummy', \n",
    "        'target_cluster_has_disappeared_for_last_time_dummy']],\n",
    "    on='point_index',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# through merge\n",
    "'target_index', 'target_has_disappeared_for_last_time_dummy', 'target_cluster_has_disappeared_for_last_time_dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max\n",
    "col_max = ['target_visible_dummy', 'target_cluster_visible_dummy', 'capture_ff',\n",
    "           'num_visible_ff', 'any_ff_visible', 'catching_ff']\n",
    "\n",
    "# strict median\n",
    "col_strict_median = ['point_index', 'valid_view_point']\n",
    "\n",
    "\n",
    "agg_funcs = {\n",
    " col: 'max' for col in col_max,\n",
    " col: 'strict_median' for col in col_strict_median,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for mode (returns first mode if multiple)\n",
    "def get_mode(x):\n",
    "    return x.mode().iloc[0] if not x.mode().empty else pd.NA\n",
    "\n",
    "def strict_median(series, method='lower'):\n",
    "    sorted_vals = np.sort(series.dropna().values)\n",
    "    n = len(sorted_vals)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    elif n % 2 == 1:\n",
    "        return sorted_vals[n // 2]\n",
    "    else:\n",
    "        if method == 'lower':\n",
    "            return sorted_vals[n // 2 - 1]\n",
    "        elif method == 'upper':\n",
    "            return sorted_vals[n // 2]\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'lower' or 'upper'\")\n",
    "        \n",
    "# Specify aggregations\n",
    "agg_funcs = {\n",
    "    \n",
    "}\n",
    "\n",
    "# Get list of remaining columns to apply median\n",
    "remaining_cols = [col for col in df.columns if col not in ['group'] + list(agg_funcs)]\n",
    "for col in remaining_cols:\n",
    "    agg_funcs[col] = 'median'\n",
    "\n",
    "# Perform groupby\n",
    "result = df.groupby('bin').agg(agg_funcs).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.behav_data_by_bin.groupby('target_index').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.ff_caught_T_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff_venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
