{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up logging configuration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/multiff_clean/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, sys\n",
    "from pathlib import Path\n",
    "for p in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    if p.name == 'Multifirefly-Project':\n",
    "        os.chdir(p)\n",
    "        sys.path.insert(0, str(p / 'multiff_analysis/multiff_code/methods'))\n",
    "        break\n",
    "\n",
    "from data_wrangling import specific_utils, process_monkey_information, general_utils\n",
    "from pattern_discovery import pattern_by_trials, pattern_by_trials, cluster_analysis, organize_patterns_and_features\n",
    "from visualization.matplotlib_tools import plot_behaviors_utils\n",
    "from neural_data_analysis.neural_analysis_tools.get_neural_data import neural_data_processing\n",
    "from neural_data_analysis.neural_analysis_tools.visualize_neural_data import plot_neural_data, plot_modeling_result\n",
    "from neural_data_analysis.neural_analysis_tools.model_neural_data import transform_vars, neural_data_modeling, drop_high_corr_vars, drop_high_vif_vars\n",
    "from neural_data_analysis.topic_based_neural_analysis.neural_vs_behavioral import prep_monkey_data, prep_target_data, neural_vs_behavioral_class\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods import cca_class, cca_utils, cca_cv_utils\n",
    "from neural_data_analysis.neural_analysis_tools.cca_methods.cca_plotting import cca_plotting, cca_plot_lag_vs_no_lag, cca_plot_cv\n",
    "from machine_learning.ml_methods import regression_utils, ml_methods_utils, regz_regression_utils, ml_methods_class, classification_utils, ml_plotting_utils\n",
    "from neural_data_analysis.design_kits.design_by_segment import create_design_df, predictor_utils, other_feats\n",
    "from neural_data_analysis.topic_based_neural_analysis.planning_and_neural import planning_and_neural_class, pn_utils, pn_helper_class, pn_aligned_by_seg, pn_aligned_by_event, pn_glm_utils\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.tpg import glm_bases, glm_plotting, glm_plotting2, glm_fit\n",
    "\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_psth import core_stops_psth, get_stops_utils, psth_postprocessing, psth_stats, compare_events, dpca_utils\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_fit import stop_glm_fit, cv_stop_glm, glm_fit_utils, variance_explained\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_plotting import plot_spikes, plot_glm_fit, plot_tuning_func\n",
    "from neural_data_analysis.design_kits.design_around_event import event_binning, stop_design, cluster_design, design_checks\n",
    "from neural_data_analysis.topic_based_neural_analysis.stop_event_analysis.stop_glm.glm_hyperparams import compare_glm_configs, glm_hyperparams_class\n",
    "from neural_data_analysis.neural_analysis_tools.glm_tools.glm_decoding_tools import glm_decoding_llr, glm_decoding\n",
    "from planning_analysis.show_planning.cur_vs_nxt_ff import cvn_from_ref_class\n",
    "from planning_analysis.plan_factors import build_factor_comp\n",
    "\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import gc\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from scipy import linalg, interpolate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse\n",
    "from numpy import pi\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "# Machine Learning imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "\n",
    "# Neuroscience specific imports\n",
    "import neo\n",
    "import rcca\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "rc('animation', html='jshtml')\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "np.set_printoptions(suppress=True)\n",
    "print(\"done\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0222\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 83 points where monkey is outside of 1338 points that are outside of the reward boundary, which is 6.20% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Removed 0 rows out of 766 rows where cur_ff was not visible bbas or nxt_ff was not visible both bbas and bsans\n",
      "shared_stops_near_ff_df has 766 rows\n",
      "Retrieving shared_stops_near_ff_df succeeded\n",
      "[Warning] 2.036% of ff_x_relative > ff_y_relative. Rows will be removed.\n",
      "Successfully retrieved diff_in_curv_df from all_monkey_data/planning/monkey_Bruno/data_0330/diff_in_curv_df/opt_arc_stop_closest/test/dist_-100_window_-25cm_0cm\n",
      "Successfully retrieved heading_info_df from all_monkey_data/planning/monkey_Bruno/data_0330/heading_info_df/opt_arc_stop_closest/test/Bruno_dist_-100\n"
     ]
    }
   ],
   "source": [
    "cvn = cvn_from_ref_class.CurVsNxtFfFromRefClass(raw_data_folder_path=raw_data_folder_path)\n",
    "# Quick method - tries to retrieve first, creates if needed\n",
    "cvn.make_heading_info_df_without_long_process(\n",
    "    test_or_control='test',  # or 'control'\n",
    "    ref_point_mode='distance',  # or 'time after cur ff visible'\n",
    "    ref_point_value=-100,  # or 0.0 for time mode\n",
    "    heading_info_df_exists_ok=True,  # Set to False to force recreation\n",
    "    stops_near_ff_df_exists_ok=True,\n",
    "    save_data=True\n",
    ")\n",
    "\n",
    "# Access the result\n",
    "heading_info_df = cvn.heading_info_df\n",
    "heading_df = heading_info_df[['cur_ff_index', 'diff_in_abs_angle_to_nxt_ff']].copy()\n",
    "heading_df = heading_df.sort_values(by='diff_in_abs_angle_to_nxt_ff', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# based on same side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_wrangling import combine_info_utils, specific_utils\n",
    "\n",
    "# Get all sessions for a specific monkey\n",
    "monkey_name = \"monkey_Bruno\"  # or \"monkey_Schro\"\n",
    "sessions_df = combine_info_utils.make_sessions_df_for_one_monkey(\n",
    "    raw_data_dir_name='all_monkey_data/raw_monkey_data',\n",
    "    monkey_name=monkey_name\n",
    ")\n",
    "\n",
    "# Iterate through each session\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished']:\n",
    "        continue  # Skip already processed sessions\n",
    "    \n",
    "    # Construct the raw_data_folder_path\n",
    "    raw_data_folder_path = f\"all_monkey_data/raw_monkey_data/{row['monkey_name']}/{row['data_name']}\"\n",
    "    \n",
    "    print(f\"Processing: {raw_data_folder_path}\")\n",
    "    \n",
    "\n",
    "    pn = glm_decoding.init_decoding_data(raw_data_folder_path)\n",
    "\n",
    "    heading_info_df, heading_df = pn_glm_utils.get_test_heading_df(raw_data_folder_path)\n",
    "\n",
    "    build_factor_comp.add_dir_from_cur_ff_same_side(heading_info_df)\n",
    "    heading_info_df['dir_from_cur_ff_same_side'].mean()\n",
    "\n",
    "\n",
    "    for same_side in [True, False]:\n",
    "        print('-'*100)\n",
    "        print('-'*100)\n",
    "        if same_side:\n",
    "            str = \"=========Same Side=========\"\n",
    "        else:\n",
    "            str = \"=========Opposite Side=========\"\n",
    "            \n",
    "        rebinned_x_var, rebinned_y_var = pn_glm_utils.select_ff_subset_by_dir_from_cur_ff_same_side(heading_info_df, pn.rebinned_x_var, pn.rebinned_y_var,\n",
    "                                                                                                    same_side=same_side)\n",
    "        \n",
    "        rebinned_x_var = pn_glm_utils.drop_constant_columns(rebinned_x_var)\n",
    "        data = rebinned_y_var.copy()\n",
    "\n",
    "\n",
    "        df_X, df_Y = glm_decoding.get_data_for_decoding_vis(rebinned_x_var, rebinned_y_var, pn.bin_width)\n",
    "\n",
    "        exposure = np.ones(len(df_Y)) * pn.bin_width\n",
    "        offset_log = np.log(exposure)\n",
    "\n",
    "        report = stop_glm_fit.glm_mini_report(\n",
    "            df_X=df_X, df_Y=df_Y, offset_log=offset_log,\n",
    "            cov_type='HC1', \n",
    "            fast_mle=True,\n",
    "            do_inference=False, \n",
    "            make_plots=False,\n",
    "            show_plots=True,\n",
    "        )\n",
    "        \n",
    "        #cols_to_decode = ['nxt_vis', 'random_0_or_1', 'cur_vis']\n",
    "        cols_to_decode = ['nxt_vis']\n",
    "        groups = np.array(data['new_segment'])\n",
    "\n",
    "        # # Decoding from fit\n",
    "        # print(f\"{str}\")\n",
    "        # glm_decoding.glm_decoding_from_fit(cols_to_decode, df_X, df_Y, offset_log, report)\n",
    "\n",
    "        # CV\n",
    "        print(f\"{str}\")\n",
    "        glm_decoding.glm_decoding_cv(cols_to_decode, df_X, df_Y, groups, offset_log)\n",
    "\n",
    "        # # permutations\n",
    "        # print(f\"{str}\")\n",
    "        # glm_decoding.glm_decoding_permutation_test(cols_to_decode, df_X, df_Y,\n",
    "        #                         groups, offset_log, report, print_progress=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top vs bottom (diff_in_abs_angle_to_nxt_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_wrangling import combine_info_utils, specific_utils\n",
    "\n",
    "# Get all sessions for a specific monkey\n",
    "monkey_name = \"monkey_Bruno\"  # or \"monkey_Schro\"\n",
    "sessions_df = combine_info_utils.make_sessions_df_for_one_monkey(\n",
    "    raw_data_dir_name='all_monkey_data/raw_monkey_data',\n",
    "    monkey_name=monkey_name\n",
    ")\n",
    "\n",
    "# Iterate through each session\n",
    "for index, row in sessions_df.iterrows():\n",
    "    if row['finished']:\n",
    "        continue  # Skip already processed sessions\n",
    "    \n",
    "    # Construct the raw_data_folder_path\n",
    "    raw_data_folder_path = f\"all_monkey_data/raw_monkey_data/{row['monkey_name']}/{row['data_name']}\"\n",
    "    \n",
    "    print(f\"Processing: {raw_data_folder_path}\")\n",
    "    \n",
    "\n",
    "    pn = glm_decoding.init_decoding_data(raw_data_folder_path)\n",
    "\n",
    "    heading_info_df, heading_df = pn_glm_utils.get_test_heading_df(raw_data_folder_path)\n",
    "\n",
    "    heading_info_df['dir_from_cur_ff_same_side'].mean()\n",
    "\n",
    "\n",
    "    for top in [True, False]:\n",
    "        print('-'*100)\n",
    "        print('-'*100)\n",
    "        if top:\n",
    "            str = \"=========TOP TOP TOP TOP TOP=========\"\n",
    "        else:\n",
    "            str = \"=========BOTTOM BOTTOM BOTTOM BOTTOM BOTTOM=========\"\n",
    "        rebinned_x_var, rebinned_y_var = pn_glm_utils.select_ff_subset(heading_df, pn.rebinned_x_var, pn.rebinned_y_var, \n",
    "                                                                    top=False, pct=0.5)\n",
    "\n",
    "        rebinned_x_var = pn_glm_utils.drop_constant_columns(rebinned_x_var)\n",
    "        data = rebinned_y_var.copy()\n",
    "\n",
    "\n",
    "        df_X, df_Y = glm_decoding.get_data_for_decoding_vis(rebinned_x_var, rebinned_y_var, pn.bin_width)\n",
    "\n",
    "        exposure = np.ones(len(df_Y)) * pn.bin_width\n",
    "        offset_log = np.log(exposure)\n",
    "\n",
    "        report = stop_glm_fit.glm_mini_report(\n",
    "            df_X=df_X, df_Y=df_Y, offset_log=offset_log,\n",
    "            cov_type='HC1', \n",
    "            fast_mle=True,\n",
    "            do_inference=False, \n",
    "            make_plots=False,\n",
    "            show_plots=True,\n",
    "        )\n",
    "        \n",
    "        #cols_to_decode = ['nxt_vis', 'random_0_or_1', 'cur_vis']\n",
    "        cols_to_decode = ['nxt_vis']\n",
    "        groups = np.array(data['new_segment'])\n",
    "\n",
    "        # Decoding from fit\n",
    "        print(f\"{str}\")\n",
    "        glm_decoding.glm_decoding_from_fit(cols_to_decode, df_X, df_Y, offset_log, report)\n",
    "\n",
    "        # CV\n",
    "        print(f\"{str}\")\n",
    "        glm_decoding.glm_decoding_cv(cols_to_decode, df_X, df_Y, groups, offset_log)\n",
    "\n",
    "        # permutations\n",
    "        print(f\"{str}\")\n",
    "        glm_decoding.glm_decoding_permutation_test(cols_to_decode, df_X, df_Y,\n",
    "                                groups, offset_log, report, print_progress=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded binned_spikes_df from all_monkey_data/processed_neural_data/monkey_Bruno/data_0222/binned_spikes_df_0p05.csv\n",
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 1233 points that are significantly larger than ff_caught_T_sorted, which is 0.08% of the points. Max value of closest_time - capture time is 1.7424889999997504. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 73 points where monkey is outside of 1233 points that are outside of the reward boundary, which is 5.92% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Removed 0 rows out of 702 rows where cur_ff was not visible bbas or nxt_ff was not visible both bbas and bsans\n",
      "shared_stops_near_ff_df has 702 rows\n",
      "Retrieving shared_stops_near_ff_df succeeded\n",
      "[Warning] 0.287% of ff_y_relative values are negative and will be removed.\n",
      "[Warning] 6.628% of ff_x_relative > ff_y_relative. Rows will be removed.\n",
      "Successfully retrieved diff_in_curv_df from all_monkey_data/planning/monkey_Bruno/data_0222/diff_in_curv_df/opt_arc_stop_closest/test/cur_vis_0_1_window_-25cm_0cm\n",
      "Successfully retrieved heading_info_df from all_monkey_data/planning/monkey_Bruno/data_0222/heading_info_df/opt_arc_stop_closest/test/Bruno_cur_vis_0_1\n",
      "Need to make a new heading_info_df so that no data are dropped because ff_y is negative. No curature info is needed for this temporary heading_info_df.\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: 109 arc out of 38842 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 94.87922876097338. We will adjust them by making them a little less than 90.\n",
      "Warning: 146 arc out of 37952 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 92.99207431568017. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: max_big_angle is 179.4948464687672 when ff is to the left. There is a problem here. We will adjust them by making them a little less than 90.\n",
      "Warning: 2333 arc out of 38842 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 179.4948464687672. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: 1232 arc out of 38842 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 133.9076555471738. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Percentage of rows outside of [-45, 45]: 3.17%\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Bruno/data_0222/ff_dataframe.h5\n",
      "Made new planning_data_by_point and saved to all_monkey_data/planning_and_neural/monkey_Bruno/data_0222/planning_data_by_point/opt_arc_stop_closest/test/cur_vis_0_1_window_-25cm_0cm\n",
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 1233 points that are significantly larger than ff_caught_T_sorted, which is 0.08% of the points. Max value of closest_time - capture time is 1.7424889999997504. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 73 points where monkey is outside of 1233 points that are outside of the reward boundary, which is 5.92% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Removed 0 rows out of 702 rows where cur_ff was not visible bbas or nxt_ff was not visible both bbas and bsans\n",
      "shared_stops_near_ff_df has 702 rows\n",
      "Retrieving shared_stops_near_ff_df succeeded\n",
      "[Warning] 1.754% of ff_y_relative values are negative and will be removed.\n",
      "[Warning] 16.786% of ff_x_relative > ff_y_relative. Rows will be removed.\n",
      "Successfully retrieved diff_in_curv_df from all_monkey_data/planning/monkey_Bruno/data_0222/diff_in_curv_df/opt_arc_stop_closest/control/cur_vis_0_1_window_-25cm_0cm\n",
      "Successfully retrieved heading_info_df from all_monkey_data/planning/monkey_Bruno/data_0222/heading_info_df/opt_arc_stop_closest/control/Bruno_cur_vis_0_1\n",
      "Need to make a new heading_info_df so that no data are dropped because ff_y is negative. No curature info is needed for this temporary heading_info_df.\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: 156 arc out of 30783 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 98.85900066412302. We will adjust them by making them a little less than 90.\n",
      "Warning: 322 arc out of 27048 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 94.07826559324383. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: max_big_angle is 179.92954436673722 when ff is to the left. There is a problem here. We will adjust them by making them a little less than 90.\n",
      "Warning: 4451 arc out of 30783 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 179.92954436673722. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: max_big_angle is 176.56232545558393 when ff is to the left. There is a problem here. We will adjust them by making them a little less than 90.\n",
      "Warning: 3998 arc out of 30783 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 176.56232545558393. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "Percentage of rows outside of [-45, 45]: 9.35%\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Bruno/data_0222/ff_dataframe.h5\n",
      "Made new planning_data_by_point and saved to all_monkey_data/planning_and_neural/monkey_Bruno/data_0222/planning_data_by_point/opt_arc_stop_closest/control/cur_vis_0_1_window_-25cm_0cm\n",
      "Failed to load behav_data_by_point from all_monkey_data/target_decoder/monkey_Bruno/data_0222/behav_data_by_point.csv. Will make new behav_data_by_point.\n",
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 1233 points that are significantly larger than ff_caught_T_sorted, which is 0.08% of the points. Max value of closest_time - capture time is 1.7424889999997504. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 73 points where monkey is outside of 1233 points that are outside of the reward boundary, which is 5.92% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Bruno/data_0222/ff_dataframe.h5\n",
      "Retrieved target_df\n",
      "Retrieved target_cluster_df\n",
      "Warning: At least one firefly has lower == upper angle bound after clipping (likely > 90° to boundary). Check input.\n",
      "Warning: max_big_angle is 179.95325441525884 when ff is to the left. There is a problem here. We will adjust them by making them a little less than 90.\n",
      "Warning: 14396 arc out of 218751 arcs where ff is to the left of the monkey has an angle larger than 90 degrees. The max is 179.95325441525884. We will adjust them by making them a little less than 90.\n",
      "Warning: At least one arc end is outside the reward boundary. This is invalid. We will adjust them by making them a little less than pi.\n",
      "\n",
      "================================================================================\n",
      "NA Values Analysis for behav_data_by_bin (218,751 rows)\n",
      "================================================================================\n",
      "\n",
      "Number of rows with at least one NA value: 192,911\n",
      "\n",
      "Columns with NA values:\n",
      "------------------------------------------------------------\n",
      "stop_id_duration                          170,456 (  77.9%)\n",
      "stop_id_start_time                        170,456 (  77.9%)\n",
      "stop_id_end_time                          170,456 (  77.9%)\n",
      "stop_cluster_id                           170,456 (  77.9%)\n",
      "stop_cluster_start_point                  170,456 (  77.9%)\n",
      "stop_cluster_end_point                    170,456 (  77.9%)\n",
      "stop_cluster_size                         170,456 (  77.9%)\n",
      "time_since_target_last_seen                91,402 (  41.8%)\n",
      "target_last_seen_distance                  91,402 (  41.8%)\n",
      "time_target_last_seen                      91,402 (  41.8%)\n",
      "target_last_seen_angle                     91,402 (  41.8%)\n",
      "target_last_seen_angle_to_boundary         91,402 (  41.8%)\n",
      "monkey_x_target_last_seen                  91,402 (  41.8%)\n",
      "monkey_y_target_last_seen                  91,402 (  41.8%)\n",
      "monkey_angle_target_last_seen              91,402 (  41.8%)\n",
      "cum_distance_when_target_last_seen         91,402 (  41.8%)\n",
      "distance_from_monkey_pos_target_last_seen   91,402 (  41.8%)\n",
      "cum_distance_since_target_last_seen        91,402 (  41.8%)\n",
      "d_heading_since_target_last_seen           91,402 (  41.8%)\n",
      "target_cluster_last_seen_time              81,057 (  37.1%)\n",
      "target_cluster_last_seen_distance          81,057 (  37.1%)\n",
      "target_cluster_last_seen_angle             81,057 (  37.1%)\n",
      "target_cluster_last_seen_angle_to_boundary   81,057 (  37.1%)\n",
      "monkey_x_target_cluster_last_seen          81,057 (  37.1%)\n",
      "monkey_y_target_cluster_last_seen          81,057 (  37.1%)\n",
      "monkey_angle_target_cluster_last_seen      81,057 (  37.1%)\n",
      "cum_distance_target_cluster_last_seen      81,057 (  37.1%)\n",
      "------------------------------------------------------------\n",
      "Deleted instance attributes ['ff_dataframe', 'monkey_information', 'target_df', 'curv_of_traj_df'] to free up memory\n",
      "Saved behav_data_by_point to all_monkey_data/target_decoder/monkey_Bruno/data_0222/behav_data_by_point.csv\n",
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 1233 points that are significantly larger than ff_caught_T_sorted, which is 0.08% of the points. Max value of closest_time - capture time is 1.7424889999997504. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 73 points where monkey is outside of 1233 points that are outside of the reward boundary, which is 5.92% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "There are 3 duplicated point_index in bin_info. Note: one_point_index_per_bin is False\n"
     ]
    }
   ],
   "source": [
    "raw_data_folder_path = \"all_monkey_data/raw_monkey_data/monkey_Bruno/data_0222\"\n",
    "pn = pn_aligned_by_event.PlanningAndNeuralEventAligned(raw_data_folder_path=raw_data_folder_path)\n",
    "pn.prep_data_to_analyze_planning(planning_data_by_point_exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: new_seg_duration 1.5 is not a multiple of bin_width 0.05\n",
      "new_seg_duration is now 1.5, and post_event_window is now 1.5\n",
      "Loaded new_seg_info from all_monkey_data/planning_and_neural/monkey_Bruno/data_0222/new_seg_info/tlim2_cur_first_pre0_post1p5.csv\n",
      "Dropped 30 columns due to containing NA in rebinned_y_var via calling drop_na_cols function: ['nxt_cntr_arc_curv', 'nxt_opt_arc_curv', 'cur_cntr_arc_curv', 'cur_opt_arc_curv', 'cur_opt_arc_end_heading', 'angle_opt_cur_end_to_nxt_ff', 'angle_from_stop_to_nxt_ff', 'diff_in_angle_to_nxt_ff', 'diff_in_abs_angle_to_nxt_ff', 'traj_curv_to_stop', 'curv_from_stop_to_nxt_ff', 'opt_curv_to_cur_ff', 'curv_from_cur_end_to_nxt_ff', 'd_curv_null_arc', 'd_curv_monkey', 'abs_d_curv_null_arc', 'abs_d_curv_monkey', 'diff_in_d_curv', 'diff_in_abs_d_curv', 'abs_angle_opt_cur_end_to_nxt_ff', 'abs_angle_from_stop_to_nxt_ff', 'abs_diff_in_angle_to_nxt_ff', 'abs_diff_in_abs_angle_to_nxt_ff', 'stop_id_end_time', 'stop_id_duration', 'stop_cluster_id', 'stop_cluster_start_point', 'stop_cluster_end_point', 'stop_cluster_size', 'stop_id_start_time']\n",
      "Made rebinned_x_var, rebinned_y_var, rebinned_x_var_lags, and rebinned_y_var_lags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dusiyi/Documents/Multifirefly-Project/multiff_analysis/multiff_code/methods/neural_data_analysis/neural_analysis_tools/get_neural_data/neural_data_processing.py:262: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  'lag_segment_id', group_keys=False).apply(lag_group)\n"
     ]
    }
   ],
   "source": [
    "pn.rebin_data_in_new_segments(cur_or_nxt='cur', first_or_last='first', time_limit_to_count_sighting=2,\n",
    "                                pre_event_window=0, post_event_window=1.5, rebinned_max_x_lag_number=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.rebinned_y_var = pn_utils.rebin_segment_data(\n",
    "    pn.planning_data_by_point, pn.new_seg_info, bin_width=pn.bin_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8914 entries, 0 to 8913\n",
      "Data columns (total 1 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   time_since_target_last_seen  8914 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 69.8 KB\n"
     ]
    }
   ],
   "source": [
    "pn.rebinned_y_var[['time_since_target_last_seen']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   5127.00000\n",
       "mean       0.34051\n",
       "std        0.35699\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.24074\n",
       "75%        0.59734\n",
       "max        1.47709\n",
       "Name: time_since_target_last_seen, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.rebinned_y_var['time_since_target_last_seen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monkey_x</th>\n",
       "      <th>monkey_y</th>\n",
       "      <th>time</th>\n",
       "      <th>point_index</th>\n",
       "      <th>monkey_angle</th>\n",
       "      <th>speed</th>\n",
       "      <th>accel</th>\n",
       "      <th>ang_speed</th>\n",
       "      <th>ang_accel</th>\n",
       "      <th>_contam</th>\n",
       "      <th>...</th>\n",
       "      <th>target_cluster_last_seen_angle</th>\n",
       "      <th>target_cluster_last_seen_angle_to_boundary</th>\n",
       "      <th>monkey_x_target_cluster_last_seen</th>\n",
       "      <th>monkey_y_target_cluster_last_seen</th>\n",
       "      <th>monkey_angle_target_cluster_last_seen</th>\n",
       "      <th>cum_distance_target_cluster_last_seen</th>\n",
       "      <th>target_cluster_has_disappeared_for_last_time_dummy</th>\n",
       "      <th>target_cluster_visible_dummy</th>\n",
       "      <th>curv_of_traj</th>\n",
       "      <th>target_opt_arc_dheading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.80000</td>\n",
       "      <td>0.08336</td>\n",
       "      <td>0</td>\n",
       "      <td>1.57080</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-127.95750</td>\n",
       "      <td>3242.61415</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.80000</td>\n",
       "      <td>0.09999</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.56612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-92.58555</td>\n",
       "      <td>3891.29539</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.80000</td>\n",
       "      <td>0.11654</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.56612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2822.78260</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.80000</td>\n",
       "      <td>0.13314</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.56612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.80000</td>\n",
       "      <td>0.14975</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.56612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218746</th>\n",
       "      <td>44.83097</td>\n",
       "      <td>292.44476</td>\n",
       "      <td>3597.06860</td>\n",
       "      <td>218746</td>\n",
       "      <td>-1.23116</td>\n",
       "      <td>24.51224</td>\n",
       "      <td>-570.18740</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.11538</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.86870</td>\n",
       "      <td>457.53769</td>\n",
       "      <td>-1.43900</td>\n",
       "      <td>785446.14219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00228</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218747</th>\n",
       "      <td>44.93691</td>\n",
       "      <td>292.15079</td>\n",
       "      <td>3597.08525</td>\n",
       "      <td>218747</td>\n",
       "      <td>-1.23116</td>\n",
       "      <td>14.93512</td>\n",
       "      <td>-448.57057</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.86870</td>\n",
       "      <td>457.53769</td>\n",
       "      <td>-1.43900</td>\n",
       "      <td>785446.14219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00226</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218748</th>\n",
       "      <td>45.00046</td>\n",
       "      <td>291.97443</td>\n",
       "      <td>3597.10177</td>\n",
       "      <td>218748</td>\n",
       "      <td>-1.23116</td>\n",
       "      <td>9.48333</td>\n",
       "      <td>-336.53191</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.86870</td>\n",
       "      <td>457.53769</td>\n",
       "      <td>-1.43900</td>\n",
       "      <td>785446.14219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218749</th>\n",
       "      <td>45.04283</td>\n",
       "      <td>291.85681</td>\n",
       "      <td>3597.11841</td>\n",
       "      <td>218749</td>\n",
       "      <td>-1.23116</td>\n",
       "      <td>3.76618</td>\n",
       "      <td>-212.95439</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.86870</td>\n",
       "      <td>457.53769</td>\n",
       "      <td>-1.43900</td>\n",
       "      <td>785446.14219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218750</th>\n",
       "      <td>45.04283</td>\n",
       "      <td>291.85681</td>\n",
       "      <td>3597.13505</td>\n",
       "      <td>218750</td>\n",
       "      <td>-1.23116</td>\n",
       "      <td>2.40666</td>\n",
       "      <td>-165.57154</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.86870</td>\n",
       "      <td>457.53769</td>\n",
       "      <td>-1.43900</td>\n",
       "      <td>785446.14219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218751 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        monkey_x  monkey_y       time  point_index  monkey_angle    speed  \\\n",
       "0        0.00000  30.80000    0.08336            0       1.57080  0.00000   \n",
       "1        0.00000  30.80000    0.09999            1      -1.56612  0.00000   \n",
       "2        0.00000  30.80000    0.11654            2      -1.56612  0.00000   \n",
       "3        0.00000  30.80000    0.13314            3      -1.56612  0.00000   \n",
       "4        0.00000  30.80000    0.14975            4      -1.56612  0.00000   \n",
       "...          ...       ...        ...          ...           ...      ...   \n",
       "218746  44.83097 292.44476 3597.06860       218746      -1.23116 24.51224   \n",
       "218747  44.93691 292.15079 3597.08525       218747      -1.23116 14.93512   \n",
       "218748  45.00046 291.97443 3597.10177       218748      -1.23116  9.48333   \n",
       "218749  45.04283 291.85681 3597.11841       218749      -1.23116  3.76618   \n",
       "218750  45.04283 291.85681 3597.13505       218750      -1.23116  2.40666   \n",
       "\n",
       "            accel  ang_speed  ang_accel  _contam  ...  \\\n",
       "0        -0.00000 -127.95750 3242.61415    False  ...   \n",
       "1        -0.00000  -92.58555 3891.29539    False  ...   \n",
       "2         0.00000    0.00000 2822.78260    False  ...   \n",
       "3        -0.00000   -0.00000    0.00000    False  ...   \n",
       "4        -0.00000    0.00000   -0.00000    False  ...   \n",
       "...           ...        ...        ...      ...  ...   \n",
       "218746 -570.18740    0.00000   -0.11538    False  ...   \n",
       "218747 -448.57057    0.00000   -0.00000    False  ...   \n",
       "218748 -336.53191    0.00000   -0.00000    False  ...   \n",
       "218749 -212.95439   -0.00000   -0.00000    False  ...   \n",
       "218750 -165.57154   -0.00000   -0.00000    False  ...   \n",
       "\n",
       "        target_cluster_last_seen_angle  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "4                                  NaN   \n",
       "...                                ...   \n",
       "218746                         0.06286   \n",
       "218747                         0.06286   \n",
       "218748                         0.06286   \n",
       "218749                         0.06286   \n",
       "218750                         0.06286   \n",
       "\n",
       "        target_cluster_last_seen_angle_to_boundary  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "...                                            ...   \n",
       "218746                                     0.00000   \n",
       "218747                                     0.00000   \n",
       "218748                                     0.00000   \n",
       "218749                                     0.00000   \n",
       "218750                                     0.00000   \n",
       "\n",
       "        monkey_x_target_cluster_last_seen  monkey_y_target_cluster_last_seen  \\\n",
       "0                                     NaN                                NaN   \n",
       "1                                     NaN                                NaN   \n",
       "2                                     NaN                                NaN   \n",
       "3                                     NaN                                NaN   \n",
       "4                                     NaN                                NaN   \n",
       "...                                   ...                                ...   \n",
       "218746                            2.86870                          457.53769   \n",
       "218747                            2.86870                          457.53769   \n",
       "218748                            2.86870                          457.53769   \n",
       "218749                            2.86870                          457.53769   \n",
       "218750                            2.86870                          457.53769   \n",
       "\n",
       "        monkey_angle_target_cluster_last_seen  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "218746                               -1.43900   \n",
       "218747                               -1.43900   \n",
       "218748                               -1.43900   \n",
       "218749                               -1.43900   \n",
       "218750                               -1.43900   \n",
       "\n",
       "        cum_distance_target_cluster_last_seen  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "218746                           785446.14219   \n",
       "218747                           785446.14219   \n",
       "218748                           785446.14219   \n",
       "218749                           785446.14219   \n",
       "218750                           785446.14219   \n",
       "\n",
       "        target_cluster_has_disappeared_for_last_time_dummy  \\\n",
       "0                                                       0    \n",
       "1                                                       0    \n",
       "2                                                       0    \n",
       "3                                                       0    \n",
       "4                                                       0    \n",
       "...                                                   ...    \n",
       "218746                                                  1    \n",
       "218747                                                  1    \n",
       "218748                                                  1    \n",
       "218749                                                  1    \n",
       "218750                                                  1    \n",
       "\n",
       "        target_cluster_visible_dummy  curv_of_traj  target_opt_arc_dheading  \n",
       "0                                  1       0.00000                 -0.00000  \n",
       "1                                  1       0.00000                  0.09967  \n",
       "2                                  1       0.00000                  0.09967  \n",
       "3                                  1       0.00000                  0.09967  \n",
       "4                                  1       0.00000                  0.09967  \n",
       "...                              ...           ...                      ...  \n",
       "218746                             0       0.00228                 -0.00000  \n",
       "218747                             0       0.00226                 -0.00000  \n",
       "218748                             0       0.00225                 -0.00000  \n",
       "218749                             0       0.00225                 -0.00000  \n",
       "218750                             0       0.00225                 -0.00000  \n",
       "\n",
       "[218751 rows x 89 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.dec.behav_data_by_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved monkey_information\n",
      "The number of points that were removed due to delta_position exceeding the ceiling is 0\n",
      "Warning: ff_closest_stop_time_sorted has 1 points out of 1233 points that are significantly larger than ff_caught_T_sorted, which is 0.08% of the points. Max value of closest_time - capture time is 1.7424889999997504. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_closest_stop_time_sorted has 73 points where monkey is outside of 1233 points that are outside of the reward boundary, which is 5.92% of the points. They are replaced with the original ff_caught_T in ff_caught_T_new.\n",
      "Warning: ff_caught_T_new is not monotonically increasing. Will make it monotonically increasing.\n",
      "Note: ff_caught_T_sorted is replaced with ff_caught_T_new\n",
      "Retrieved ff_dataframe from all_monkey_data/processed_data/monkey_Bruno/data_0222/ff_dataframe.h5\n",
      "Retrieved target_df\n",
      "Retrieved target_cluster_df\n",
      "Made new target_df\n"
     ]
    }
   ],
   "source": [
    "pn.dec.get_basic_data()\n",
    "pn.dec._make_or_retrieve_target_df(exists_ok=False)\n",
    "pn.dec.make_or_retrieve_target_cluster_df()\n",
    "pn.dec.target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cur_in_memory</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1927.03294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1927.09107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1927.14085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1927.19072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1927.24049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>3582.19590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>3582.24566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>3582.29549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>3582.34525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>3582.37845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3787 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cur_in_memory       time\n",
       "5127        1.00000 1927.03294\n",
       "5128        1.00000 1927.09107\n",
       "5129        1.00000 1927.14085\n",
       "5130        1.00000 1927.19072\n",
       "5131        1.00000 1927.24049\n",
       "...             ...        ...\n",
       "8909        1.00000 3582.19590\n",
       "8910        1.00000 3582.24566\n",
       "8911        1.00000 3582.29549\n",
       "8912        1.00000 3582.34525\n",
       "8913        1.00000 3582.37845\n",
       "\n",
       "[3787 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.rebinned_y_var.loc[pn.rebinned_y_var['time_since_target_last_seen'].isna(), ['cur_ff_index', 'cur_in_memory', 'time']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiff_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
